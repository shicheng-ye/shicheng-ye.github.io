{"pages":[],"posts":[{"title":"[da] floyd","text":"Step 1. 思路假设图上的任意两个点，已知两点间的路径权值，如果在图中能够找到一个点, 使其成为两点间的桥点，并且构成的新路径值小于旧路径值。则新路比旧路更短，由此可以得到一个递推公式： d[u][v]=min(d[u][v],d[u][k]+d[k][v]) Step 2. 代码实现1234for (int k = 1; k &lt;= n; k++) for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= n; j++) dis[i][j] = min(dis[i][j], dis[i][k] + dis[k][j]); Step 3. 潜在疑惑由于d[i][k]，d[k][j]在不断更新，而不是恒定的最小值，所以如何保证d[i][j]在最后一次更新的时候，d[i][k]，d[k][j]一定是最小的 ? 令任意两点i和j之间的路径上可选择经过的结点集合中，桥点编号最大的是k，当k=x的时候，d[i][j]得到最小值。 设i-x中的桥点编号最大的为x1 ,x-j中编号最大的为x2 易得x&gt;x1 ,x&gt;x2① 假设此时命题成立，则x=$x_1$时，d[i][x]最小，x=x2 时，d[x][j]最小 由此可以得到x=k的时候d[i][x]+d[x][j]已经是最小了,那么e[i][j]=min(e[i][j]，e[i][x]+e[x][j])必然可以得到最小值 Step 4. 原先的错误想法以及更正假设x1 &gt; k ，当 x = k，由于d[i][k] 还未取得最小值, 故d[i][k] + d[k][j]并没有取到最大值。所以命题①错误？事实上因为i-j的桥点编号最大的必然是k，此时令 k = x1 , 则 d[i][k]的桥点编号皆小于k, 故当 x = k 时，d[i][k]和d[k][j] ，因此f[i][j]可以取到最大值。 当 x2 &gt; k 时同理。","link":"/2021/07/06/data-structure-algorithms/2021-07-06-floyd/"},{"title":"[da] fragmentary knowledge","text":"杂记+++ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 200 * 1000 + 11;int p[N];int d[N];vector&lt;int&gt; g[N];void dfs(int v, int pr = -1, int dst = 0) { d[v] = dst; p[v] = pr; for (auto to : g[v]) { if (to != pr) { dfs(to, v, dst + 1); } }}int main() {#ifdef _DEBUG freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin);#endif int n; scanf(&quot;%d&quot;, &amp;n); for (int i = 0; i &lt; n - 1; ++i) { int x, y; scanf(&quot;%d %d&quot;, &amp;x, &amp;y); --x, --y; g[x].push_back(y); g[y].push_back(x); } dfs(0); set&lt;pair&lt;int, int&gt;&gt; st; for (int i = 0; i &lt; n; ++i) { if (d[i] &gt; 2) { st.insert(make_pair(-d[i], i)); } } int ans = 0; while (!st.empty()) { int v = st.begin()-&gt;second; v = p[v]; ++ans; auto it = st.find(make_pair(-d[v], v)); if (it != st.end()) { st.erase(it); } for (auto to : g[v]) { auto it = st.find(make_pair(-d[to], to)); if (it != st.end()) { st.erase(it); } } } printf(&quot;%d\\n&quot;, ans); system(&quot;pause&quot;);} Memset简介memset 函数是内存赋值函数，用来给某一块内存空间进行赋值的。 原型为 ： 1void *memset(void *s, int v, size_t n); 这里s可以是数组名，也可以是指向某一内在空间的指针；v为要填充的值；n为要填充的字节数； 应用① 数组置0（通用） 1memset(dp, 0, sizeof(dp)); ② 无符号整数组置最值 即每个字节置为 0xff 12memset(dp, 0xff, sizeof(dp)); ③ 有符号整数置最值（memset能达到的最值） 12memset(dp, 0x7f, sizeof(dp));memset(arr,0x80,sizeof(arr)); //set int to -2139062144 ④ 有符号整数置-1 即每个字节变成 0xff（-1补码） 12memset(dp, -1, sizeof(dp));memset(dp, 0xff, sizeof(dp)); ⑤ Double置最值 12memset(arr,0x7F,sizeof(arr)); //set double to 1.38242e+306memset(arr,0xFE,sizeof(arr)); //set double to -5.31401e+303 DP198. House Robber 1234Input: nums = [2,7,9,3,1]Output: 12Explanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12. 动态转移方程： 12dp[i] = max(dp[i-1], dp[i-2] + nums[i]);// 若不抢这家，那么本次最大值为上次最大值；反之为上上次最大值＋这次 746. Min Cost Climbing Stairs 123Input: cost = [1, 100, 1, 1, 1, 100, 1, 1, 100, 1]Output: 6Explanation: Cheapest is start on cost[0], and only step on 1s, skipping cost[3]. 动态转移方程： 12dp[i] = min(dp[i-1] + cost[i-1], dp[i-2] + cost[i-2]);// 到达i点有两种方案：要么从前一次过来，要么从前前一格过来 53. Maximum Subarray 123Input: nums = [-2,1,-3,4,-1,2,1,-5,4]Output: 6Explanation: [4,-1,2,1] has the largest sum = 6. 动态转移方程： 12dp[i] = (dp[i-1] &gt; 0 ? dp[i-1] + nums[i] : nums[i])//dp[i] 代表以元素 nums[i] 为结尾的连续子数组最大和。 392. Is Subsequence 12Input: s = &quot;abc&quot;, t = &quot;ahbgdc&quot;Output: true 动态转移方程： 12dp[i] = (t[i] == s[dp[i-1]] ? dp[i-1]+1 : dp[i-1]);// dp[i] 表示t的第i位已匹配至s的dp[i]位 经典dp 0-1背包给你一个可装载重量为W的背包和N个物品，每个物品有重量和价值两个属性。其中第i个物品的重量为wt[i]，价值为val[i]，现在让你用这个背包装物品，最多能装的价值是多少？ 123N = 3, W = 4wt = [2, 1, 3]val = [4, 2, 3] dp[i][w] 的定义如下：对于容量为w的背包，装前i个物品，可以装的最大价值。 ① 若第i个物品的wt[i] &gt; w，那么一定不会拿取。则容量为w的包装前i个物品可得到的价值则为容量为w的包装前i-1个物品可得到的价值，即dp[i][w] = dp[i-1][w]。 ② 若第i个物品的wt[i] &lt;= w，那么则有以下两种情况 ​ a.不拿。容量为w的包装前i个物品可得到的值则为容量为w的包装前i-1个物品可得到的价值，即dp[i][w] = dp[i-1][w]。 ​ b.拿走。容量为w的包装前i个物品可得到的值则为容量为w-wt[i]的包装前i-1个物品可得到的价值+第i项物品的价值，即 dp[i][w] = dp[i - 1][w - wt[i-1]] + val[i-1]。 二者取最优解即可。 123456789101112131415161718int knapsack(int W, int N, vector&lt;int&gt;&amp; wt, vector&lt;int&gt;&amp; val) { // vector 全填入 0，base case 已初始化 vector&lt;vector&lt;int&gt;&gt; dp(N + 1, vector&lt;int&gt;(W + 1, 0)); for (int i = 1; i &lt;= N; i++) { for (int w = 1; w &lt;= W; w++) { if (w - wt[i-1] &lt; 0) { // 当前背包容量装不下，只能选择不装入背包 dp[i][w] = dp[i - 1][w]; } else { // 装入或者不装入背包，择优 dp[i][w] = max(dp[i - 1][w - wt[i-1]] + val[i-1], dp[i - 1][w]); } } } return dp[N][W];} P1048 采药","link":"/2021/07/06/data-structure-algorithms/2021-07-06-fragmentary-knowledge/"},{"title":"[da] graph-theory algorithm template","text":"Step 1. 建图 + DFS/BFSP5318 【深基18.例3】查找文献 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;bits/stdc++.h&gt;using namespace std;const int maxn = 100000 + 5;struct Edge{ int to, nxt;} e[maxn * 10];int head[maxn], tot, vst[maxn];vector&lt;pair&lt;int, int&gt; &gt; tmp;bool cmp(pair&lt;int, int&gt; x, pair&lt;int, int&gt; y){ //排序规则 if(x.first == y.first) //v相同按u排序 return x.second &gt; y.second; else return x.first &gt; y.first; //否则按v从大到小排序}void add(int u, int v){ e[++tot].to = v; e[tot].nxt = head[u]; head[u] = tot;}void bfs(int rt){ queue&lt;int&gt; q; q.push(rt); vst[rt] = 1; while (!q.empty()){ int u = q.front(); cout &lt;&lt; u &lt;&lt; &quot; &quot;; for (int i = head[u]; i != -1; i = e[i].nxt) { int v = e[i].to; if (!vst[v]){ q.push(v); vst[v] = 1; } } q.pop(); }}void dfs(int rt){ cout &lt;&lt; rt &lt;&lt; &quot; &quot;; vst[rt] = 1; for (int i = head[rt]; i != -1; i = e[i].nxt) { int v = e[i].to; if (!vst[v]){ //vst[v] = 1; dfs(v); } }}int main() { //freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin); ios::sync_with_stdio(false); memset(head, -1, sizeof(head)); int m, n; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; m; ++i){ int u, v; cin &gt;&gt; u &gt;&gt; v; tmp.push_back(make_pair(u, v)); } sort(tmp.begin(), tmp.end(), cmp); for (int i = 0; i &lt; m; ++i) { add(tmp[i].first, tmp[i].second); } dfs(1); cout &lt;&lt; endl; memset(vst, 0, sizeof(vst)); bfs(1); return 0;} Step 2. 建图 + 拓扑排序P4017 最大食物链计数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;bits/stdc++.h&gt;using namespace std;const int maxn = 5005;const int mod = 80112002;struct Edge{ int to, nxt;}e[maxn*100];int head[maxn], tot, ans, indegree[maxn], cnt[maxn];void add(int u, int v){ e[++tot].to = v; e[tot].nxt = head[u]; head[u] = tot;}void topo_sort(int n){ queue&lt;int&gt; q; for (int i = 1; i &lt;= n; ++i) { if (indegree[i] == 0) { q.push(i); cnt[i] = 1; } } while (!q.empty()){ int u = q.front(); q.pop(); if (head[u] == -1) ans = (ans + cnt[u]) % mod; for (int i = head[u]; i != -1; i = e[i].nxt) { int v = e[i].to; cnt[v] = (cnt[v] + cnt[u]) % mod; indegree[v]--; if (indegree[v] == 0){ q.push(v); } } }}int main() { //freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin); ios::sync_with_stdio(false); memset(head, -1, sizeof(head)); int n, m, u, v; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; m; ++i){ cin &gt;&gt; u &gt;&gt; v; add(u, v); indegree[v]++; } topo_sort(n); cout &lt;&lt; ans &lt;&lt; endl; return 0;}","link":"/2021/07/06/data-structure-algorithms/2021-07-06-graph-theory-algorithm-template/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/04/09/hello/hello-world/"},{"title":"","text":"1. 命名 Type Public Internal Modules lower_with_under _lower_with_under Packages lower_with_under Classes CapWords _CapWords Exceptions CapWords Functions lower_with_under() _lower_with_under Global/Class Constants CAPS_WITH_UNDER _CAPS_WITH_UNDER Global/Class Variables lower_with_under _lower_with_under Instance Variables lower_with_under _lower_with_under Method Names lower_with_under() _lower_with_under Function/Method Paramters lower_with_under Local Variables lower_with_under 2. 函数长度一般不超过 40 行 3. 行长度一般不超过 80 个字符 4. 注释4.1 文档字符串包、类、模块或者函数的第一句话，一般使用三重引号包裹，对于只有一行的注释来说，尾部引号应该在同一行。对于多行注释一般按如下方式组织：首先是一行以句号，问号或惊叹号结尾的概述。接着是一个空行，然后是文档字符串剩下的部分，它应该与文档字符串的第一行的第一个引号对齐。 123456789&quot;&quot;&quot;A one line summary of the module or program, terminated by a period.Leave one blank line. The rest of this docstring should contain anoverall description of the module or program. Optionally, it may alsocontain a brief description of exported classes and functions and/or usageexamples.Typical usage example:foo= CLa55Foo()bar = foo.FunctionBar()&quot;&quot;&quot; 4.2 块注释或行注释对于复杂的操作，应该在其操作开始前写上若干行注释。对于不是一目了然的代码，应在其行尾添加注释。 123456# We use a weighted dictionary search to find out where i is in# the array. We extrapolate position based on the largest num# in the array and the array size and then do binary search to# get the exact numberif i &amp; (i-1) == 0: # True if i is 0 or a power of 2. 为了提高可读性，注释应该至少离开代码 2 个空格。 5. 空行顶级定义之间空两行，比如函数或者类定义。方法定义，类定义与第一个方法之间，都应该空一行。函数或方法中，某些地方要是你觉得合适，就空行。","link":"/2023/04/09/lab-experience/code-style/"},{"title":"","text":"ssh连接：finalshell+指令操作？ 公钥登录。 添加公钥，这一段是写给在服务器上已经有账号的。反之，cd home+mkdir 用户名。 拿到新的公钥，并且创建新的账号的文件夹底下 shell) 先查看文件夹下是否存在.ssh文件夹 否则运行sudo mkdir ./.ssh 然后将公钥id_rsa.pub上传到对应的账户的.ssh文件夹下，并且改名为authorized_keys 用 sudo chown 用户名 authorized_keys 修改公钥的所有人 用 sudo chmod 600 authorized_keys 给公钥添加运行权限 Vim：Bundle，Nerdtree，TagBar，jedi-python jupyterlab的关闭：ps -ef|grep jupyter|awk {‘print $2’}|xargs kill svn操作：权限修改，文件夹创建 frp账号密码：nomad + nomad123 jupyter密码：Lab504jupyter sudo操作：ub-d504 + lab504ubd tail nohup.out：在当前路径生成一个nohup.out 查看进程：top htop ps -ef grep pstree 2号服切换到asus账户： ​ su asus + D504y2021 ​ ssh ub-d504@192.169.0.200 然后可以通过该方式，ssh到1号服 从1号服copy文件到2号服使用scp linux基本操作 服务器上传下载文件：scp 公钥与私钥：公钥加密，私钥解密。私钥签名，公钥验证。 SSH对于公钥和私钥的用法：https://blog.csdn.net/qq_34649947/article/details/80140465 https://blog.csdn.net/csm201314/article/details/78453579 终端：人与机器交互的接口。终端具有两个基本功能：向主机输入信息和向外部输出信息。所以终端可以分为输入设备和输出设备。 ssh：Secure Shell（安全外壳协议），为建立在应用层基础上的可靠，专为远程登录会话和其他网络服务提供安全性的协议。运用如finalshell。 端口：客户端可以通过ip地址找到对应的服务器端，但是服务器端是有很多端口的，每个应用程序对应一个端口号，通过端口号，客户端才能真正的访问到该服务器。 定时器：keep alive保活机制？ 防火墙：就是专门给服务器提供防御、保障数据安全的防火墙。 frp，svn，jupyter维护：http://39.107.92.9:5636/dokuwiki/doku.php?id=term_script sz：从Linux下载文件到本机 , 在Linux终端输入命令回车后，选择本地存储路径即可。 123命令格式： sz filename 下载文件filename sz file1 file2 下载多个文件 sz dir/* 下载dir目录下所有文件 rz：从本地上传文件到Linux，在Linux终端输入命令回车后，选择本地要上传的文件即可，可一次指定多个文件 scp：Linux scp 命令用于 Linux 之间复制文件和目录 https://www.runoob.com/linux/linux-comm-scp.html 123456789scp，sz，rz nc # Netcat (网络刀)，端口扫描，远程拷贝等等 # https://blog.csdn.net/freeking101/article/details/53289198vimcat # 查看文件内容grep # grep jupyter对于输入进来的内容，按行查找包含“jupyter”的内容并输出ps -ef # ps查看进程 -e代表显示所有进程 -f代表全格式kill nohup {} &amp; # 使后台运行，运行日志输出到当前目录的nohup.out 关注服务器状态的指令：htop + nvidia-smi nvidia-smi：显示GPU当前的状态。训练的时候，可以用这条指令每隔1秒看一下显卡状态：watch -n 1 ‘nvidia-smi’ htop：是Linux系统中的一个互动的进程查看器 vscode关闭文件夹：[Ctrl + K F] 串口调试 arm相机的包 开学两周突破 tail nohup.out：在当前路径生成一个nohup.out top htop ps -ef grep pstree：查看进程 scp -r /root/lk root@43.224.34.73:/home/lk/cpfile：Linux 之间拷贝Secure Copy nautilus /file：终端打开文件 操作服务器时遇到的问题鼠标不见了/卡死？ctrl+alt+f1 回到登陆界面，重新登录。 终端如何粘贴？ctrl+shift+v。 找不到home？点开文件界面，左侧最下栏。","link":"/2023/04/09/lab-experience/lab-notes/"},{"title":"","text":"服务器基本操作服务器上的服务 一号服 二号服 frpc frpc dokuwiki jupyterlab svn frpc服务位置： /home/chensiji/ （如果是服务器2位置是/home/asus） 1.开启服务指令：nohup ./frpc -c frpc.ini &amp; *如果显示无法执行该指令，可以在开头加个sudo 解释： ./ 执行 frpc 可执行文件frpc -c 使用配置文件 frpc.ini 配置文件名称 nohup {} &amp; 使后台运行，运行日志输出到当前目录的nohup.out 2.查看配置文件：cat frpc.ini 会显示类似如下的内容： [common] server_addr = 39.107.92.9 server_port = 7000 [ssh] type = tcp local_ip = 192.169.0.200 local_port = 22 … 3.关闭进程： 首先用如下指令查看当前正在运行的进程号： ps -ef|grep frp 上图中显示的11665、11666那一列的数字为进程的进程号。根据进程号我们可以关闭相应的进程。 正常关闭：sudo kill &lt;进程号&gt; 强制关闭: sudo kill -9 &lt;进程号&gt; 在将上述所有进程都’kill’后，可以发现众多服务的网络连接都失效了（grep那个进程不用’kill’，查询过程本身就是个进程）： 之后需要用开启服务的指令开启这部分服务(见1) dokuwiki不用维护，开机就有 jupyterlab需要先切换到用户ub-d504，因为之前的文件都在这个用户下开启的，用别的用户在同样位置启动jupyter lab可能会导致权限访问问题切换用户： su ub-d504（用户名） *密码可以询问有关负责人 需要先进入conda环境，才能使用指令，因为我们的jupyter是安装conda时附带的服务*具体可见conda部分 1.启动指令 nohup jupyter lab &amp; 要让jupyter lab在后台运行，否则退出直连连接后jupyter lab的服务也失效。 2.关闭进程 ps -ef|grep jupyter|awk {‘print $2’}|xargs kill 解释： 管道符号，将前者的输出作为后者的输入 grep jupyter 对于输入进来的内容，按行查找包含”jupyter”的内容并输出 awk {‘print $2’} 把输入按空格分开成多项，打印第二项 xargs 把前面的输入作为后面命令的参数 kill 直接根据进程号关闭进程 svn位置 /srv/svn_repo/Lab 1.启动指令 sudo svnserve -d -r /srv/svn_repo –listen-port 3501 -d: 已守护模式启动 -r：指定svn版本库根目录，这样是便于客户端不用输入全路径就可以访问版本库 2.停止服务 ps -ef|grep svn 查询进程号 kill &lt;进程号&gt;","link":"/2023/04/09/lab-experience/server-operation/"},{"title":"","text":"Q-learning 为什么不用重要性采样？Q-learning 是单步更新的，target是直接获得的，而不是根据策略接下来得到的。反之，TD(2)及以上就需要重要性采样。 softmax 溢出问题：e的10000次方，pytorch的源码怎么处理的？数列所有数减去数列的最大值，这样和减之前一模一样的。","link":"/2023/04/09/lab-experience/rl-notes/"},{"title":"","text":"YouCompleteMe 安装github 项目地址：https://github.com/ycm-core/YouCompleteMe 该项目有子模块，github 被墙的情况下很难克隆。我 ssh 连接导实验室的无人机为之 vim 配置该插件，不是很懂怎么命令行翻墙。因此，我是本地电脑翻墙克隆后，再输入如下指令克隆它的子模块。 1git submodule update --init --recursive 针对 github 被墙，可用工具：dev-sidecar，pigcha。 克隆了子模块后，上传至 onedrive，并获取下载链接。在 linux 终端输入如下指令下载： 1wget -c &lt;url&gt; -O &lt;/path/name&gt; 解压 zip 1unzip &lt;filename&gt; 按教程安装依赖包：https://github.com/ycm-core/YouCompleteMe#linux-64-bit 在 .vimrc 中加入 ycm-core/YouCompleteMe 后，编译 YCM。 1234cd ~/.vim/bundle/YouCompleteMepython3 install.py --all(所有语言语法检查) or python3 install.py --clangd-completer(C系列语言语法检查) or python3 install.py (没有语法检查) 可能出现的问题： Your C++ compiler does NOT fully support C++17 解决：https://stackoverflow.com/questions/65284572/your-c-compiler-does-not-fully-support-c17 下载 clangd：https://www.cnblogs.com/zi-wang/p/13550305.html 编译生成 ycm_core，https://github.com/ycm-core/YouCompleteMe/wiki/Full-Installation-Guide 注意：更新 Vim 至 8.1 先克隆 8.1.2424 版本的 vim 1git clone -b &lt;tag&gt; url 按照如下教程配置：https://github.com/ycm-core/YouCompleteMe/wiki/Building-Vim-from-source 查看版本 1vim --version |grep VIM 查看是否支持 python3 1vim --version |grep python","link":"/2023/04/09/lab-experience/youcompleteme-installation/"},{"title":"[ml][rv] domain adaptation","text":"27 Domain Adaptation训练资料跟测试资料的分布是不一样的，叫做 ==Domain Shift==。 解决办法是 ==Domain Adaptation==，它也可以看做是 ==Transfer Learning== 的一种。 Transfer Learning ：在 A 任务上学到的技能可以被用在 B 任务上 Domain Adaptation：你的训练资料是一个 Domain，你的测试资料是另外一个 Domain，你在训练资料上面学到的资讯可以要把它用到另外一个 Domain 上。 Domain Shift两者可能情况。一，输入资料即训练集和测试集的分布不同。二，输入跟输出虽然分布相同的，但它们之间的关係变了，比如训练集叫做 0 的东西在测试集里叫做 1。 今天只考虑前者。记测试集为 ==Target Domain==，训练集为 ==Source Domain==。 Domain Adaptation分三种情况考虑： 其一，在 Target Domain 上有一大堆的资料且配有 Label，那就直接拿 Target Domain 的资料来训练。 其二，在 Target Domain 上有一点点的资料且配有 Label，那就拿他们来微调，即不要在 Target Domain 上的资料上跑太多的 Iteration。 其三，在 Target Domain 上有一大堆的资料但没有 Label。找个 Feature Extractor，它会把 Source 和 Target 不一样的部分拿掉，只抽取出它们共同的部分。 其四，在 Target Domain 上有一点点的资料且没有 Label。有一个方法叫做 ==Testing Time Training==,它的缩写是 TTT。 Domain Adversarial Training怎麼找出这样的一个 Feature Extractor 呢？那其实我们可以把一个一般的 Classifier 分成 Feature Extractor 跟 Label Predictor 。 Domain Adaptation 的一种方法 ==Domain Adversarial Training== 训练 Feature Extractor：让 Source Domain 的图片得到的 Feature，跟 Target Domain 的分不出差异。 训练 Domain Classifier：二元分类器，区分这个 feature 是来自於 Source Domain,还是来自於 Target Domain。 Domain Adversarial Training 很像是 GAN。可以把 Feature Extractor 想成是 Generator，把 Domain Classifier 想成是 Discriminator。 Generator 好像优势太大了，它只要都输出 0 不就无法区分了吗？不行，都输出 0 虽然 Domain Classifier 无法区分，但 Label Predictor 也无法区分！ 接下来考虑参数优化。Label Predictor 要做的事情就是让这个 Source Domain 的 Image 分类越正确越好，即最小化 Loss（交叉熵，分类问题有交叉熵）。Domain Classifier 要做的事情就是让 Domain 的分类越正确越好，也是最小化交叉熵。 Feature Extractor 要做的事情是，它又要保证能让 Label Predictor 有个好结果，又要骗过 Domain Classifier，故把 loss 设为 $L-L_d$。 Limitation刚才这整套想法有一个小小的问题 直觉上讲右边更好，所以我们是不是应该要让右边的状况发生呢？怎么做呢？也许一个可能的想法：我们既然知道分界点在哪裡，那我们应该要让这些方形远离这一个分界点。 Considering Decision Boundary什麼叫做离 Boundary 越远越好呢？如果今天输出的结果非常地集中，即 Entropy 小，叫做离 Boundary 远。反之则近。 到目前為止都假设说，Source Domain 跟 Target Domain，它的类别都要是一模一样。但是真的一定会这样吗？ 实线的圈圈代表，Source Domain 裡面有的东西，这个虚实线的圈圈代表 Target Domain 裡面有的东西。所以在这个前提之下，你说你要让 Source Domain 的 Data 跟 Target Domain 的 Data，它们的 Feature 完全 Match 在一起，那意味著说，你硬是要让老虎去变得跟狗像，到时候你就分不出老虎这个类别了。 Domain Generalization但其实还有一个更严峻的状况，如果我们对 Target Domain 一无所知的话怎麼办呢？这种情况通常就叫 ==Domain Generalization==。 我们期待机器在 Testing 的时候，不管来什麼样的 Domain，它都可以处理。 Domain Generalization 又分成两种状况：其一，训练资料本来就包含了各式各样不同的 Domain 的数据；其二，训练资料只有一个 Domain，做 Data Augmentation。","link":"/2022/07/06/machine-learning/2022-07-06-review-domain-adaptation/"},{"title":"[rv] reinforcement learning","text":"Reinforcement Learning P1 ：BasicsSupervised Learning→RLSupervised Learning：给定 label Self Supervised Learning：自动生成 label Unsupervised Learning(Auto-encoder)：没用到人类的 label，但事实上仍然还有 label 只不过不需要用人力生成 RL：机器当我们给它一个输入的时候，我们不知道最佳的输出（label）应该是什么。如下棋。 Outline Machine Learning ≈ Looking for a Function机器学习就是找一个 Function，Reinforcement Learning 也是，这个 Function 即 Actor 本身，要做的就是最大化 reward 之总和。 例：Atari Space Invador。Actor：操作对象。环境：游戏场景。Observation：游戏画面。 例：围棋。稀疏 Reward，只有游戏结束（输、赢）才能够拿到 Reward。 Machine Learning is so simple ……Machine Learning 三个步骤： 定义含待求未知数的 Function 定义 Loss Function Optimization，minimize loss 而 RL 其实也是一模一样的三个步骤 Step 1: Function with UnknownFunction (in RL) = Actor, RL 中的 Actor 即神经网络，通称 Policy 的 Network。 神经网络输入：the observation of machine represented as a vector or a matrix。 神经网络输出：each action corresponds to a neuron in output layer。 为什么输出结果是概率分布？引入随机性。 Step 2: Define “Loss”从游戏开始到结束的这整个过程被称之为一个 ==Episode==, 将整个游戏的过程中 Actor 採取非常多的行为得到的 Reward 通通集合起来便是 ==Total Reward (Return)==。$R = \\sum^{T}_{t=1}r_t$ 。 Return 是最大化的对象，我们要最小化 loss，可以定义 loss = -R。 Step 3: Optimization将整个游戏的过程中 s 跟 a 所形成的这个 Sequence 叫做 Trajectory。符号表示为 $\\tau = {s_1, a_1,s_2,a_2,…}$。 通常说，Reward Function 在定义的时候和 Action 与 Observation 都有关联。即 $r_i$ 和 $s_i$ 和 $a_i$ 有关系。优化 Return 就行。 但是 RL 困难之处在于它不是一个一般的 Optimization 的问题。 第一个问题是，Actor 的输出是有随机性的。 Network 裡面的某一个 Layer 每次产生出来结果是不一样的。第二，Environment 只是一个黑盒，且包含随机性。 与 GAN 的对比。 相同：GAN 中 调整 Generator 的参数让 Discriminator 的输出越大越好。RL 中调整 ACtor 的参数让 Environment 的 Reward 越大越好。 不同：Discriminator 是 Network，但 Environment 只是个黑盒。不能用 GD 调整 Environment。 Policy GradientHow to control your actor 可以把它想成一个分类的问题。即 s 是 Actor 的输入, $\\hat{a}$(Ground Truth) 就是 Label。 计算 Actor 的输出跟 Ground Truth 之间的 Cross-entropy，那接下来就可以定义一个 Loss。提示：根据交叉熵的定义，预测分布和真实分布有相同的分布时交叉熵最小。Loss 越小，就等价于预测值越接近真实值。 模型训练 用数值 A 表示代替 +1/-1，就可以实现表示动作的好坏程度。Loss 改写为：$$L=\\sum A_ne_n$$ Value FunctionVersion 0用随机的 Actor 去跟环境做互动收集训练资料获得 ${s_i, a_i}$。再根据情况好坏为之赋予 $r_i$。 最简单的但不正确的版本。短视近利。事实上，每一个行为都会影响到接下来发生的事情。例：Space Invador 中，由于只有开火才能得到正 Reward，故他会一直开火。 Reward Delay：牺牲短期的利益,以换取更长程的目标。 Version 1==Cumulated Reward==：把当下与未来所有的 Reward 加起来评估一个 Action 的好坏。$$G_t = \\sum^{N}_{n=t} r_n$$用 $G_i$ 表示每个 ${s_i, a_i}$ 对应的 reward。 问题在于：未来发生的影响中，有些影响大有些影响小。 Version 2加上递减权重 $\\gamma$。未来的 reward 中，离当下近的表示影响更大。$$G’t = \\sum^{N}{n=t} \\gamma^{n-t}r_n$$ Version 3做标准化，因为好或坏是相对的。 一个最简单的方法就是：把所有的 G’ 都减掉一个 b，即==Baseline==。 Policy Gradient 其中，$L = \\sum A_n e_n$。$A_n$ 就是 Reward，$e_n$ 就是交叉熵。 一般的 Training，Data Collection 都是在 For 循环之外。但在 RL 裡面收集资料是在 For 循环裡面。这意味着更新一次参数以后，就要重新收集资料，因此 RL 的训练过程非常花时间。 为什么不把 Data Collection 放在 For 循环之外？彼之砒霜，吾之蜜糖。因为由 $θ_{i-1}$ 所收集出来的资料不一定适合拿来 Update $θ_{i}$ 的参数。 故同一个 Action 同一个行为，对于不同的 Actor 而言，它的好是不一样的。更新后的 Actor，可能 Trajectory 就会跟之前出现区别。 On-policy v.s. Off-policy被训练的 Actor 与跟环境互动的 Actor 是同一个叫做 ==On-policy Learning==。 反之，为 ==Off-policy Learning==。 Off-policy 的好处：不用一直收集资料。可以收一次资料，就 Update 参数很多次。 显然上文所述为 On-policy Learning。 Off-policy → Proximal Policy Optimization(PPO)Off-policy 的经典算法： Proximal Policy Optimization。 Off-policy 的重点：在训练的那个 Network，要知道自己跟别人之间的差距，它要有意识到它跟环境互动的那个 Actor 是不一样的。 例子：东施效颦，别瞎模仿。 Collection Training Data: ExplorationExploration：Actor 在採取行为的时候有随机性的。随机性大一点意味着能够收集到比较丰富的资料。实现方法：增大 Actor 的 Output（Distribution）的 Entropy；在 Actor 参数上加 Noise。 CriticCritic 用以评估一个 Actor 的好坏。Given actor 𝜃, how good it is when observing 𝑠 (and taking action 𝑎)。 本课程中 Critic 叫做 ==Value Function==，用 $V^θ(s)$ 来表示。输出一个 scalar（Discounted Cumulated Reward）。 故 Value Function 的作用就是：对某一个参数为 $\\theta$ 的 Actor 来说，如果它已经看到某一个游戏画面 s，那接下来会得到的 Discounted Cumulated Reward 应该是多少。 DCR 需要未来的 Reward 来计算。但当下怎么知道未来的 Reward 呢？Value Function 的能力就是要未卜先知。 How to estimate $ V^θ(s) $Monte-Carlo (MC) based approachMC：把 Actor 拿去跟环境互动很多轮，可以得到每轮的 DCR。 那么 Value Function 就得到一笔训练资料，训练目标是：如果看到 $s_a$ 作为输入，那它的输出 $ V^θ(s_a) $ 应该要跟 G’a 越接近越好。 Temporal-difference (TD) approach一轮互动可能无法终止或者很长。 TD：不用玩完整场游戏，才能得到训练 Value 的资料。虽然我们不知道，$ V^θ(s_t)$ 和 $ V^θ(s_{t+1})$ 应该是什么，但是我们可以让 $ V^θ(s_t)$ 与 $ \\gamma V^θ(s_{t+1})$ 的差值逼近已知的 $r_t$。 MC v.s. TD Version 3.5把 baseline 设成 $V^θ(S)$。把 ${s_t,a_t}$ 对应的 Value 定义为：$$A_t = G’_t-V^θ(s_t)$$为什么这样可以？我们知道 $ V^θ(s_t)$是看到某一个画面 $s_t$ 以后，接下来会得到的 (加权) Reward。它其实是一个期望，因为有随机性，即每次的 $a_t$ 可能不同，故每次可能会得到不一样的 Reward。 图中 Gt’ 是 sample 某一个 trajectory 的结果，而$ V^θ(s_t)$ 是很多条路径平均以后的结果。 问题在于：把一个 sample 去减掉平均，这样会准吗？也许这个sample 特别好或特别坏。为什麽不是拿平均去减掉平均？ Version 4最后一个版本：平均去减掉平均。这就是 ==Advantage Actor-Critic==。 把 ${s_t,a_t}$ 对应的 Value 定义为：$$A_t = r_t+V^θ(s_{t+1})-V^θ(s_t)$$ Tip of Actor-CriticActor 和 Critic 都是 Network，他们的输入可以公用 CNN。 Sparse RewardSparse Reward：$r_t$ = 0 in most cases。例如拧螺丝。 解决办法：reward shaping。 Imitation LearningActor 可以与环境互动，但 reward function 不知道怎么定义。 解决办法：根据专家的演示 ${\\hat{\\tau_1}, \\hat{\\tau_2}, …}$ 进行模仿学习。 例子：自动驾驶，机械臂抓举。 问题：专家们只对有限的观察进行抽样。 Inverse Reinforcement Learning使用 reward function 找到最佳 actor。 原则：The teacher is always the best。 方法论： 和 GAN 的类比理解 GAN 中 Generator 的优化目标是产生跟 Ground Truth 的很像的结果，IRL 中 Actor 的优化目标是产生跟 Expert 的很像的结果。 GAN 中 Discriminator 的优化目标是产生分辨 Ground Truth 和 Generator 的输出值，给 Ground Truth 打高分，IRL 中 Reward 则是给 Expert 打高分。","link":"/2022/07/06/machine-learning/2022-07-06-review-reinforcement-learning/"},{"title":"[ml][rv] sysu-courses","text":"1. 线性回归 + 逻辑回归 TIPS：什么是线性回归逻辑回归，损失函数有可能带正则项，为什么要加正则项因为要防止过拟合，损失函数要怎么定义，梯度下降好处有什么坏处有什么，最优参数表达式怎么写的 损失函数 最优参数表达式 损失函数带正则项的原因（补）：防止过拟合。[防止过拟合的另一种方法：k-fold交叉验证] 定义（补）： 回归模型 线性模型： 对于上式，假设b=0，则易得： 矩阵形式可以写作为： 显然，我们的目的就是求位置参数 theta，如何求解？构造最大似然估计（maximum likelihood estimator，MLE），找到 theta 使得似然概率最大。 最大似然估计的合理性在于这样一个假设：既然能出现这样一个数据分布，那么可以假设在当前的 theta 情况下，出现该数据分布的概率是很大的。因此可以进行最大似然估计。 最大似然的求解可以有两种：分析法，即令微分=0；迭代法，即（随机）梯度下降。 基于独立同分布的假设，n 个数据点的概率可以表示为： 问：为什么这里的 p(x_i) 可以表示成1？ 问题转化为： 为简便计算，一般求对数 MLE： 第一项对于 theta 而言是常数项，省去，故最终优化目标为： 等价于： 如何通过梯度下降求解参数： 为保证对数似然是凸的，求二阶导（Hessian）矩阵： 如果 X 是满秩的，那么 XX 就是正定的，因此 theta_{MLE} = minimum。用正则化处理退化情况 令梯度为 0，解得： 据此可以利用一些矩阵方式求解，方法有 Cholesky Factorization 等。 抑或是梯度下降求解 theta_{MLE}（rho 是学习率）： 其中，对数似然求微分得到的系数 2 被并入 rho。 更好的办法——随机梯度下降： 在非线性的情况，可以采用非线性变换，如 splines, radial basis functions 等。 逻辑回归 要知道的就是 w，对于 w 的取值，我们可以令： $$\\omega = argmax_{\\omega} \\prod_{l} P(y^l|x^l,w)$$ 其中，$$y^l$$ 和 $$x^l$$ 取之于训练集。上式写作 log-likelihood： 根据 y 只能取 0 或 1 的性质，把 argmax 右边的 sum 写作下式： 写出 loss 方程，直接开导！ 梯度下降： 加入正则化，防止过拟合的版本： 2. 过拟合什么是过拟合 Low training error does not imply good expected performance 降低过拟合的方法 Reduce number of features + Keep all the features, but reduce values of parameters ① 损失函数加入正则项 ② k-fold交叉验证 3. 训练方法 什么是过拟合、欠拟合，过拟合：训练集损失函数误差小，测试集大。怎么避免过拟合？加入正则项，使他训练集没那么好，增加模型的延展性；k-折交叉验证的k什么意思，分数据集怎么分，可以随机也可以不随机 一个衡量模型好坏的指标： 训练集-矫正集-测试集 使用验证集是为了快速调参，(网络层数，网络节点数，迭代次数，学习率）。另外用验证集还可以监控模型是否异常（过拟合），然后决定是不是要提前停止训练。 留出法（Hold-out method） 把数据集分此训练集(2/3)和测试集(1/3)，经常使用的情况：有几千个示例，每个类有几百个实例。 更大的测试集可以得到更精确的错误率估计。 有时有些类的实例很少，此时就要用 Stratified (分层) sample，确保每个类在训练测试集中的比例大致相等，这可以减少模型方差。 Repeated hold-out method 在每次迭代中，随机选择一定比例数据进行训练（可能分层）。对不同迭代的错误率进行平均，以得出总体错误率。 仍不是最佳：不同的测试集重叠，但我们希望每个数据都被至少测试一次。 k-fold cross validation ① 数据分成 k 等分个子集。② 每次选 k 份中未选择过的一份当测试集，其他训练集。 每个子集在交叉验证就分层过了。总 estimate 就是各次 estimate 的平均。 k-fold cross validation with validation and test sets 这是个稍微不那么精细的方法 ① 数据分成 k 等分个子集。② 每次选 k 份中未选择过的一份当测试集，剩余的选个当验证集，其他就是训练集。 最优的 k：10，实验证明可以得到最精确的 estimate。 Bootstrap method 我们随机地从数据集中抽取出 n 个数据组成一个新的数据集（允许重复）。 由于只在 63% 的数据集上训练，因此测试集上的 error estimate 不太好，故联合训练集上的 error： 重复以上过程多次，平均结果。 总结： hold-out method：large data cross-validation method： middle-sized data leave-one-out and bootstrap method：small data 4. 决策树 决策树做分类的监督学习算法，熵的定义 熵的求解 $$log(p_i)$$ 定义为信息量。 条件熵的求解 求解对应属性的信息增益 决策树的构建 预剪枝，后剪枝 5. SVM 标准的SVM是个线性的分类器，基本思想：找出一个分界面，让分界面离正负样本的距离最大，不需要背答对了大概意思就行，损失函数怎么定义，不需要会求解，为什么引入核函数，有什么功能 SVM 的基本思想 找出一个分界面，让分界面（margin）离正负样本（support vector）的距离最大 点到直线的距离： SVM 的损失函数 Hinge 损失函数 $$L(y, f(x)) = [1-yf(x)]+ \\z+=\\begin{cases}z,z \\ge 0 \\0,z \\le 0\\end{cases}$$ SVM 的优化目标 $$最小化：\\frac{1}{2}||w||^2 + C\\sum^{N}_{i=1}\\delta_i\\ \\限制条件： (1)\\ \\delta_i&gt;=0,(i=1-N)\\(2)\\ y_i(w^TX_i+b) &gt;= 1-\\delta_i,(i=1-N)$$ SVM 的损失函数 $$\\frac{1}{2}||w||^2+C\\sum^{N}_{i=1}max(0, 1-y_i(wx_i+b))$$ 提出公因子 C，等价于 $$\\frac{1}{2C}||w||^2+\\sum^{N}_{i=1}max(0, 1-y_i(wx_i+b))$$ 参考：https://blog.csdn.net/guofei_fly/article/details/102750900 SVM 中的核函数 高维非线性计算资源消耗大，故映射到线性低维。 根据对 SVM 优化问题的观察，可以得知数据点只以点积的形式出现： 因此，无需考虑具体的映射 phi 函数的形式，只需要考虑核函数： 举例而言： 要求核函数满足 Mercer function，即要求正定（对于nxn的矩阵，entry[i,j]=K(xi,xj)）。 基本的核函数： 6. PCA PCA基本思想：降维，把最关键的维度找出来。PCA无监督的。 PCA三种理解的角度：通过重构误差最小推出PCA的定义公式；通过方差最大的思想推出PCA；通过奇异值分解的方法推出PCA。 PCA有进行一些假设约束，如两两方向之间正交。推导过程要知道，比如PCA重构误差的推导。PCA有什么缺点：要求方向正交，而这不一定是合理的。 PCA 的基本思想 降维，把最关键的维度找出来，以代表大部分的信息。 PCA 的三种理解角度：最小重构误差 正交的概念： 正交定理（举个例子就能理解，$$\\alpha_{i}$$ 类似投影长度）： 当前的目标，就是找到这几个正交向量，以最好 地表示原数据。 PCA(主成分分析)所对应的数学理论是 SVD。而奇异值分解本身是完全不需要对矩阵中的元素做标准化或者去中心化的。但是对于机器学习，我们通常会对矩阵（也就是数据）的每一列先进行标准化。 Frobenius norm $$||X||{F} = \\sqrt{\\sum{i} \\sum_j X_{i,j}^2}$$ PCA 的三种理解角度：最大化方差 最大化方差等价于尽可能多地保留原始数据的信息。 以其中一个投影坐标方向 $$u_1$$ 为例，求其方差表达式： 类似前文所述，要使的 var 最大，等价于让 $$u_1$$ 是 S 的那个最大特征值的特征向量。 PCA 的三种理解角度：SVD 分解 7. 聚类 k是什么？k个聚类。初始选取的k个点可以是随机的也可以是自己定义的。kmeans为什么可以收敛？可以通过实验的方法来了解k的选取。不同的初始状态会导致不同的结果。 K-Means 聚类的思想 在数据集中根据一定策略选择K个点作为每个簇的初始中心，然后将数据划分到距离这K个点最近的簇中，但形成的新簇并不一定是最好的划分，因此生成的新簇中，重新计算每个簇的中心点，然后在重新进行划分，直到每次划分的结果保持不变。 K-Means 聚类的步骤 ① Ask user how many clusters they’d like. ② Randomly guess k cluster Center locations ③ Each datapoint finds out which Center it’s closest to. ④ Each Center finds the centroid of the points it owns ⑤ Jumps to ③，Repeat until terminated! K-Means 聚类的目标函数 $$Encode(x_i)$$ 可以理解为把数据点 $$x_i$$ 归到第几个聚类，$$Decode[j]$$ 可以理解为把第 j 个聚类的中心 $$c_j$$。 要最小化 Distortion。① 这就要求 $$x_i$$ 必须被归到离他最近的聚类。② 同时，还要求对 $$c_j$$ 对 Distortion 的偏微分都为 0： 满足 minimum 的情况，也就是满足 $$c_j$$ 是该聚类中的点的均值的情况。 ① 和 ② 连续操作没意义，但是交替操作就很有意义，这即是 K-means。为什么可以收敛呢？ 有限个点分到有限个聚类里，这样配置/聚类的可能情况是有限的。同时，当配置改变，意味着得到了更好的 Distortion。每次改变都是更好的配置，如果一直改变，迟早会用光所有的配置。 不一定能全局最优。因此，谨记：选好初始值，或者跑多次不一样的k-means。 对选好初始值的一种可行方案：首先随便选个数据点做聚类中心，之后选的聚类中心尽可能选离所有已选聚类中心远的数据点。 K-Means 聚类的 K 的选取 常规方法：最小化 Schwarz Criterion (also related to the BIC, schwarz’s bayesian criterion (bic)) 8. EM 算法背景——欲解决的问题 E 步 + M 步 理论推导： 先重新表达所要优化的对数似然函数： 强烈建议结合浙大的课程一起复习！ EM 算法一般形式 ① 随机选取 $$\\theta_0$$ ② E-step $$Q_i(z_i) = P(z_i|x_i, \\theta_k) = \\frac{P(z_i,x_i|\\theta_k)}{P(x_i|\\theta_k)}=\\frac{P(z_i,x_i|\\theta_k)}{\\sum_{z_i} P(z_i, x_i|\\theta_k)}$$ ③ M-step $$\\theta_{k+1}=argmax_{\\theta} \\sum_{i=1}^{N} \\sum_{z_i}Q_i(z_i) log\\frac{P(z_i,x_i|\\theta_k)}{Q_i(z_i)}$$ ④ 回到 ②，直至收敛。 高斯混合聚类算法的思想和步骤 一种 soft(fuzzy) 的聚类 实现思想：根据 EM 算法，针对每个数据点，为之分配属于每个聚类的概率 高斯分布 高斯分布的均值与方差： 开始极大似然估计： 转为对数似然估计： E 步 —— 求出数据点属于每个聚类的比重： M 步 —— 更新高斯分布的参数： https://zhuanlan.zhihu.com/p/85338773 9. 推荐系统 打分矩阵L分解成用户矩阵U和item矩阵I，然后可以用梯度下降求，目标函数怎么定义？U*I的结果尽可能接近L。基于用户：得到打分矩阵，计算相似度量公式，计算两两相似度，找出k个最像的用户，计算打分。基于商品：有时候用户很多，但商品数量有限。得到打分矩阵，确定一个商品之间相似度的度量公式。基于内容：考察商品之间的相似度，不仅考虑打分，还考虑商品的描述内容。冷启动：概念，新用户进来很难对其进行推荐，新商品进来不知道跟哪些商品相似，难以推荐新商品。数据稀疏的问题：打分矩阵的数据是很稀疏的。 https://zhuanlan.zhihu.com/p/28577447 SVD 分解 基于矩阵分解的推荐系统 打分矩阵 L 分解成用户矩阵 U 和商品矩阵 I，然后可以用梯度下降求，目标函数怎么定义？U * I 的结果尽可能接近 L。 基于用户的协同推荐 根据打分矩阵，计算相似度量公式 观察 sim(a, b)，其实就是相关系数（Pearson correlation）的计算。 问题：可能会导致只给出一些特定的 items。 解决：对差异较大的项目给予更多权重；significance weighting；Case amplification。 总结：memory-based，不适用现实场景，现实中这个矩阵太大。 基于商品的协同推荐 基于内容的协同推荐 基本思想：根据推荐物品或内容的元数据，发现物品或者内容的相关性，然后基于用户以往的喜好记录，推荐给用户相似的物品。即考察商品之间的相似度，不仅考虑打分，还考虑商品的描述内容。 应用：电影 A 和 C 的类型都是爱情和浪漫，那么就会给看过电影 A 的人推荐电影 C。 冷启动问题 数据稀疏的问题","link":"/2022/07/06/machine-learning/2022-07-06-review-machine-learning-courses/"},{"title":"[ml][nt] support vector machine","text":"没有免费的午餐定理：在不考虑先验概率的情况下，所有算法的性能一样。即没有不存在适用于所有的问题的算法，不存在普适性的算法，任何两个算法，以及它们训练出来的模型，在所有的现实问题的集合面前是无优劣的，它们的性能的数学期望值是一样的。 尽管如此，适合大部分情况的算法依然是存在的。 线性可分（Linear Separable）：存在一条直线分开两类。线性不可分（Linear Unseparable）：反之。 同样地，可以延伸至高维。用数学方式表示： 两侧正负号是人为定义的，将权重和偏置取反，两侧符号也便取反。 线性可分的严格定义：一个样本训练集 $${(X_i, y_i), …, (X_N,y_N)}$$ 在 i=1-N 线性可分，是指存在 $$(w_1, w_2, b)$$ 使得对 i=1-N，都有： $$(1)\\ 若y_i=+1, 则w_1x_{i1}+w_2x_{i2}+b&gt;0 \\(2)\\ 若y_i=-1, 则w_1x_{i1}+w_2x_{i2}+b&lt;0$$ 线性可分定义的简化形式： 如果 $$y_i$$ = +1 或 -1，一个样本训练集 $${(X_i, y_i), …, (X_N,y_N)}$$ 在 i=1-N 线性可分，是指存在 $$(w_1, w_2, b)$$ 使得对 i=1-N，都有： $$y_i(w^TX_i+b)&gt;0$$ 课后思考： ① 你能否给出实际生活中训练样本集是线性可分和线性不可分的例子？大多数实际生活中的例子是线性可分还是线性不可分？ ② 我们对于线性可分和线性不可分的定义只是局限于二分类间题，请对类别数大于 2 的情况，给出线性可分与线性不分严格的数学定义。 ③ 请通过数学定义严格证明，在二分类情况下，如果一个数据集是线性可分的，那么一定存在无数多个超平面可以把这两个类别完全分开。 线性可分的解法支持向量机算法步骤：① 解决线性可分问题 ② 再将线性可分问题中获得的结论推广到线性不可分情况 例子：三种分割按照免费午餐定理应该都一样，为什么会觉得 2 比较好？因为建立在这样一个先验假设：训练样本的位置在特征空间上有测量误差，这样的话 2 会有更高的容错率。 那么如何画出2线？也就是SVM算法的步骤①。 把一条分割线平行地往两侧移动，直到擦到两边的样本。令平行线擦到的样本为支持向量（support vector），平行线的间隔称为间隔（margin），SVM就是要让间隔做最大的那一个分割线。 但该方法不唯一，与该线平行的线都是间隔最大的。为保证唯一性，应使这条线在两条平行线中央。 总结条件：① 该直线分开了两类 ② 该直线最大化间隔 ③该直线处于间隔的中间，到所有支持向量距离相等。 基于以下事实： ① 相同超平面 $$w^Tx+b=0 与\\(\\alpha w^T)x+(ab)=0是同一个超平面(\\alpha \\neq 0)$$ ② 点到直线/面的距离公式 $$d=\\frac{|w^Tx+b|}{||w||}$$ 我们要的就是最大化 margin 到 support vector 之间的距离！ 据事实一，引出SVM最难理解的部分：用 a 去缩放 w 和 b。在 SVM 中，我们会发现我们会令支持向量到点的距离这一分式的分子是 1，为什么可以这么设呢？ 因为对于对于一个 $$(w, b)$$，可以对齐进行任意的等比例放缩得到 $$(aw, ab)$$，二者所表示的超平面是不变的，但是会使得分子的大小变化，因此可以使得： $$|w^Tx_0+b|=1, \\ x_0为支持向量 \\ |w^Tx_0+b|&gt;1, \\ x_0非支持向量$$ 这样我们就大幅简化了要优化的对象。也即 $$d=\\frac{|w^Tx+b|}{||w||} = \\frac{1}{||w||}$$ 因而问题转换为最小化 w 的模。实操中为方便求导定义作如下形式： $$最小化：\\frac{1}{2}||w||^2 \\限制条件：y_i(w^TX_i+b) &gt;= 1,(i=1-N) \\||w||^2 = \\sum^{m}_{i=1}w_i^2$$ 其中，$$y_i$$ 的作用是协调超平面的作用，同线性可分中的作用一样。上述的 1 可以改成别的整数，相当于放缩的时候采用了不同的尺度。 因而，SVM问题转为一个凸优化中的二次规划问题。 二次规划问题的定义：①目标函数(Objective Function)是二次项。②限制条件是一次项（这里的不等式就是一次项）。这样的问题要么无解，要么有唯一最小值。 已知凸优化问题，必有全局唯一的极值，可以用梯度下降解决。具体的解决方法，需学习《最优化》。 课后思考： ① 支持向量机的限制条件如果从大于等于1变成大于等于2，则(w, b)会变成(aw , ab) 。如果 Xi 和 w 是 M 维向量，那么 a 是多少？ ② 证明在线性可分条件下，有且只有唯一一条直线满足 SVM 的三个条件。 线性不可分的解法考虑线性不可分的情况，需要适当放松限制条件，否则以上问题无解。 基本思路有为为每个训练样本及其标签设置松弛变量（slack variable）δ。 因此，限制条件改写为： $$y_i(w^TX_i+b) &gt;= 1-\\delta_i,(i=1-N)$$ 当然还要加入新的限制使得 $$\\delta$$ 在一个合理范围内。最终，该问题改写为： $$最小化：\\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i\\ 或\\ \\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i^2 \\限制条件： (1)\\ \\delta_i&gt;=0,(i=1-N)\\(2)\\ y_i(w^TX_i+b) &gt;= 1-\\delta_i,(i=1-N)$$ 比例因子C，起到平衡加法两侧的作用，是人为设定的超参数。实操中，要不断变化C，同时测试算法的效果，然后选个最好的。两个最小化形式都是二次型。C 设尽可能大，可以尽可能向线性的结果靠拢。 一个失败的情况：线性模型的表现力是不够的。 课后思考： ① 在这个例子中，你能否设计出一个这样的非线性变换，将这个分类问题转化为线性可分呢？ 非线性变换针对线性模型表现力不够的情况，因而需要扩大可选函数范围。SVM中，会将特征空间把低维映射到高维，再使用线性超平面分类。 定理：在一个 M 维空间上随机取 N 个训练样本随机的对每个训练样本赋予标签 +1 或 -1，这些训练样本线性可分的概率为 P(M)，当 M 趋于无穷大时，P(M) = 1。 构造映射 $$\\varphi(x)$$ 便是关键。假设已知映射 $$\\varphi(x)$$，则改为： $$最小化：\\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i\\ 或\\ \\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i^2 \\限制条件： (1)\\ \\delta_i&gt;=0,(i=1-N)\\(2)\\ y_i(w^T\\varphi(X_i)+b) &gt;= 1-\\delta_i,(i=1-N)$$ 此时，w 的维度和映射后的向量维度相同。解法是和低维完全类似的。 为研究 $$\\varphi(x)$$ 的形式，引入核函数的概念。实操中我们不用知道 $$\\varphi(x)$$ 的具体形式，取而代之的是核函数： 即对于任意两个向量，有 $$K(X_1,X_2)=\\varphi(X_1)^T\\varphi(X_2)$$ 那么仍然能通过一些技巧获得样本的类别，从而完成对样本类别的预测。具体通过为什么技巧将在之后描述。在此先举例说明核函数以及低维到高维的映射 $$\\varphi(x)$$ 之间的相互关系。 假设 $$\\varphi(x)$$ 是一个把二维向量映射为三维向量的映射： $$X=[x_1,x_2]^T \\\\phi(X)=\\phi([x_1,x_2]^T)=[x_1^2,x_1x_2,x_2^2]$$ 假设有 X1 和 X2，那么核函数为： $$K(X_1,X_2)=\\phi(X_1)^T\\phi(X_2) \\=[x_{11}^2,x_{11}x_{12},x_{12}^2][x_{21}^2,x_{21}x_{22},x_{22}^2]^T \\= x_{11}^2x_{21}^2+x_{11}x_{12}x_{21}x_{22}+x_{12}^2x_{22}^2$$ 反之，已知核函数 K 求 phi（x）。 $$K(X_1,X_2)=(x_{11}x_{21}+x_{12}x_{22}+1)^2 \\= x_{11}^2x_{21}^2+x_{12}^2x_{22}^2+1+2x_{11}x_{21}x_{12}x_{22}+2x_{11}x_{21}+2x_{12}x_{22} \\= \\phi(X_1)^T\\phi(X_2)$$ 根据定义和观察， $$\\phi(X)=\\phi([x_1,x_2]^t) \\= [x_1^2,x_2^2,1,\\sqrt{2}x_1x_2,\\sqrt{2}x_1,\\sqrt{2}x_2]^T$$ 因而，核函数 K 和映射 phi 一一映射。但是 K 需要满足一定条件才可写作两个 phi 内积的形式。具体条件如下：（Mercer’s Theorem） $$K(X_1,X_2) 能写成 \\phi(X_1)^T\\phi(X_2)的充要条件：$$ $$① K(X_1,X_2)=K(X_2,X_1)（交换性）\\② \\forall C_i(i= 1\\sim N),\\forall N有\\sum^{N}{i=1}\\sum^{N}{j=1}C_iC_jK(X_i,X_j) \\ge0 （半正定性质）$$ 虽然无法知道 phi 的具体形式，但是可以知道 wx+b 的值，进而知道所属类别。 对偶问题具体研究已知 K 不知 phi 求 SVM 的优化问题。 原问题（Prime problem） $$最小化：f(w) \\限制条件：g_i(w) \\le 0,i=1\\sim K \\h_i(w) = 0,i=1\\sim K$$ 对偶问题（Dual problem） $$L(w,\\alpha,\\beta)=f(w)+\\sum^{K}{i=1}\\alpha_ig_i(w)+\\sum^{M}{i=1}\\beta_ih_i(w) \\=f(w)+\\alpha^Tg(w)+\\beta^Th(w)$$ 其中， $$\\alpha = [\\alpha_1,\\alpha_2,…,\\alpha_K]^T \\\\beta = [\\beta_1,\\beta_2,…,\\beta_M]^T \\g(w) = [g_1(w),g_2(w),…,g_K(w)]^T \\h(w) = [h_1(w),h_2(w),…,h_M(w)]^T$$ 在定义了 L 函数的基础上，定义对偶问题如下：遍历定义域里的 w，找到使得 L 最小的那个 w，同时把最小的这个函数值赋值给 theta 函数。 个人理解：先通过遍历 w 得到最小的 L。得到最小的 L 后就找到了对应的 w，此时 w 已知，alpha 和 beta 未知，因而得到 alpha 和 beta 的 theta 函数。之后再最大化这个函数。 综合两个问题的定义，得到以下定理： 定理一： 这个定理告诉我们原问题的解总是大于等于对偶问题的解。我们把 f(w*) - theta(alpha*, beta*) 定义为对偶差距（DUALITY GAP）。对偶差距显然大于等于0。 强对偶定理： 简单点说，原问题的目标函数是凸函数，限制条件是线性函数，那么对偶差距为0。具体证明可以课后阅读。 根据定理一推出的不等式： 若 f(w*) = theta(alpha*, beta*) （简单点说，就是原问题和对偶问题的解相等的时候），则根据定理一，显然可以推出，对于所有的 i=1~K，要么 alpha_i = 0，要么 g(w*) = 0。这个条件就是 KKT 条件。 最终求解将原问题转换为对偶问题，以完成问题的求解。 支持向量机的原问题满足强对偶定理。回顾 SVM 的优化问题： 结合原问题的定义，需要把前两个限制条件改成小于等于 0 的定义。限制条件取反，那么最小化中也要取反。 两个限制条件都线性的，目标函数是凸的，满足强对偶定理。 SVM 中不存在 h(x) 的情况。因此，可以把 SVM 的对偶问题写作如下形式： tips：对偶问题中的 w 指的是未知变量，此时，未知变量 w 包括 (w, sigma, beta)。求微分，得下式： 根据 ② 消去红框，根据 ③ 消去蓝框： 原式还剩三项： 整理之后，化简为： 问题中，已知的是所有的 x，y 以及核函数 K。这是一个凸的问题，可以用 SMO 算法求解。 但化成这样后，还没完。这样求出了 alpha 还要求 omega 和 bias。 但是求 omega 岂不是又得知道映射函数？实则不用，因为实际上我们不需要知道 omega。考虑测试流程： 测试样本 x 输入，若 omega^T phi(x) + b&gt;= 0 则 y=+1，反之 y=-1。 实际上， omega^T phi(x) = sum_i_N alpha_i y_i K(xi, x)。又把 phi 化简掉了，只需要用核函数 K 去算就行。 接下来分析求 bias，先把 SVM 问题中的 KKT 条件列出： 假定 alpha_i 都算出来了，那么一定能找出一个 alpha_i 是 0&lt;alpha_i&lt;C 的【？】。首先取一个 alpha_i 是 0&lt;alpha_i&lt;C 的，可得 beta_i = c-alpha_i &gt; 0，可得 epsilon_i = 0。有 alpha_i != 0 可得 ② 中后半式，根据该式求解 b： 在实际运算中，可以取所有满足条件 0&lt;alpha_i&lt;C 的 alpha_i，求出对应 b ，然后做平均。 总结如下：","link":"/2022/07/06/machine-learning/2022-07-06-support-vector-machine/"},{"title":"[ml][rv] generative adversarial network","text":"GAN_P1GenerationNetwork as Generator输入 x 和从一个distribution 裡面 sample 出来的 z，输出变成了一个复杂的 distribution。这种输出 distribution 的 network 称之为==generator==。 Why distribution为什么要输出一个分布？有时候需要这样。 例子：video prediction，即给机器一段的影片，然后它要预测接下来会发生什麼事情。训练资料裡面同样的输入，有时候同样的转角有两种可能性。所以你的 network 学到的就是两面讨好。 什麼时候我们会特别需要这？我们的任务需要一点创造力的时候。通俗讲，们想要找一个function，但是同样的输入有多种可能的输出，他们都是对的。 Generative Adversarial Network (GAN)generative 的 model，其中一个非常知名的就是==generative adversarial network==。 Anime Face Generation例子：让机器生成动画人物的,二次元人物的脸。 Discriminator在GAN裡面除了==generator==以外还有一个 ==discriminator==。 discriminaton 也是个 network，它的作用是：拿一张图片作為输入，它的输出是一个数值。越大代表越像是真实的二次元图像。 Basic Idea of GAN物竞天择。对应到 GAN，枯叶蝶就是 generator，那它的天敌就是 discriminator。 generator 生成二次元图像。discriminator 分辨二次元图像。 AlgorithmStep 0：初始化 generator 和 discriminator 的参数。Step 1: Fix generator G, and update discriminator D从这个 gaussian distribution 裡面去 sample 一堆 vector，把这些 vector 丢到 generator 裡面，它就吐出一些图片。 你会有一个 database，这个database裡面，有很多二次元人物的头像。 接下来就拿真正的二次元人物头像，跟 generator 產生出来的结果，去训练你的discriminator。discriminator 它训练的目标是要分辨，真正的二次元人物跟 generator 產生出来的二次元人物。 这对於 discriminator 来说是一个分类的问题。也可以说是 regression 的问题。 Step 2: Fix discriminator D, and update generator G我们把 generator 生成的图片丢到 Discriminator 裡面，Discriminator 会给这个图片一个分数，那 generator 是要 Discriminator 的输出值越大越好 举例来说 generator 如果是五层的 network，Discriminator 如果是五层的 network，把它们接起来我们就把它当作是一个十层的 network 来看待。这个十层的network裡面，其中某一隐藏层的输出就是代表一张图片。 我们要做的事情是,整个巨大的 network 啊,它会吃一个向量作為输入，然后他会输出一个分数,那我们希望调整这个 network，让输出的分数越大越好。==gradient ascent== 来优化。 GAN_P2_Theory behind GAN接下来讨论為什麼这个 Generator 跟 Discriminator 的互动，可以让我们的 Generator產生像是真正的人脸的图片。 那我们先来弄清楚训练的目标到底是什麼，我们想要 Minimize 的是让 Generator 产生的 Distribution 和 真正 Data 的 Distribution 越接近越好。 Div = Divergence。红色下划线的函数也就表示了我们的 Loss Function。 常见的 Divergence 计算方法： 但是我们这边遇到一个困难的问题，这个 Divergence 很难算的。而==GAN==是一个很神奇的做法,它==可以突破,我们不知道怎麼计算 Divergence 的限制==。 我们不需要知道 PG 跟 Pdata 它们实际上的 Formulation （对应公式的 P(x) 和 Q(x)）长什麼样子，只要能从 PG 和 Pdata这两个 Distributions Sample 东西出来，就有办法算 Divergence。 Discriminator如何在只有做 Sample 的前提之下估测出 Divergence？那这个就是要靠 ==Discriminator== 的力量。 Discriminator 优化的过程，你也可以把它写成式子： 这个 Discriminator 可以去 Maximize某一个 Function,我们这边叫做 ==Objective Function==（我们要 Maximize 的东西,我们会叫 Objective Function,如果 Minimize 我们就叫它 Loss Function）。 $E_{y\\sim P_{data}}[logD(y)]$ 我们有一堆 Y,它是从 Pdata 裡面 Sample 出来的,也就是它们是真正的 Image,而我们把这个真正的 Image 丢到 D 裡面,得到一个分数再取$logD(y)$ $E_{y\\sim P_G}[log(1-D(y))]$ 那另外一方面,我们有一堆 Y,它是从 PG 从 Generato r 所產生出来的,把这些图片也丢到 Discriminator 裡面,得到一个分数,再取 $log(1 - D (y))$ 那这边最神奇的地方是这一个式子，这个红框框裡面的数值,它跟 JS Divergence 有关。假设 PG 跟 Pdata 的 Divergence 很小，所以这个 Objective 这个 V 的 Maximum 的值就比较小。所以小的 Divergence，对应到小的这个 Objective Function 的Maximum 的值。 Tips for GAN技巧之一： ==WGAN==。 在此之前先讲 JS Divergence 有什麼样的问题。 JS divergence is not suitablePG 跟 Pdata 有一个非常关键的特性是：它们重叠的部分往往非常少。 原因有二：其一，那图片其实是高维空间裡面的一个低维的 Manifold，二次元人物的头像它的分布在高维的空间中其实是非常狭窄的。其二，我们对 PG 跟 Pdata,它的分布的理解来自於 Sample，如果采样不全有重叠也发现不了。 JS Divergence 有个特性，是两个没有重叠的分布，JS Divergence 算出来,就永远都是 Log2。因此用 JS Divergence 的时候，你就假设你今天在 Train 一个 Binary 的 Classifier，你会发现实际上你通常 Train 完以后正确率几乎都是 100%。 因為你 Sample 的图片根本就没几张，它直接用硬背来分辨。所以这时候 accuracy 没啥用。 Wasserstein Distance假想你在开一台推土机,那你把分布 P 想成是一堆土，把分布 Q 想成是你要把土堆放的目的地，那这个推土机把 P 这边的土，挪到 Q 所移动的平均距离就是 Wasserstein Distance。 但是推土的办法有很多种。因此光只是要计算一个 Distance，居然还要解一个 Optimization 的问题，解出这个 Optimization 的问题，才能算 Wasserstein Distance。先讲 Wasserstein Distance 能给我们什么好处。 由左向右的时候，Wasserstein Distance 是越来越小的，表明 Generator 在进步。JS Divergence 却不变。 WGAN用 Wasserstein Distance 来取代 JS Divergence 的时候，这个 GAN 就叫做 WGAN。 接下来你会遇到的问题就是，Wasserstein Distance 是要怎麼算。 解下面这个 Opimilazion 的 Problem，解出来以后你得到的值就是 Wasserstein Distance。 即我们想要 Discriminator 对 Pdata 输出越大越好，对 PG 的 输出越小越好。 限制：D 必须要是一个 1-Lipschitz 的 Function。 1-Lipschitz 不知道是什麼的话也没关係。可以想象成 D 必须要是一个足够平滑的 Function。 否则，就会出现无限大的情况。这会导致要优化的目标越来越大，这下就又不能收敛力（悲。 接下来的问题就是怎麼做到 1-Lipschitz 的这个限制。 想法一：只需 Train Network 的时候，让 Training 的那个参数，要求它放得在 C 跟 -C 之间，如果参数更新后超过就设为 C 就设为 C，小于 -C 就设为 -C。但这样其实挺拉的。 想法二：Gradient Penalty。 想法三：Spectral Normalization。 GAN_P3有了 WGAN 并不代表说 GAN 就一定特别好 Train。為什麼 GAN 很难被 Train 起来？ 事实上 Generator 跟 Discriminator，它们是互相砥砺才能互相成长的，只要其中一者发生什麼问题停止训练，另外一者就会跟著停下训练。 Conditional Generation到目前為止我们讲的 Generator，它输入都是一个随机的分布而已，那这个不见得非常有用。 我们现在想要更进一步的是，我们可以操控 Generator 的输出，我们给它一个 Condition x，让它根据 x 跟 z 来產生 y，那这样的 Conditional Generation。 普通的 ==GAN== 不也是一个标量一个向量输入？ 如果要做文字对图片的生成，它其实是一个 Supervised Learning 的问题。你需要一些 Label 的 Data，比如说红眼睛的人头像，才能够训练这种 Conditional 的 Generation。 所以在这样的任务裡面，我们的 x 就是一段文字。比如说输入 Red Eyes，然后机器就可以画一个红眼睛的角色，但每次画出来的角色都不一样。 也许你就可以去把 Generator 训练出来，但这样的方法是错误的。因为这样的 Generator 它只要產生清晰的图片，就可以骗过 Discriminator 了，它何必要去管 Input 文字叙述是什麼。 所以在 Conditional GAN 裡面， Discriminator 不是只吃图片 y，它还要吃 Condition x。 那怎麼样训练这样的 Discriminator ？那你需要文字跟影像成对的资料，所以 Conditional GAN 一般的训练需要的 Data 的，是需要有标註的资料的。 光是这样子的 Positive Sample 还不够，还有 Negative Sample，即產生好的图片文字叙述配不上的状况。 再考虑 Image To Image 的情形，只是从影像產生影像,把文字的部分用影像取代掉而已。文献上如果你要做到最好，往往就是 GAN 跟 Supervised Learning，同时使用。 此外，输入的 label 也可以是 multi-label 的。 GAN_P4 Learning from Unpaired Data最后讲一个GAN的神奇应用，它把GAN用在==unsupervised Learning==。 我们可能会遇到一个状况：我们有一堆 X 我们有一堆 Y，但 X 跟 Y 是不成对的。这叫做==unlabeled==的资料。 我们这边举一个例子：影像风格转换。X domain 是真人的照片，Y domain的图是二次元人物的头像。这个例子没有任何的成对的资料。 解决办法：Unsupervised Conditional Generation。 输入是一个 Gaussian 的分佈，输出可能是一个复杂的分佈。现在我们在稍微转换一下我们的想法，输入说是 X domain 的图片的分佈，输出说是 Y domain 的图片的分佈。 把输入改成 X domain 很简单，不从高斯分布里采样就行。那怎麼让输出变成是Y domain 的 distribution 呢？ 那就要两三个 discriminator，那这个 discriminator 给它看过很多 Y domain 的图，所以它能够分辨 Y domain 的图跟不是 Y domain 的图。 但这样不够，还得保证生成的二次元头像跟输入的真实的照片有关联。 由于没有成对数据，因此无法直接套用 conditional GAN 的想法。因為在 conditional GAN 裡面，我们是有成对的资料来训练 discriminator 的。 Cycle GAN这边这个想法叫做==Cycle GAN==。在Cycle GAN裡面会 train 两个 generator。 在训练的时候增加了一个额外的目标：希望输入一张图片，从 X domain 转成 Y domain 以后，要从Y domain转回原来的。我们要让原图和还原的图越相近越好。这叫做 ==Cycle的consistency==。 两张图片本质上就是两个向量，它们之间的距离越接近越好，就是要两张图片越像越好。 所以现在这边我们有三个Network： 第一个generator,它的工作是把X转成Y 第二个generator,它的工作是要把Y还原回原来的X 那这个discriminator,它的工作仍然是要看,蓝色的这个generator它的输出,像不像是Y domain的图 这时你可能会有的一个问题就是：你只能保证两个 domain 的图有关系，但这种关系真的有意义？比如两个 generator 学到的都是图片反转，同样也能保证 cycle consistency。这个问题实际上一般不出现。 Cycle GAN 可以是双向的。 一些其他的 GAN。Disco GAN、Dual GAN 跟 Cycle GAN 没什么不同。 相比只能在两种风格间转换的 Cycle GAN，StarGAN 可以做多风格影像风格转换。 一些其他应用：把长的文章变成简短的摘要；翻译；非督导式的语音辨识。 Evaluation of Generation要评估 Generator 的好坏完全用人来看显然有很多的问题。应该来点客观的方法。 比如跑一个影像的分类系统：把你的 GAN 產生出来的图片，丢到一个的影像的分类系统裡面，看它產生什麼样的结果。 如果四不像，那就是均匀分布力。 Diversity - Mode Collapse但是光用这个评估的方法会被一个叫做 ==Mode Collapse== 的问题骗过去。 这会导致 Generative Model 输出来的图片来来去去就是那几张可能单一的图片。 那為什麼会有 Mode Collapse 这种现象发生？直觉上理解，这个地方就是 Discriminator 的一个盲点，发现这个盲点后每次都整这一出。 Diversity - Mode Dropping但是有另外一种更难被侦测到的问题叫做 ==Mode Dropping==。 Mode Dropping 的意思是说，你的產生出来的资料，但看起来多样性好像也够。 这种问题难以侦测。一种可能的方法： 借助我们的 Image Classifier。比如把 Generator 產生 1000 张图片，把这 1000 张图片裡,都丢到 Image Classify 裡面，看输出是哪个 class。 每张图片，都会给我们一个 Distribution。把所有图片的 Distribution 加起来平均，如果很集中说明多样性不行。 Diversity 跟 Quality 好像是有点互斥？实则不然。二者评估范围不同。Quality 是只看一张图片的分布，而 Diversity 看的是一堆图片它分布的平均。 过去有一个非常常被使用的分数,叫做 ==Inception Score==。如果 Quality 高，那个 Diversity 又大，那 Inception Score 就会比较大。 Fréchet Inception Distance (FID)还有一个 Evaluation 的 Measure,叫 ==Fréchet Inception Distance==。 你先把你產生出来的二次元的人物，丢到 Inception Net 裡面，那个 Inception Network 输出它的类别，那你得到的可能就是人脸，那每一张二次元的人物看起来都是人脸，那我们不要拿那个类别。 我们拿进入 Softmax 之前的 Hidden Layer 的输出。把这个向量拿出来代表这张图片。 我们拿出来的是一个向量，而不是最后的类别。那虽然最后分类的类别可能是一样的，但是在决定最后的类别之前，这个向量就算都是人脸，可能还是不一样的。 假设真实的图片跟產生出来的图片它们都是 Gaussians 的 Distribution，然后去**计算这两个 Gaussians Distribution 之间的==Fréchet Distance==**。因為它是一个 Distance，所以这个值就是越小越好，代表这两组图片越接近。 但实际上图片不一定是 Gaussians Distribution，且要準确得到你的 Network 它的分布需要產生大量的 Sample 才能做到。","link":"/2022/07/06/machine-learning/2022-07-06-review-generative-adversarial-network.md/"},{"title":"[ml][rv] pattern recognition","text":"1. 总览 考核形式 主要考对概念的一些理解，例如说偏置方差分解和过拟合欠拟合之间的关系 计算有但不是太多 在理解的基础上对算法进行记忆，比如 PCA &amp; LDA，他们的目标函数优化这些都是要知道的 2. 提取特征 提取特征：Normalization(Chap. 9), PCA(Chap. 5), FLD(Chap. 6), Sparse(Chap. 11), …PCA 无监督，FLD 有监督地利用标签去提取特征的方法Sparse 没有详细地去讲 Normalization 可以把范围从 [0, 1] 拉伸至任意范围。 如果某一维度的最大值等于最小值，这个维度的数据可以丢掉。 如果 0 值在原始数据中代表 “空”，那么应该把它规范成0。 如果测试样例的数据范围大于 0 或 大于 1，有时候算法必须要求 [0, 1]，那么可以把小于 0 的值设为 0，大于 1 同理，如果算法不要求其实也可以这么做。 如果能看出某维数据符合高斯分布，那么也可以化为标准高斯分布： L-1 规范化：如果值非负，规范化后样例各维之和为 1 L-2 规范化：把数据规范化为单位向量 PCA首先要会做 SVD 分解。 FLD思想：把数据点进行投影，使得不同类别之间的数据距离尽可能大。 可分性的绝对要素：两个均值之间的距离 + 两个标准差。要实现分类，就需要最大化这二者的比例。 注：PCA 和 FLD 中的 X 的尺寸都是 (dim x 1) 。因而，$$a^Ta$$ 的结果是一个值，$$aa^T$$ 的结果是一个矩阵。 二分类的 FLD： $$w$$：投影方向 $$m_i$$ ：集合 i 的均值 $$C_i$$ ：集合 i 的协方差矩阵 $$C_i = \\frac{1}{N_i} \\sum_{x \\in X_i} (x-m_i)(x-m_i)^T$$ 传统 FLD 用散度矩阵而不是用协方差矩阵，散度矩阵 $$S_i = N_iC_i$$ 类间散度矩阵 &amp; 类内散度矩阵： $$S_B=(m_1-m_2)(m_1-m_2)^T \\S_W = S_1+S_2$$ 目标函数（第一行的 m 是投影后的均值，第二行的 m 是向量）： $$J = \\frac{(m_1-m_2)^2}{\\sigma_1^2+\\sigma_2^2} \\= \\frac{(m_1^T w-m_2^Tw) ^ 2}{\\sigma_1^2+\\sigma_2^2} \\= \\frac{w^T(m_1-m_2)(m_1-m_2)^Tw}{w^T(C_1+C_2)w} \\= \\frac{w^TS_Bw}{w^TS_Ww} \\$$ 如果一个均值向量扮演了所属类别的所有样本的代理，那么就可以用均值向量集合的散度矩阵代替 $$S_B$$ $$\\sum^{2}_{i=1}(m_i - \\overline{m})(m_i - \\overline{m}) ^T \\\\overline{m} = \\frac{m_1+m_2}{2}$$ 之后就可以计算以及规范化了。 考虑至多类别呢？ 类内散度矩阵 $$S_W = \\sum ^{K}{k=1} S_k = \\sum ^{K}{k=1}N_kC_k = \\sum ^{K}{k=1} \\sum{x \\ in X_k}(x-m_i)(x-m_i)^T$$ 总散度矩阵 $$S_T = \\sum ^{N}{i=1}(x_i-m)(x_i-m)^T \\m = \\frac{1}{N} \\sum^{N}{i=1}x_i$$ 类间散度矩阵 $$S_B =\\sum ^{K}_{k=1}N_k(m_k-m)(m_k-m)^T$$ 规律：总散度矩阵 = 类内散度矩阵 + 类间散度矩阵。 多分类问题中，类间散度矩阵不再是秩为 1 的矩阵，算法 6.1 不可用，故求解如下广义特征值问题来找最佳投影方向： $$S_B w = \\lambda S_W w$$ 当 $S_W$ 可逆，广义特征值问题等价于： $$S_W ^ {-1} S_B w = \\lambda w$$ 那么如何找更多投影方向（降低更多维度）呢？类似 PCA，只要使用与前 K-1 个最大广义特征值对应的广义特征向量即可 Sparse含义：最小化 $$l_0$$$ norm（向量 x 的非零元素个数） $$minimize\\ ||x||_0 \\subject\\ to\\ Ax=y$$ 3. 分类器 分类器：kNN, SVM, Decision Tree, Ensemble, Regression, NN, CNNkNN, SVM 前两个重要，后面都是简单提一下CNN 也可以看作是个特征提取的方法 kNN（机器学习）理解且会用 缺陷以及解决办法 出现平局：可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。 离群点 复杂度 O(nd) [d是计算距离的代价] SVM（机器学习）Decision Tree + Regression（机器学习）EnsembleNNCNN4. 概率模型 概率模型 (Chap. 8)：参数估计，非参，HMM，GMM参数估计：点估计，贝叶斯估计，HMM非参数估计：KDE要知道 HMM 的隐马尔可夫性质 + 要知道 GMM 的概念 概率模型：计算变量的概率或者概率分布的模型。 参数估计：假设 PDF 服从某种函数形式，当指定其所有参数值之后，PDF 就完全确定，估计 PDF 就是估计参数。 非参数估计：非参数不代表无参数（允许无限），用训练数据直接估计空间中任意点的密度 p(x|D)。 生成模型：估计 p(x|y=i) 和 p(y=i)，根据贝叶斯定理求 p(y=i|x) 判别模型：直接估计 p(y=i|x) 这些模型都有两个步骤：推理和决策，分别是估计各种密度函数，根据估计得到的PDF对任意的？给出输出。 点估计（参）点估计（point estimation）是用样本统计量来估计总体参数，典型的如 MLE 和 MAP，把 $$\\theta$$ 视作固定参数，目的是找这个最佳参数。 p(D|theta) 不是 PDF，但 p(x|theta) 是。 likelihood function of MLE： $$l(\\theta) = p(D|\\theta) = \\prod_{i}p(x_i|\\theta)$$ 高斯分布的最大似然估计，可以通过对 $ll(\\theta)$ 求偏微分得到结果： $$\\mu = \\frac{1}{n} \\sum^{n}{i=1}x_i \\\\sigma^2 = \\frac{1}{n} \\sum^{n}{i=1}(x_i-\\mu)(x_i-\\mu)^T$$ 最大后验估计（MAP）：把参数 theta 自身的取值可能性考虑进来。如果一无所知就等价于 MLE。 $$\\theta = argmax_{\\theta} l(\\theta)p(\\theta)$$ 渐进性质（asymptotic property），如一致性（consistency）：随样本容量增大收敛到参数真值的估计量 其他性质，无偏估计（unbiased estimate）：指估计量的期望和被估计量的真值相等 完成 inference 后，如何决策？根据参数得到后验概率 p(y|x;theta) 得出结果，在 0-1 风险时，选择概率大的就行。 贝叶斯估计（参）点估计是把 $\\theta$ 看成固定参数，而贝叶斯估计 p(theta|D) 是估计一个 $$\\theta$$ 的分布，而不是一个值（点）！ 高斯分布参数的贝叶斯估计：设参数 theta 的先验分布 p(theta)，数据 X = {x1, … , xn}，估计 p(theta|D)。这里假设单变量，只估计 p(theta|D) 的高斯分布的均值 mu，方差 sigma^2 已知： 根据已知的先验高斯分布 P(theta) = N(mu0, sigma0^2) 根据贝叶斯定理和独立性，可以得 p(theta|D) = 估计均值 &amp; 方差为： 共轭先验conjugate prior：若 p(x|theta) ，存在先验 p(theta)，使得 p(x|theta) 和 p(theta) 有相同的函数形式，从而简化推导和计算。如高斯分布的共轭先验分布仍然是高斯分布。 完成 inference 后，如何决策？输出一个分布，结果通常根据期望决定。 KDE（非参）常用的参数形式基本都是单模的，不足以描述复杂的数据分布。因此应该直接以训练数据自身来估计分布。 例：直方图。每维 n 个bin，那么 n 维应该保存多少个bin的参数？$$n^d$$。太大了，且不光滑！ 给定一组提取于未知分布 p(x) 的数据 $x_1,x_2,…,x_n$ ，任一点 x 处的核密度估计定义为： $$\\hat{p}(x) = \\frac{1}{nh} \\sum^{n}_{i=1}K(\\frac{x-x_i}{h})$$ $$K(x) \\ge0, \\int K(x)dx=1$$ KDE 核函数与 SVM 的不同：在概率估计中被用于估计目标点周围的概率密度。而在SVM中，被用于计算两点间的核空间距离。 连续的。 窗宽确定：使得估计的积分均方误差 (mean integral square error,MISE) 达到最小，如下式 $$MISE{\\hat{p}h(x)}=E[\\int^{\\inf}{-\\inf}{\\hat{p}_h(x)-p(x)}dx]$$ HMM（机器学习）隐马尔可夫性质 $$P(X_t|X_{1:t-1})=P(X_t|X_{t-1})$$ ，无记忆性，当前状态的只跟上一个状态有关系。 随机过程（stochastic process） $${X(t), t\\in T}$$ 是一系列随机变量的集合，用于描述一些过程的时间进化，目的是希望过去对现在有帮助。也就是说，对于每个 $$t \\in T$$, $$X(t)$$ 是一个随机变量。索引 t 通常被解释为时间，因此把 $$X(t)$$ 作为 t 时流程的状态。 B：emission probability 发出观察值的概率。$$b_j(k)=Pr(O_t=V_k|Q_t=S_j)$$。当未知状态为 $$S_j$$ 时观察到为 $$V_k$$ 的概率。 Problem 1. Evaluation 概念：给定已知 $$\\lambda = (A,B,\\pi)$$ 的 HMM 模型，以及一个完整的输出序列 $$o=o_{1:T}$$，求该模型观察到该输出序列的概率 $$P(O|\\lambda)$$。 作用：看出此模型对该观察序列的成绩，从而在多个模型中选择最适合的模型。 算法 Naive 假设隐状态序列 $q_{1:T}$ 已知： $$Pr(o_{1:T}|\\lambda, q_{ 1:T}) = \\prod^{T}{t=1}Pr(o_t|q_t, \\lambda) = \\prod^{T}{t=1}b_{q_i}(o_i)$$ 则必有 $$Pr(o_{1:T}|\\lambda) = Pr(o_{1:T}, q_{1:T}|\\lambda) =\\sum_{all\\ Q}Pr(o_{1:T}|\\lambda, q_{ 1:T})Pr(q_{1:T}|\\lambda)$$ 时间复杂度 $$O(TN^T)$$ 对 Naive 的观察与优化——提取 $$b_i(o_i)$$ $$Pr(o_{1:T}|\\lambda)=\\sum_{i=1}^{N}Pr(o_{1:T},Q_T=S_i|\\lambda)\\=\\sum_{i=1}^{N}Pr(o_{1:T-1},Q_T=S_i|\\lambda)Pr(O_T=V_k|Q_T=S_i,\\lambda)\\=\\sum_{i=1}^{N}Pr(o_{1:T-1},Q_T=S_i|\\lambda)b_i(o_T)$$ 对 Naive 的观察与优化——提取 $$A_{ji}$$ $$Pr(o_{1:T-1},Q_T=S_i|\\lambda) = \\sum_{j=1}^{N}Pr(o_{1:T-1},Q_{T-1}=S_j|\\lambda)A_{ji}$$ 根据 2. 和 3. 的提取优化，可得 $$Pr(o_{1:T}|\\lambda)=\\sum_{i=1}^{N}Pr(o_{1:T},Q_T=S_i|\\lambda)\\=\\sum_{i=1}^{N}Pr(o_{1:T-1},Q_T=S_i|\\lambda)b_i(o_T)\\=\\sum_{i=1}^{N}(b_i(o_T)\\sum_{j=1}^{N}Pr(o_{1:T-1},Q_{T-1}=S_j|\\lambda)A_{ji}) \\$$ 前向算法 forward 定义 $$\\alpha_{t}(i)=Pr(o_{1:t},Q_t=S_i|\\lambda)$$。含义：对于已知参数 $$\\lambda$$ 的模型，获得观测序列 $$o_{1:T}$$ 且 t 时刻隐状态为 $$S_i$$ 的概率。 初始化：$$\\alpha_1(i)=Pr(o_{1},Q_1=S_i|\\lambda) = Pr(Q_1=S_i|\\lambda)Pr(o_{1}|Q_1=S_i,\\lambda) = Pr(Q_1=S_i|\\lambda)b_i(o_1)$$ 前向递推： $$\\alpha_{t+1}(i)=[\\sum^{N}{j=1} Pr(o{1:t},Q_t=S_j|\\lambda)A_{ji}]b_i(o_{t+1})\\=[\\sum^{N}{j=1} a{t}(j)A_{ji}]b_i(o_{t+1})$$ 结果：$$Pr(o_{1:T}|\\lambda)=\\sum^{N}{i=1}Pr(o{1:T},Q_T=S_i|\\lambda)=\\sum^{N}_{i=1} \\alpha_T(i) $$ 复杂度：$$O(TN^2)$$ ⑤ 后向算法 backward 定义 $$\\beta_t(i) = Pr(o_{t+1:T}|Q_t=S_i, \\lambda)$$。含义：对于已知参数 $$\\lambda$$ 的模型，已知 t 时刻状态为 $$S_i$$，未来观测到 $$o_{t+1:T}$$ 的概率。 初始化：$$\\beta_T(i) = 1$$。 反向更新： $$\\beta_t(i) = \\sum^{N}{j=1}A{ij}b_j(o_{t+1})\\beta_{t+1}(j)$$ 输出：$$Pr(o_{1:T}|\\lambda)=\\sum^{N}{i=1}\\pi{i}b_i(o_{1})\\beta_{1}(i)$$ Problem 2：Decoding 概念：给定已知 $$\\lambda = (A,B,\\pi)$$ 的 HMM 模型，以及一个完整的输出序列 $$o=o_{1:T}$$，求一个完全指定的隐变量序列 $$q_{1:T}$$ 的值。 作用：语音识别中状态可能有实际意义（各音节），可以用来观察模型结构，优化模型。 算法： Problem 3：Learning 概念：发现 $$\\lambda = (A,B,\\pi)$$，使得对于固定的 N，T，和观察值 O，似然概率 $$P(O|\\lambda)$$ 最大。 作用：最重要的问题 目前无法发现全局最优解，常用 Baum-Welch 算法。 5. 优化方法 优化方法：极值条件，对偶，KKT，GD，SGD，EM，要知道凸优化和非凸优化，要知道凸优化的话，极值就是最优点，那么找最优点就是导数等于0要直到 SVM 里面的对偶问题，SVM 没有显式最优解，因此可以用 GD，Regression 有显式最优解在神经网络里面一般用 SGD，SGD 要有一个概念，为什么我们要用 SGD 和 GD？要知道二者区别，还得知道 SGD 优点要对概率模型的参数进行估计的话，可以考虑用 EM 进行参数估计，比如 HMM 凸优化定义： $$minimize \\ f_0(x) \\subject \\ to \\ f_i(x)&lt;=b_i,\\ \\ i=1,…,m$$ 其中，目标函数和约束函数都是凸函数，即 $$f_i(\\alpha x+\\beta y) &lt;= \\alpha f_i(x) + \\beta f_i(y) \\\\alpha + \\beta = 1,\\ \\alpha &gt;=0, \\ \\beta&gt;=0$$ [SVM 中的对偶 &amp; KKT（机器学习）GD &amp; SGD随机梯度下降每次只用一个样本，对于最优化凸问题，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。但是相比于批量梯度，这样的方法更快，更快收敛。 批量梯度下降每次更新时用所有样本。对于最优化凸问题，可以达到一个全局最优。如果样本不多的情况下，当然是这样收敛的速度会更快。但是很多时候，样本很多，更新一次要很久。 EM &amp; GMM（机器学习）浙大 6. 距离度量 （样本之间的）距离度量：l-p 范数, DTW, …要知道如何度量两个不同时间序列的样本之间的距离DTW 动态时间规整 $$l_0$$ 范数：向量 x 的非零元素的个数 DTW（Dynamic Time Warping）：动态时间规整 性质：1. 匹配是顺序的 2. 每个 $$x_i$$ 或 $$y_i$$ 都要有对应的匹配 3. 一个 $$x_i$$ 可以和多个 $$y_j$$ 匹配，反之亦然 递推公式： 熵单变量 $$H=-\\sum^{m}_{i=1}p_ilog_2p_i$$ $$h=-\\int p(x)ln(p(x))dx$$ 双变量 $$H(x,y)=-\\sum_{x}\\sum_{y}P(x,y)log_2P(x,y)$$ $$h=-\\int p(x,y)ln(p(x,y))dxdy$$ $$H(X|Y) = \\sum_{y}P(y)H(X|Y=y) =-\\sum_{y}P(y)\\sum_{x}P(X=x|Y=y)log_2P(X=x|Y=y) \\= -\\sum_{x,y}P(x,y)log_2 \\frac{P(x,y)}{p(y)}$$ $$h(x,y) = -\\int p(x,y)ln\\frac{p(x,y)}{p(y)}dxdy$$ 熵之间的关系 H(X,Y)=H(X)+H(Y|X)=H(Y)+H(X|Y) H(X|Y)&lt;H(X) H(Y|X)&lt;H(Y) 互信息 $$I(X;Y)=H(X)-H(X|Y) = \\sum_{x,y}P(x,y)log_2 \\frac{P(x,y)}{P(x)P(y)}$$ KL 散度 $$KL(P||Q)=\\sum_{i} P_ilog_2\\frac{P_i}{Q_i}$$ $$KL(P||Q) \\ge 0$$，等号成立条件：$$P_i=Q_i$$。不对称。 交叉熵 $$CE(P,Q)=-\\sum_{i}P_ilog_2Q_i \\CE(P,Q)=H(p)+KL(P||Q)=-\\sum_{i}P_ilog_2P_i+\\sum_{i} P_ilog_2\\frac{P_i}{Q_i}$$ 7. 损失函数 损失函数：square, hinge, exponential, logistic, cross entropy, …线性回归：squareSVM：hingeAdaboost：exp逻辑回归：logistic神经网络：cross entropy Square（机器学习）形式： $$L(f,y)=(f-y)^2$$ 线性回归中的 Square： $$L=\\sum^{N}_{i=1}(y_i-\\theta^Tx_i)$$ Hinge译为铰链损失。 形式： $$L(y,f(x)) = max(0,1-yf(x)),$$ SVM 中的 Hinge： $$L = \\frac{1}{2C}||w||^2+\\sum^{N}_{i=1}max(0, 1-y_i(\\theta^Tx_i+b))$$ Exp译为指数损失。 形式： $$L(y, f(x)) = exp[-yf(x)]$$ Adaboost 中的 Exp： $$L(y, f(x)) = \\frac{1}{n} \\sum^{n}_{i=1} exp[-y_if(x_i)]$$ Logistic（机器学习）形式： $$L(y,f(x))=\\sum_{l}y^l ln P(y^l=1|x^l,w)+(1-y^l)ln P(y^l=0|x^l,w) \\=\\sum_{l}y^l(w_0+\\sum^{n}{i=1}w_ix_i^l)-ln(1+exp(w_0+\\sum^{n}{i=1}w_ix_i^l))$$ Cross entropy形式： $$L(y,f(x)) = -\\sum^{n}_{i=1}y_i logf(x_i)$$ 8. 评价准则 评价准则：Acc, ROC, AP, Recall (TPR, true position rate), Precision, Bayes error, Bias-variance概念掌握Bayes error：取一个后验概率最大的去作为模型预测的输出Bias-variance：把模型的误差做一个偏执方差分解，需要直到模型的偏置和方差，以及是由什么决定的 PPT 3-4","link":"/2022/07/06/machine-learning/2022-07-06-review-pattern-recognition-courses/"},{"title":"","text":"���ʷ��෨ �������⣺�� �����������࣬omega_1 �� omega_2���� ����ĳ�������� X��Ҫô�� X in omega_1��Ҫô�� X in omega_2�� �� P(omega_1 |X) �� P(omega_2 |X)��P(omega_1 |X) + P(omega_2 |X) = 1�� �������⣺P(omega_1 |X) &gt; P(omega_2 |X) ���� X in omega_1�� ���ݱ�Ҷ˹��ʽ�� P(omega_1 |X) = P��X, omega_1) / P(X) = P��X|omega_1) P(omega_1)/ P(X) P(omega_2 |X) = P��X, omega_2) / P(X) = P��X|omega_2) P(omega_2)/ P(X) Ҫ�Ƚ�P(omega_1 |X) &gt; P(omega_2 |X)��ֻ��Ҫ�Ƚ���ʽ�ķ��ӡ� ���У�P(omega_1) �� P(omega_2) ���� omega ��������ʡ�P��X|omega_1) �� P��X|omega_2) ���� X �� omega �ϵ��������ʣ�P(omega_1 |X) �� P(omega_2 |X) ���� X �� W �ϵĺ�����ʡ� �˹����������������ʣ�����������ģ�� P(omega_1 |X) �� P(omega_2 |X)��������ˣ������Ա���Ҫ�ǳ���ע������ʡ�����ѵ��������ģ�ͣ�ѵ����ʱ���������忪�����ǲ��Ե�ʱ���һ�����ͻ���ֺܴ�����⡣Ҳ��������Ҫ�ڲ��Ժ�ѵ����ʱ��֤������������ǲ��ġ�ʵ��ʱ������һ�������������ҵĲ��裬��ԭ��Ҳ��������� ���������ص㡣��һ������������ӣ�����֪��������ʣ������������������һ�����ڴ�����£�����׼�� �� P��X|omega_1) &lt; P��X|omega_2) �� X in omega_2����֮ X in omega_1 ��ι��� P��X|omega) ������˵����һ�� X_i in omega������� P��X|omega) �����������������ܶȹ������⡣","link":"/2023/04/09/machine-learning/lec2_%E6%A6%82%E7%8E%87%E5%88%86%E7%B1%BB%E6%B3%95/"},{"title":"","text":"���ر�Ҷ˹��������Naive Bayesian Classifier�� ������������ ���� X ��ÿ��ά�ȶ�����ɢ�� �� X ��ÿ��ά�ȶ��Ƕ����ģ�������أ� �����и�Ӧ�ý������ʼ����࣬��һ���ļ���ֻ�����ࣨ�Ƿ��������ʼ����� ���룺һ���ʼ� d �����d in c_1 �� d in c_2 ѵ������ {(d_i, y_I)}_{i=1-N}��d={w1, w2, …, wn} ��ÿ���ʼ��������� ѧϰĿ�꣺P(d|c_1) �� P(d|c_2) P(d|C) = P({w1, w2, …, wn} | C) ������������������������������ �٣�w �����ﱻ����Ϊ���ʣ�������Ȼ�ܶ࣬��������Ŀ�����޵ģ���˿��Ա���ɢ��ʾ�������������� �ڣ���Ȼ���Ƕ����ģ���Ϊ�����뵥��֮����������ϵ�������������ʼ�������һ�򵥵���������Լ��� �ڳ�������һЩ��Ϊ���ӵı�������ʶ�𣬱㲻����ô���� P(d|C) = P({w1, w2, …, wp} | C) = [�۳� i in n]P(w_i|C) P(w_i|C_j) = count(w_i, c_j) / [�ۼ�w in V]count(w, c_j)������ j=1-2�� P(C_i) = count(C_i) / count(C) ��P(d|c_1)P(c_1) &gt; P(d|c_2)P(c_2) �� d in c_1�� �����ܴ����������������һ������δ��ѵ�����г��ֹ�����ô P(d|c) [����cȡ�ĸ�] ���� 0��Ϊ��ֹ����������Ľ����㹫ʽ���£� P(w_i|C_j) = count(w_i, c_j) + 1/ [�ۼ�w in V]count(w, c_j) + |V|������ j=1-2�� ��˹�ܶȺ��� ���� {x_i}_{i=1-n} in C��X_i ��һά����� $P(X|C) = \\frac{1}{\\sqrt{2\\pi \\sigma}}e ^ {- \\frac{(x-\\mu)^2}{2\\sigma^2}}$ $\\mu = \\frac{1}{N} \\sum^{N}_{i=1}X_i$ $\\sigma^2=\\frac{1}{N-1}\\sum^{N}_{i=1}(X_i-\\mu)^2$ [��ƫ����] �����һά�����������֤����ά������� $P(X|C)=\\frac{1}{\\sqrt{(2\\pi)^d |\\sum|}}exp[-\\frac{1}{2}(x-\\mu)^T\\sum^{-1}(x-\\mu)]$ ������� $\\sum $ �� $\\mu$�����ü�����Ȼ��������Ŀ�꺯���� $E(\\mu, \\sum)=\\sum^{N}_{i=1}lnP(x_i|C)$ ���ڼ��裺�� ���� {X_i}_{i=1-N} ����ͬ�ֲ� �� �趨 $\\mu$ ��$\\sum$ ʹ���� {x_i} �ĸ������ ���򣬾����֤���κ�ȥ�˽⡣ ������Ҫǿ�����㣬�����ʷ��෨Ҫ����ļ��㣺 �� ���� X �ĸ��ʷֲ��ľ�����ʽ��Ҳ������ P(X|C)�������������ʽ���У���һЩ���������������˹���ʷֲ���Ϊ $\\mu, \\sum$�� �� �ü��������Ȼ�������Ż�Ŀ�꺯���� �� �� �� �е��Ż����⣬��ô�������� ��Ȼ�����ڸ�˹�����Ǹ�͹�ĺ���������ֵ����ȫ�����ֵ�������ڿ���ֱ����΢������������ںܶ���������㲻�����ģ�����ô���أ������ݶ��½��ȵȡ� ��˹���ģ�� ��󣬾�������һ���㲻��������ֵ�����⡣Ҳ����ϸ�˹ģ�ͣ�Gaussian Mixture Model����","link":"/2023/04/09/machine-learning/lec3_%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1/"},{"title":"","text":"EM��Expectation-Maximization���㷨1. �����ֲ���ֵ���㷨��ֻ��ĳһ��ֲ���ֵ����ɽ⡣ �ŵ㣺�� ����Ҫ���κβ��� �� ��̼� ���⣺�������֪��ÿһ����������ĸ���˹�ֲ�����ô�����ܹ����׵ع���ÿ����˹�ֲ��ľ�ֵ�ͷ�������������ǲ�֪��ÿһ����������ĸ���˹�ֲ�����������ƣ�EM�㷨�� 2. GMM �е� EM�� ������������裺Ҫô a. �����ÿһ����ķֲ�������Ҫô b. �������˹�ֲ��Ĳ��� �� b. Ϊ����Ȼ�������Ĺ�����Ȼ�������˹�ֲ��Ĳ����� �� E-step�� �� M-step�� �� �ص� �ڣ�����ѭ����ֱ�������� 3. K-Means �е� EM�ٿ���һ�� EM �㷨������ ���� K-means�� �޼ලѧϰ��һ�֡� ���⣺���� N ������ {X_i}_{i=1-N}����� N ����������� {Z_i}_{i=1-N}�� ֤�� k-means �㷨�� ���ȶ�������һ��Ŀ�꺯���� Ȼ�󿴵� �� ���������� �� ������ʹ�� E ��С�� �ٿ��ǵ� �� ���� ���ڴ������������ ��ˣ��� �� ���ľ�ֵ��������Ҳ���� E ��С�����ϣ��� E �½� 0���������һ�� ���� ʹ�� E �����½����� E һ�������� 4. EM �㷨һ����ʽ�����������ӣ��ó� EM �㷨��һ����ʽ��������֪�����Ϸֲ���$$p(x,z;\\theta)$$���У�x �ǹ۲쵽�ı�����z ��Ǳ�ڱ���������Ҫ������������µĶ��������Ȼ���ƣ�$$\\theta = argmax_{\\theta}logp(x;\\theta)\\p(x;\\theta) = \\sum_{z}p(x,z;\\theta)$$��˹���ģ���е�����������ÿ��������ĳ����˹�ֲ��ĸ��� K-Means �е�����������ÿ�����Ƿ�����ĳ������ ͬ��ͬ���ȼ� ���� Jensen ����ʽ�Ƶ��������f(x) = logx��E(x) = log[] �������ڵĶ�������ô X �����Ǹ���ʽ�� ���һ������Ϊ�����½�ȼ��� E(theta)������������˵�ʽ���Ƶ���Ҳ����˵���ڵȼ۵�����£��������½������󻯶�����Ȼ�����ˡ� ���һ�е��Ƶ����£� ͨ�� E �����ҵ���ʹ�õȺų����� $Q_i(z^{(i)})$�������Ժ����ǾͿ������ E(f(x)) �ˣ�Ҳ���ǵȼ������ f(E(x))�� ���������Ƶ����õ� EM �㷨��һ����ʽ�� ֮����֤�� ����������һ��� EM �㷨�� kmeans �㷨�Ĺ����� z_i �Ķ��壺�� i �����ĸ����ࡣ Ϊʲô p ��ô���壿 ���һ�е�ʽ���� ֮�������΢�֣� �ܽ��ص㣺��ֵѡ�񲻺ûᵼ�²��õĽ�������������ֲ���ֵ�� �ο����ϣ� https://blog.csdn.net/Matrix_cc/article/details/105266141","link":"/2023/04/09/machine-learning/lec4_EM%E7%AE%97%E6%B3%95/"},{"title":"","text":"MAVROS 教程 —— Offboard 模式下自主飞行 AMOV 视频教程 1.1 工具链安装MAVROS 操作无人机的软硬件架构 Mavros 工具包可以把接收到的 Mavlink 消息（状态数据）转换成 ROS 消息发送给 ROS 系统，亦可以把 ROS 系统发送的 ROS 消息（控制消息）转换成 Mavlink 消息发送给飞控。 工具链：VMware 虚拟机 + 18.04 Ubuntu + ROS Melodic + mavros 包 + gazebo 仿真工具 ROS 安装 换源，如中科大、阿里、清华。vim(gedit) /etc/apt/source.list。 sudo apt-get update。sudo apt-get update 安装。最后两行代码容易失败，建议科学上网或者多试几次。 检验安装：roscore Mavros 安装 二进制安装：已经编译好的工具 源码安装[推荐]：安装。都是原始代码，必须编译成可以执行的二进制文件才可以执行，可以修改代码，进行开发等等。注：教程处用的是 kinetic 版本，实际中记得换成 melodic。 检验安装：roslaunch mavros px4.launch 1.2 ROS 创建节点与编译ROS 的通信方式： server 点对点，响应快 topic 多对多 ROS 文件系统组织 编译基于 catkin，CMakeList.txt 用于后续的编译。 常用命令 rospack 获取有关包的信息，本教程仅以 find 为例，返回包的路径。 rospack find [pacakge name] roscd 将目录改为包或堆栈，或者其子目录 roscd &lt;package-or-stack&gt;[/subdir] rosls 直接查看包中文件，或者其子目录 rosls &lt;package-or-stack&gt;[/subdir] 节点创建与编译 创建工作空间并进入 src。mkdir -p catkin_ws/src，cd catkin_ws/src 创建功能包。crakin_create_pkg [package-name] roscpp std_msgs roscpp：用 cpp 编译 std_msgs：用已有的数据结构 进入功能包的 src 并创建源文件。cd package-name/src。 回到上级目录，修改 CMakeLists.txt。 第一个参数是为生成的可以执行文件定义一个名字，第二个是默认的源代码目录，需要修改。 第一个参数需要和前者对应。 回到工作空间目录，编译。catkin build。会产生 build、devel 文件夹。 编译成功后，roscore，source ~/catkin_ws/devel/setup.sh。之后便可 rosrun [结点名]。 1.3 ROS 编程基础例程：简单的发布和订阅 [代码讲解] 运行方式（注意各个命令用独立的终端） roscore rosrun minimal_nodes[包名] minimal_publisher[节点名] rosrun minimal_nodes[包名] minimal_subscriber[节点名] rostopic list，rostopic info topic1[话题名]，rostopic hz topic1[话题名]。 例程：简单的控制器和仿真器 [代码讲解] 运行方式 roscore rosrun minimal_nodes[包名] minimal_simulator[节点名] rosrun minimal_nodes[包名] minimal_controller[节点名] 发送预定速度：rostopic pub -r 10[hz] vel_cmd[话题名] std_msgs/Float64[数据类型] 1.0 C++ 类的使用 ROS代码如果订阅很多个消息，发布多个消息的话，很快会变得过于冗长，若要提高代码效率和代码复用，最好使用类。 在头文件中定义类: 定义所有成员函数的原型 定义私有和公共数据成员 定义构造函数的原型 编写一个单独的实现文件 包含上面的头文件 包含已经声明成员函数的工作代码 包含在构造函数中封装的必要的初始化的代码 构建文件系统 在功能包目录下创建一个inlcude/minimal_controller_class [结点名]的文件夹 并在该文件夹下创建一个minimal_controller_class.h的文件 在src目录下创建minimal_controller_class.cpp文件 修改CMakeLists.txt，使得ros结点包含进include文件夹所包含的头文件 没看完，先跳过。 1.4 Mavros 消息的订阅与发布1.4.1 应用mavros控制无人机的消息流 如何去查阅mavros的消息与mavlink协议之间的关系 如何去找到mavlink协议与uorb消息之间的对应关系 1.4.2 example offboard例程的仿真与解析 使用gazebo进行软件在环仿真 搭载机载计算机的无人机的实际飞行测试 ENU 坐标系，z=2，升高两米。","link":"/2023/04/09/lab-experience/mavros-tutorials/MAVROS%20notes/"},{"title":"","text":"���������ɷ�ģ�ͣ�Hidden Markov Models��HMM�� һ��Ӧ�õ�����������ʶ�𡣶���һ�����������ǵ������ǣ���֪����ô���������Σ���֪��ÿ��״̬��ʱ���ж೤����Ҳ��֪��ÿ�������ζ�Ӧ�����֡� ����ǰ������⣬һ�����ܵķ������� kmeans �����࣬������״̬�������е���֮����ģ���ش��Ĵ��ڣ���ʵ����������ô����ʵ���У����� ni shi shui��һ�㲻�Ƿֳ� ni �� shi �� shui���Ữ�ֵظ�ϸ�� �����������ɷ�ģ�ͣ��൱��˵���ʱ������ѭ����˵�ǵ�ʱ������ѭ��… һ�� HMM ������������ɣ�lambda = {A, B, pi} Ϊ�˽�ģ���㣬��һ��ʱ��״ֻ̬��ǰһ��ʱ��״̬�йأ����������Ʒ�����������ǰ���״̬�� ÿ�����������ĸ��ʷֲ�һ����в�ͬ��GMMָ��˹���ģ�͡�b_j(O) ��ʾ�������� O ���� S_j �ĸ��ʡ� ���������壺����ֻ֪������� O�����ǲ�֪������״̬ Q��Q �Ǳ������� O ��ģ���Ҫ������������ġ� �����������������⡣ ��һ��ʶ�����⣨Evaluation�����ٸ����ӣ�����1-10������ʶ�𣬽���10��ģ�ͣ�����ÿ��ģ����һ��P��˭��P�󣬾�˵�����ĸ����֡� ��Щ����Ϊʲô��Ҫ�� b ����� pi ����� O1 ��״̬�� q1����ô����ͨ�� b ����� O1 ���� q1 �ĸ��ʡ����ǵؼ���һ�㣬���� b �����ȷ�еطֱ� O1 ��״̬������Ӧ��״̬ q1������ 1���Ƕ�Ӧ��״̬������ 0����ô��ô�������� q1 ״̬��ʼ�Ŀ����� pi ��û�����壬�ʸ���� pi ��һ�� 0�������˵������һ��������������ʣ��������ܱ����ϳ�ĳһ����һЩ�ض��Ĵʡ� ���ǵ�һ�� b ��������� O1 ��״̬�����ϵĸ��ʷֲ���Ҳ���� O1 ���ڸ���״̬�ĸ���ֵ������ O1 ������ p1 ���� s1����ô�ڵ�ǰ���� O1 �������� s1 ״̬�����ĸ��ʾ��ǵ���״̬ s1 �ĸ��ʳ���p1��ͬ���ģ����ǵڶ��� b ����� O2 ������ p2 ���� s2����ô�ڵ�ǰ���� O2 �������� s2 ״̬�����ĸ��ʾ��ǵ���״̬ s2 �ĸ��ʳ��� p2�� Ҳ���Ƕ���ĳ������ O��������� O ����ĳ��״̬�ĸ��ʣ��� O ����ĳ��״̬������Ȩ�أ��������뵽�����״̬�ĸ��ʡ� һ��ʼû�뵽 b ���ԭ�򣺰�����״̬������֪�ˡ���֪�����ȷʵû�� b ���Ϊ�ȼ��� 1��ͬʱҲû�� sum �������δ֪������£���Ҫ����ÿ������Ŀ����ԣ��ͻ��и��ʷֲ�������������֪������� 1��0��0��0 �ĸ��ʷֲ��� ��Ȼ�����������⣬��ʽ�ӻ���̫�����ˣ����������⡪������󷨡� alpha_t(i) ����Ϊ�����������ۻ��� t ʱ��ʱ���Ѹ�ʱ�̵���״̬���� s_i �����ĸ��ʡ� b_i(O_1) = P(O_1|q_t=s_i, lambda) ����Ϊ��O1 ����״̬������ s_i ������Ȩ�ء� �������Decoding���� ����һ�Ǹ���ģ�ͺ������������ڵ�ǰģ�͵������ƥ��������������ĳ̶ȣ������Ǹ���ģ�ͺ����������������������������ƥ�����״̬���С� ��������ά�ر��㷨�� ÿ��ʱ�䶼����ѡ p ��״̬�е�һ���������൱����ͼ����ÿ��ʱ���ѡһ��״̬��Ȼ�����һ��·����ѡ���Ӧ״̬�󣬼����Ӧ״̬�ļ�ֵ�� ÿ��ʱ��Σ�ÿ��������һʱ��ε����нڵ����ߣ�����ֵ���ڵ�ǰ�������ֵ�Լ�������ֵʱǰһ���������һ����������Ի��ݵõ�һ����õ�·�ߣ�Ҳ����һ������ E(Q)�� ά�ر��㷨���̣� ���ϵõ������� E(Q)�����൱�ڶ��ڸ�ÿ������� O ����һ����ǩ�� �������������Ϊһ������ HMM ģ�ʹ��ǩ�Ĳ������������ѧϰ���������ô�����ı�ǩ������ȵ����磬�Զ�ͨ�� O ѧϰ�����ǩ���Ӷ��滻���й۲�� b � ����������ѵ�����⣨Learning���� ��͹���������Ż����������������˼��㣺 b ���󷨣�","link":"/2023/04/09/machine-learning/lec5_%E9%9A%90%E5%90%AB%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B/"},{"title":"","text":"MINIMAL_NODEShere are source examples for minimal nodes, as covered in the text Part 1, Chapter 1. This package ncludes a minimal publisher, minimal subscriber, minimal simulator andminimal controller, as well as a launch file.","link":"/2023/04/09/lab-experience/mavros-tutorials/Amovlab%20MAVROS%20offboard/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/1-3minimal_nodes/1-3minimal_nodes/minimal_nodes/README/"},{"title":"","text":"Mavros 1. mavros 脚本语法123456&lt;launch&gt; &lt;node pkg=&quot;功能包的名字&quot; type=&quot;功能包下你想启动节点的名字&quot; name=&quot;对这个节点再命个名&quot; output=&quot;&quot;&gt; output 结果输出在屏幕上，没有这个参数默认记录在log里 &lt;param name=&quot;&quot;&gt; 传参:https://blog.csdn.net/taste_cyn/article/details/82737225 &lt;/node&gt;&lt;/launch&gt; 2. mavros 数据传输关注 px4_pos_estimator.cpp，可能是向飞控传飞机的姿态数据。他们传数据，都是用ros订阅的方式，飞控又是只看得懂mavlink协议里面的东西。所以飞控怎么拿数据呢？ main：先在从t265订阅（subscribe）的消息中，拿到飞机的姿态数据。 main：开辟一个话题（advertise），用以表示无人机的位置和姿态。 send_to_fcu：利用 publish 将消息发布。 问：mavros 通过订阅和发布实现消息的传输，飞控又遵循的是mavlink协议，所以飞控怎么拿数据呢？ 思路：应存在有一部分会发送 mavlink 消息，那收到 mavlink 消息前，有需要先收到 send_to_fcu 发送的 mavros 消息。既然有 publish，那就应该有 subscribe，那怎么找到哪里有 subscribe？ 1grep -r &quot;/mavros/vision_pose/pose&quot; 关注 vision_pose_esimate.cpp，该文件订阅了该消息，并将该消息封装成 mavlink 消息发给飞控。 3. PX4 &amp; Ardupilotpx4和ardupilot原本是两套独立的开源飞控，各自有软件和硬件。后来ardupilot看中了px4的硬件，就把代码移植到px4上了。所以目前px4和apm主流是运行在一种硬件上的两种软件。各自都是完备的系统。 px4是基于实时操作系统的，传感器采集、导航、控制、存储等等都是单独的应用程序，因此apm的代码也被封装成了一个应用程序，跟px4的代码栈在一起。而且apm还用到了一部分px4的底层应用。 飞控控制的想法：rospy + pymavlink。 虽然pymavlink好像是ardu家的实现，但底层其实有直接做px4兼容映射的。 这些标题下的例程，优先试试。试代码的时候记得不要无脑试，要验证 mavlink 能不能通。看设计痕迹，pymavlink还是有点针对ardupilot的。 https://www.ardusub.com/developers/pymavlink.html","link":"/2023/04/09/lab-experience/mavros-tutorials/MAVROS%20topics/"}],"tags":[],"categories":[{"name":"algorithm","slug":"algorithm","link":"/categories/algorithm/"},{"name":"others","slug":"others","link":"/categories/others/"},{"name":"courses","slug":"courses","link":"/categories/courses/"},{"name":"machine-learning","slug":"machine-learning","link":"/categories/machine-learning/"}]}