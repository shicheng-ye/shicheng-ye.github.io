{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/04/09/hello/hello-world/"},{"title":"[da] floyd","text":"Step 1. æ€è·¯å‡è®¾å›¾ä¸Šçš„ä»»æ„ä¸¤ä¸ªç‚¹ï¼Œå·²çŸ¥ä¸¤ç‚¹é—´çš„è·¯å¾„æƒå€¼ï¼Œå¦‚æœåœ¨å›¾ä¸­èƒ½å¤Ÿæ‰¾åˆ°ä¸€ä¸ªç‚¹, ä½¿å…¶æˆä¸ºä¸¤ç‚¹é—´çš„æ¡¥ç‚¹ï¼Œå¹¶ä¸”æ„æˆçš„æ–°è·¯å¾„å€¼å°äºæ—§è·¯å¾„å€¼ã€‚åˆ™æ–°è·¯æ¯”æ—§è·¯æ›´çŸ­ï¼Œç”±æ­¤å¯ä»¥å¾—åˆ°ä¸€ä¸ªé€’æ¨å…¬å¼ï¼š d[u][v]=min(d[u][v],d[u][k]+d[k][v]) Step 2. ä»£ç å®ç°1234for (int k = 1; k &lt;= n; k++) for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= n; j++) dis[i][j] = min(dis[i][j], dis[i][k] + dis[k][j]); Step 3. æ½œåœ¨ç–‘æƒ‘ç”±äºd[i][k]ï¼Œd[k][j]åœ¨ä¸æ–­æ›´æ–°ï¼Œè€Œä¸æ˜¯æ’å®šçš„æœ€å°å€¼ï¼Œæ‰€ä»¥å¦‚ä½•ä¿è¯d[i][j]åœ¨æœ€åä¸€æ¬¡æ›´æ–°çš„æ—¶å€™ï¼Œd[i][k]ï¼Œd[k][j]ä¸€å®šæ˜¯æœ€å°çš„ ? ä»¤ä»»æ„ä¸¤ç‚¹iå’Œjä¹‹é—´çš„è·¯å¾„ä¸Šå¯é€‰æ‹©ç»è¿‡çš„ç»“ç‚¹é›†åˆä¸­ï¼Œæ¡¥ç‚¹ç¼–å·æœ€å¤§çš„æ˜¯kï¼Œå½“k=xçš„æ—¶å€™ï¼Œd[i][j]å¾—åˆ°æœ€å°å€¼ã€‚ è®¾i-xä¸­çš„æ¡¥ç‚¹ç¼–å·æœ€å¤§çš„ä¸ºx1 ,x-jä¸­ç¼–å·æœ€å¤§çš„ä¸ºx2 æ˜“å¾—x&gt;x1 ,x&gt;x2â‘  å‡è®¾æ­¤æ—¶å‘½é¢˜æˆç«‹ï¼Œåˆ™x=$x_1$æ—¶ï¼Œd[i][x]æœ€å°ï¼Œx=x2 æ—¶ï¼Œd[x][j]æœ€å° ç”±æ­¤å¯ä»¥å¾—åˆ°x=kçš„æ—¶å€™d[i][x]+d[x][j]å·²ç»æ˜¯æœ€å°äº†,é‚£ä¹ˆe[i][j]=min(e[i][j]ï¼Œe[i][x]+e[x][j])å¿…ç„¶å¯ä»¥å¾—åˆ°æœ€å°å€¼ Step 4. åŸå…ˆçš„é”™è¯¯æƒ³æ³•ä»¥åŠæ›´æ­£å‡è®¾x1 &gt; k ï¼Œå½“ x = kï¼Œç”±äºd[i][k] è¿˜æœªå–å¾—æœ€å°å€¼, æ•…d[i][k] + d[k][j]å¹¶æ²¡æœ‰å–åˆ°æœ€å¤§å€¼ã€‚æ‰€ä»¥å‘½é¢˜â‘ é”™è¯¯ï¼Ÿäº‹å®ä¸Šå› ä¸ºi-jçš„æ¡¥ç‚¹ç¼–å·æœ€å¤§çš„å¿…ç„¶æ˜¯kï¼Œæ­¤æ—¶ä»¤ k = x1 , åˆ™ d[i][k]çš„æ¡¥ç‚¹ç¼–å·çš†å°äºk, æ•…å½“ x = k æ—¶ï¼Œd[i][k]å’Œd[k][j] ï¼Œå› æ­¤f[i][j]å¯ä»¥å–åˆ°æœ€å¤§å€¼ã€‚ å½“ x2 &gt; k æ—¶åŒç†ã€‚","link":"/2021/07/06/data-structure-algorithms/2021-07-06-floyd/"},{"title":"[da] fragmentary knowledge","text":"æ‚è®°+++ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 200 * 1000 + 11;int p[N];int d[N];vector&lt;int&gt; g[N];void dfs(int v, int pr = -1, int dst = 0) { d[v] = dst; p[v] = pr; for (auto to : g[v]) { if (to != pr) { dfs(to, v, dst + 1); } }}int main() {#ifdef _DEBUG freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin);#endif int n; scanf(&quot;%d&quot;, &amp;n); for (int i = 0; i &lt; n - 1; ++i) { int x, y; scanf(&quot;%d %d&quot;, &amp;x, &amp;y); --x, --y; g[x].push_back(y); g[y].push_back(x); } dfs(0); set&lt;pair&lt;int, int&gt;&gt; st; for (int i = 0; i &lt; n; ++i) { if (d[i] &gt; 2) { st.insert(make_pair(-d[i], i)); } } int ans = 0; while (!st.empty()) { int v = st.begin()-&gt;second; v = p[v]; ++ans; auto it = st.find(make_pair(-d[v], v)); if (it != st.end()) { st.erase(it); } for (auto to : g[v]) { auto it = st.find(make_pair(-d[to], to)); if (it != st.end()) { st.erase(it); } } } printf(&quot;%d\\n&quot;, ans); system(&quot;pause&quot;);} Memsetç®€ä»‹memset å‡½æ•°æ˜¯å†…å­˜èµ‹å€¼å‡½æ•°ï¼Œç”¨æ¥ç»™æŸä¸€å—å†…å­˜ç©ºé—´è¿›è¡Œèµ‹å€¼çš„ã€‚ åŸå‹ä¸º ï¼š 1void *memset(void *s, int v, size_t n); è¿™é‡Œså¯ä»¥æ˜¯æ•°ç»„åï¼Œä¹Ÿå¯ä»¥æ˜¯æŒ‡å‘æŸä¸€å†…åœ¨ç©ºé—´çš„æŒ‡é’ˆï¼›vä¸ºè¦å¡«å……çš„å€¼ï¼›nä¸ºè¦å¡«å……çš„å­—èŠ‚æ•°ï¼› åº”ç”¨â‘  æ•°ç»„ç½®0ï¼ˆé€šç”¨ï¼‰ 1memset(dp, 0, sizeof(dp)); â‘¡ æ— ç¬¦å·æ•´æ•°ç»„ç½®æœ€å€¼ å³æ¯ä¸ªå­—èŠ‚ç½®ä¸º 0xff 12memset(dp, 0xff, sizeof(dp)); â‘¢ æœ‰ç¬¦å·æ•´æ•°ç½®æœ€å€¼ï¼ˆmemsetèƒ½è¾¾åˆ°çš„æœ€å€¼ï¼‰ 12memset(dp, 0x7f, sizeof(dp));memset(arr,0x80,sizeof(arr)); //set int to -2139062144 â‘£ æœ‰ç¬¦å·æ•´æ•°ç½®-1 å³æ¯ä¸ªå­—èŠ‚å˜æˆ 0xffï¼ˆ-1è¡¥ç ï¼‰ 12memset(dp, -1, sizeof(dp));memset(dp, 0xff, sizeof(dp)); â‘¤ Doubleç½®æœ€å€¼ 12memset(arr,0x7F,sizeof(arr)); //set double to 1.38242e+306memset(arr,0xFE,sizeof(arr)); //set double to -5.31401e+303 DP198. House Robber 1234Input: nums = [2,7,9,3,1]Output: 12Explanation: Rob house 1 (money = 2), rob house 3 (money = 9) and rob house 5 (money = 1). Total amount you can rob = 2 + 9 + 1 = 12. åŠ¨æ€è½¬ç§»æ–¹ç¨‹ï¼š 12dp[i] = max(dp[i-1], dp[i-2] + nums[i]);// è‹¥ä¸æŠ¢è¿™å®¶ï¼Œé‚£ä¹ˆæœ¬æ¬¡æœ€å¤§å€¼ä¸ºä¸Šæ¬¡æœ€å¤§å€¼ï¼›åä¹‹ä¸ºä¸Šä¸Šæ¬¡æœ€å¤§å€¼ï¼‹è¿™æ¬¡ 746. Min Cost Climbing Stairs 123Input: cost = [1, 100, 1, 1, 1, 100, 1, 1, 100, 1]Output: 6Explanation: Cheapest is start on cost[0], and only step on 1s, skipping cost[3]. åŠ¨æ€è½¬ç§»æ–¹ç¨‹ï¼š 12dp[i] = min(dp[i-1] + cost[i-1], dp[i-2] + cost[i-2]);// åˆ°è¾¾iç‚¹æœ‰ä¸¤ç§æ–¹æ¡ˆï¼šè¦ä¹ˆä»å‰ä¸€æ¬¡è¿‡æ¥ï¼Œè¦ä¹ˆä»å‰å‰ä¸€æ ¼è¿‡æ¥ 53. Maximum Subarray 123Input: nums = [-2,1,-3,4,-1,2,1,-5,4]Output: 6Explanation: [4,-1,2,1] has the largest sum = 6. åŠ¨æ€è½¬ç§»æ–¹ç¨‹ï¼š 12dp[i] = (dp[i-1] &gt; 0 ? dp[i-1] + nums[i] : nums[i])//dp[i] ä»£è¡¨ä»¥å…ƒç´  nums[i] ä¸ºç»“å°¾çš„è¿ç»­å­æ•°ç»„æœ€å¤§å’Œã€‚ 392. Is Subsequence 12Input: s = &quot;abc&quot;, t = &quot;ahbgdc&quot;Output: true åŠ¨æ€è½¬ç§»æ–¹ç¨‹ï¼š 12dp[i] = (t[i] == s[dp[i-1]] ? dp[i-1]+1 : dp[i-1]);// dp[i] è¡¨ç¤ºtçš„ç¬¬iä½å·²åŒ¹é…è‡³sçš„dp[i]ä½ ç»å…¸dp 0-1èƒŒåŒ…ç»™ä½ ä¸€ä¸ªå¯è£…è½½é‡é‡ä¸ºWçš„èƒŒåŒ…å’ŒNä¸ªç‰©å“ï¼Œæ¯ä¸ªç‰©å“æœ‰é‡é‡å’Œä»·å€¼ä¸¤ä¸ªå±æ€§ã€‚å…¶ä¸­ç¬¬iä¸ªç‰©å“çš„é‡é‡ä¸ºwt[i]ï¼Œä»·å€¼ä¸ºval[i]ï¼Œç°åœ¨è®©ä½ ç”¨è¿™ä¸ªèƒŒåŒ…è£…ç‰©å“ï¼Œæœ€å¤šèƒ½è£…çš„ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ 123N = 3, W = 4wt = [2, 1, 3]val = [4, 2, 3] dp[i][w] çš„å®šä¹‰å¦‚ä¸‹ï¼šå¯¹äºå®¹é‡ä¸ºwçš„èƒŒåŒ…ï¼Œè£…å‰iä¸ªç‰©å“ï¼Œå¯ä»¥è£…çš„æœ€å¤§ä»·å€¼ã€‚ â‘  è‹¥ç¬¬iä¸ªç‰©å“çš„wt[i] &gt; wï¼Œé‚£ä¹ˆä¸€å®šä¸ä¼šæ‹¿å–ã€‚åˆ™å®¹é‡ä¸ºwçš„åŒ…è£…å‰iä¸ªç‰©å“å¯å¾—åˆ°çš„ä»·å€¼åˆ™ä¸ºå®¹é‡ä¸ºwçš„åŒ…è£…å‰i-1ä¸ªç‰©å“å¯å¾—åˆ°çš„ä»·å€¼ï¼Œå³dp[i][w] = dp[i-1][w]ã€‚ â‘¡ è‹¥ç¬¬iä¸ªç‰©å“çš„wt[i] &lt;= wï¼Œé‚£ä¹ˆåˆ™æœ‰ä»¥ä¸‹ä¸¤ç§æƒ…å†µ â€‹ a.ä¸æ‹¿ã€‚å®¹é‡ä¸ºwçš„åŒ…è£…å‰iä¸ªç‰©å“å¯å¾—åˆ°çš„å€¼åˆ™ä¸ºå®¹é‡ä¸ºwçš„åŒ…è£…å‰i-1ä¸ªç‰©å“å¯å¾—åˆ°çš„ä»·å€¼ï¼Œå³dp[i][w] = dp[i-1][w]ã€‚ â€‹ b.æ‹¿èµ°ã€‚å®¹é‡ä¸ºwçš„åŒ…è£…å‰iä¸ªç‰©å“å¯å¾—åˆ°çš„å€¼åˆ™ä¸ºå®¹é‡ä¸ºw-wt[i]çš„åŒ…è£…å‰i-1ä¸ªç‰©å“å¯å¾—åˆ°çš„ä»·å€¼+ç¬¬ié¡¹ç‰©å“çš„ä»·å€¼ï¼Œå³ dp[i][w] = dp[i - 1][w - wt[i-1]] + val[i-1]ã€‚ äºŒè€…å–æœ€ä¼˜è§£å³å¯ã€‚ 123456789101112131415161718int knapsack(int W, int N, vector&lt;int&gt;&amp; wt, vector&lt;int&gt;&amp; val) { // vector å…¨å¡«å…¥ 0ï¼Œbase case å·²åˆå§‹åŒ– vector&lt;vector&lt;int&gt;&gt; dp(N + 1, vector&lt;int&gt;(W + 1, 0)); for (int i = 1; i &lt;= N; i++) { for (int w = 1; w &lt;= W; w++) { if (w - wt[i-1] &lt; 0) { // å½“å‰èƒŒåŒ…å®¹é‡è£…ä¸ä¸‹ï¼Œåªèƒ½é€‰æ‹©ä¸è£…å…¥èƒŒåŒ… dp[i][w] = dp[i - 1][w]; } else { // è£…å…¥æˆ–è€…ä¸è£…å…¥èƒŒåŒ…ï¼Œæ‹©ä¼˜ dp[i][w] = max(dp[i - 1][w - wt[i-1]] + val[i-1], dp[i - 1][w]); } } } return dp[N][W];} P1048 é‡‡è¯","link":"/2021/07/06/data-structure-algorithms/2021-07-06-fragmentary-knowledge/"},{"title":"[da] graph-theory algorithm template","text":"Step 1. å»ºå›¾ + DFS/BFSP5318 ã€æ·±åŸº18.ä¾‹3ã€‘æŸ¥æ‰¾æ–‡çŒ® 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;bits/stdc++.h&gt;using namespace std;const int maxn = 100000 + 5;struct Edge{ int to, nxt;} e[maxn * 10];int head[maxn], tot, vst[maxn];vector&lt;pair&lt;int, int&gt; &gt; tmp;bool cmp(pair&lt;int, int&gt; x, pair&lt;int, int&gt; y){ //æ’åºè§„åˆ™ if(x.first == y.first) //vç›¸åŒæŒ‰uæ’åº return x.second &gt; y.second; else return x.first &gt; y.first; //å¦åˆ™æŒ‰vä»å¤§åˆ°å°æ’åº}void add(int u, int v){ e[++tot].to = v; e[tot].nxt = head[u]; head[u] = tot;}void bfs(int rt){ queue&lt;int&gt; q; q.push(rt); vst[rt] = 1; while (!q.empty()){ int u = q.front(); cout &lt;&lt; u &lt;&lt; &quot; &quot;; for (int i = head[u]; i != -1; i = e[i].nxt) { int v = e[i].to; if (!vst[v]){ q.push(v); vst[v] = 1; } } q.pop(); }}void dfs(int rt){ cout &lt;&lt; rt &lt;&lt; &quot; &quot;; vst[rt] = 1; for (int i = head[rt]; i != -1; i = e[i].nxt) { int v = e[i].to; if (!vst[v]){ //vst[v] = 1; dfs(v); } }}int main() { //freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin); ios::sync_with_stdio(false); memset(head, -1, sizeof(head)); int m, n; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; m; ++i){ int u, v; cin &gt;&gt; u &gt;&gt; v; tmp.push_back(make_pair(u, v)); } sort(tmp.begin(), tmp.end(), cmp); for (int i = 0; i &lt; m; ++i) { add(tmp[i].first, tmp[i].second); } dfs(1); cout &lt;&lt; endl; memset(vst, 0, sizeof(vst)); bfs(1); return 0;} Step 2. å»ºå›¾ + æ‹“æ‰‘æ’åºP4017 æœ€å¤§é£Ÿç‰©é“¾è®¡æ•° 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;bits/stdc++.h&gt;using namespace std;const int maxn = 5005;const int mod = 80112002;struct Edge{ int to, nxt;}e[maxn*100];int head[maxn], tot, ans, indegree[maxn], cnt[maxn];void add(int u, int v){ e[++tot].to = v; e[tot].nxt = head[u]; head[u] = tot;}void topo_sort(int n){ queue&lt;int&gt; q; for (int i = 1; i &lt;= n; ++i) { if (indegree[i] == 0) { q.push(i); cnt[i] = 1; } } while (!q.empty()){ int u = q.front(); q.pop(); if (head[u] == -1) ans = (ans + cnt[u]) % mod; for (int i = head[u]; i != -1; i = e[i].nxt) { int v = e[i].to; cnt[v] = (cnt[v] + cnt[u]) % mod; indegree[v]--; if (indegree[v] == 0){ q.push(v); } } }}int main() { //freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin); ios::sync_with_stdio(false); memset(head, -1, sizeof(head)); int n, m, u, v; cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; m; ++i){ cin &gt;&gt; u &gt;&gt; v; add(u, v); indegree[v]++; } topo_sort(n); cout &lt;&lt; ans &lt;&lt; endl; return 0;}","link":"/2021/07/06/data-structure-algorithms/2021-07-06-graph-theory-algorithm-template/"},{"title":"","text":"1. å‘½å Type Public Internal Modules lower_with_under _lower_with_under Packages lower_with_under Classes CapWords _CapWords Exceptions CapWords Functions lower_with_under() _lower_with_under Global/Class Constants CAPS_WITH_UNDER _CAPS_WITH_UNDER Global/Class Variables lower_with_under _lower_with_under Instance Variables lower_with_under _lower_with_under Method Names lower_with_under() _lower_with_under Function/Method Paramters lower_with_under Local Variables lower_with_under 2. å‡½æ•°é•¿åº¦ä¸€èˆ¬ä¸è¶…è¿‡ 40 è¡Œ 3. è¡Œé•¿åº¦ä¸€èˆ¬ä¸è¶…è¿‡ 80 ä¸ªå­—ç¬¦ 4. æ³¨é‡Š4.1 æ–‡æ¡£å­—ç¬¦ä¸²åŒ…ã€ç±»ã€æ¨¡å—æˆ–è€…å‡½æ•°çš„ç¬¬ä¸€å¥è¯ï¼Œä¸€èˆ¬ä½¿ç”¨ä¸‰é‡å¼•å·åŒ…è£¹ï¼Œå¯¹äºåªæœ‰ä¸€è¡Œçš„æ³¨é‡Šæ¥è¯´ï¼Œå°¾éƒ¨å¼•å·åº”è¯¥åœ¨åŒä¸€è¡Œã€‚å¯¹äºå¤šè¡Œæ³¨é‡Šä¸€èˆ¬æŒ‰å¦‚ä¸‹æ–¹å¼ç»„ç»‡ï¼šé¦–å…ˆæ˜¯ä¸€è¡Œä»¥å¥å·ï¼Œé—®å·æˆ–æƒŠå¹å·ç»“å°¾çš„æ¦‚è¿°ã€‚æ¥ç€æ˜¯ä¸€ä¸ªç©ºè¡Œï¼Œç„¶åæ˜¯æ–‡æ¡£å­—ç¬¦ä¸²å‰©ä¸‹çš„éƒ¨åˆ†ï¼Œå®ƒåº”è¯¥ä¸æ–‡æ¡£å­—ç¬¦ä¸²çš„ç¬¬ä¸€è¡Œçš„ç¬¬ä¸€ä¸ªå¼•å·å¯¹é½ã€‚ 123456789&quot;&quot;&quot;A one line summary of the module or program, terminated by a period.Leave one blank line. The rest of this docstring should contain anoverall description of the module or program. Optionally, it may alsocontain a brief description of exported classes and functions and/or usageexamples.Typical usage example:foo= CLa55Foo()bar = foo.FunctionBar()&quot;&quot;&quot; 4.2 å—æ³¨é‡Šæˆ–è¡Œæ³¨é‡Šå¯¹äºå¤æ‚çš„æ“ä½œï¼Œåº”è¯¥åœ¨å…¶æ“ä½œå¼€å§‹å‰å†™ä¸Šè‹¥å¹²è¡Œæ³¨é‡Šã€‚å¯¹äºä¸æ˜¯ä¸€ç›®äº†ç„¶çš„ä»£ç ï¼Œåº”åœ¨å…¶è¡Œå°¾æ·»åŠ æ³¨é‡Šã€‚ 123456# We use a weighted dictionary search to find out where i is in# the array. We extrapolate position based on the largest num# in the array and the array size and then do binary search to# get the exact numberif i &amp; (i-1) == 0: # True if i is 0 or a power of 2. ä¸ºäº†æé«˜å¯è¯»æ€§ï¼Œæ³¨é‡Šåº”è¯¥è‡³å°‘ç¦»å¼€ä»£ç  2 ä¸ªç©ºæ ¼ã€‚ 5. ç©ºè¡Œé¡¶çº§å®šä¹‰ä¹‹é—´ç©ºä¸¤è¡Œï¼Œæ¯”å¦‚å‡½æ•°æˆ–è€…ç±»å®šä¹‰ã€‚æ–¹æ³•å®šä¹‰ï¼Œç±»å®šä¹‰ä¸ç¬¬ä¸€ä¸ªæ–¹æ³•ä¹‹é—´ï¼Œéƒ½åº”è¯¥ç©ºä¸€è¡Œã€‚å‡½æ•°æˆ–æ–¹æ³•ä¸­ï¼ŒæŸäº›åœ°æ–¹è¦æ˜¯ä½ è§‰å¾—åˆé€‚ï¼Œå°±ç©ºè¡Œã€‚","link":"/2023/04/09/lab-experience/code-style/"},{"title":"","text":"sshè¿æ¥ï¼šfinalshell+æŒ‡ä»¤æ“ä½œï¼Ÿ å…¬é’¥ç™»å½•ã€‚ æ·»åŠ å…¬é’¥ï¼Œè¿™ä¸€æ®µæ˜¯å†™ç»™åœ¨æœåŠ¡å™¨ä¸Šå·²ç»æœ‰è´¦å·çš„ã€‚åä¹‹ï¼Œcd home+mkdir ç”¨æˆ·åã€‚ æ‹¿åˆ°æ–°çš„å…¬é’¥ï¼Œå¹¶ä¸”åˆ›å»ºæ–°çš„è´¦å·çš„æ–‡ä»¶å¤¹åº•ä¸‹ shell) å…ˆæŸ¥çœ‹æ–‡ä»¶å¤¹ä¸‹æ˜¯å¦å­˜åœ¨.sshæ–‡ä»¶å¤¹ å¦åˆ™è¿è¡Œsudo mkdir ./.ssh ç„¶åå°†å…¬é’¥id_rsa.pubä¸Šä¼ åˆ°å¯¹åº”çš„è´¦æˆ·çš„.sshæ–‡ä»¶å¤¹ä¸‹ï¼Œå¹¶ä¸”æ”¹åä¸ºauthorized_keys ç”¨ sudo chown ç”¨æˆ·å authorized_keys ä¿®æ”¹å…¬é’¥çš„æ‰€æœ‰äºº ç”¨ sudo chmod 600 authorized_keys ç»™å…¬é’¥æ·»åŠ è¿è¡Œæƒé™ Vimï¼šBundleï¼ŒNerdtreeï¼ŒTagBarï¼Œjedi-python jupyterlabçš„å…³é—­ï¼šps -ef|grep jupyter|awk {â€˜print $2â€™}|xargs kill svnæ“ä½œï¼šæƒé™ä¿®æ”¹ï¼Œæ–‡ä»¶å¤¹åˆ›å»º frpè´¦å·å¯†ç ï¼šnomad + nomad123 jupyterå¯†ç ï¼šLab504jupyter sudoæ“ä½œï¼šub-d504 + lab504ubd tail nohup.outï¼šåœ¨å½“å‰è·¯å¾„ç”Ÿæˆä¸€ä¸ªnohup.out æŸ¥çœ‹è¿›ç¨‹ï¼štop htop ps -ef grep pstree 2å·æœåˆ‡æ¢åˆ°asusè´¦æˆ·ï¼š â€‹ su asus + D504y2021 â€‹ ssh ub-d504@192.169.0.200 ç„¶åå¯ä»¥é€šè¿‡è¯¥æ–¹å¼ï¼Œsshåˆ°1å·æœ ä»1å·æœcopyæ–‡ä»¶åˆ°2å·æœä½¿ç”¨scp linuxåŸºæœ¬æ“ä½œ æœåŠ¡å™¨ä¸Šä¼ ä¸‹è½½æ–‡ä»¶ï¼šscp å…¬é’¥ä¸ç§é’¥ï¼šå…¬é’¥åŠ å¯†ï¼Œç§é’¥è§£å¯†ã€‚ç§é’¥ç­¾åï¼Œå…¬é’¥éªŒè¯ã€‚ SSHå¯¹äºå…¬é’¥å’Œç§é’¥çš„ç”¨æ³•ï¼šhttps://blog.csdn.net/qq_34649947/article/details/80140465 https://blog.csdn.net/csm201314/article/details/78453579 ç»ˆç«¯ï¼šäººä¸æœºå™¨äº¤äº’çš„æ¥å£ã€‚ç»ˆç«¯å…·æœ‰ä¸¤ä¸ªåŸºæœ¬åŠŸèƒ½ï¼šå‘ä¸»æœºè¾“å…¥ä¿¡æ¯å’Œå‘å¤–éƒ¨è¾“å‡ºä¿¡æ¯ã€‚æ‰€ä»¥ç»ˆç«¯å¯ä»¥åˆ†ä¸ºè¾“å…¥è®¾å¤‡å’Œè¾“å‡ºè®¾å¤‡ã€‚ sshï¼šSecure Shellï¼ˆå®‰å…¨å¤–å£³åè®®ï¼‰ï¼Œä¸ºå»ºç«‹åœ¨åº”ç”¨å±‚åŸºç¡€ä¸Šçš„å¯é ï¼Œä¸“ä¸ºè¿œç¨‹ç™»å½•ä¼šè¯å’Œå…¶ä»–ç½‘ç»œæœåŠ¡æä¾›å®‰å…¨æ€§çš„åè®®ã€‚è¿ç”¨å¦‚finalshellã€‚ ç«¯å£ï¼šå®¢æˆ·ç«¯å¯ä»¥é€šè¿‡ipåœ°å€æ‰¾åˆ°å¯¹åº”çš„æœåŠ¡å™¨ç«¯ï¼Œä½†æ˜¯æœåŠ¡å™¨ç«¯æ˜¯æœ‰å¾ˆå¤šç«¯å£çš„ï¼Œæ¯ä¸ªåº”ç”¨ç¨‹åºå¯¹åº”ä¸€ä¸ªç«¯å£å·ï¼Œé€šè¿‡ç«¯å£å·ï¼Œå®¢æˆ·ç«¯æ‰èƒ½çœŸæ­£çš„è®¿é—®åˆ°è¯¥æœåŠ¡å™¨ã€‚ å®šæ—¶å™¨ï¼škeep aliveä¿æ´»æœºåˆ¶ï¼Ÿ é˜²ç«å¢™ï¼šå°±æ˜¯ä¸“é—¨ç»™æœåŠ¡å™¨æä¾›é˜²å¾¡ã€ä¿éšœæ•°æ®å®‰å…¨çš„é˜²ç«å¢™ã€‚ frpï¼Œsvnï¼Œjupyterç»´æŠ¤ï¼šhttp://39.107.92.9:5636/dokuwiki/doku.php?id=term_script szï¼šä»Linuxä¸‹è½½æ–‡ä»¶åˆ°æœ¬æœº , åœ¨Linuxç»ˆç«¯è¾“å…¥å‘½ä»¤å›è½¦åï¼Œé€‰æ‹©æœ¬åœ°å­˜å‚¨è·¯å¾„å³å¯ã€‚ 123å‘½ä»¤æ ¼å¼ï¼š sz filename ä¸‹è½½æ–‡ä»¶filename sz file1 file2 ä¸‹è½½å¤šä¸ªæ–‡ä»¶ sz dir/* ä¸‹è½½dirç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶ rzï¼šä»æœ¬åœ°ä¸Šä¼ æ–‡ä»¶åˆ°Linuxï¼Œåœ¨Linuxç»ˆç«¯è¾“å…¥å‘½ä»¤å›è½¦åï¼Œé€‰æ‹©æœ¬åœ°è¦ä¸Šä¼ çš„æ–‡ä»¶å³å¯ï¼Œå¯ä¸€æ¬¡æŒ‡å®šå¤šä¸ªæ–‡ä»¶ scpï¼šLinux scp å‘½ä»¤ç”¨äº Linux ä¹‹é—´å¤åˆ¶æ–‡ä»¶å’Œç›®å½• https://www.runoob.com/linux/linux-comm-scp.html 123456789scpï¼Œszï¼Œrz nc # Netcat (ç½‘ç»œåˆ€)ï¼Œç«¯å£æ‰«æï¼Œè¿œç¨‹æ‹·è´ç­‰ç­‰ # https://blog.csdn.net/freeking101/article/details/53289198vimcat # æŸ¥çœ‹æ–‡ä»¶å†…å®¹grep # grep jupyterå¯¹äºè¾“å…¥è¿›æ¥çš„å†…å®¹ï¼ŒæŒ‰è¡ŒæŸ¥æ‰¾åŒ…å«â€œjupyterâ€çš„å†…å®¹å¹¶è¾“å‡ºps -ef # psæŸ¥çœ‹è¿›ç¨‹ -eä»£è¡¨æ˜¾ç¤ºæ‰€æœ‰è¿›ç¨‹ -fä»£è¡¨å…¨æ ¼å¼kill nohup {} &amp; # ä½¿åå°è¿è¡Œï¼Œè¿è¡Œæ—¥å¿—è¾“å‡ºåˆ°å½“å‰ç›®å½•çš„nohup.out å…³æ³¨æœåŠ¡å™¨çŠ¶æ€çš„æŒ‡ä»¤ï¼šhtop + nvidia-smi nvidia-smiï¼šæ˜¾ç¤ºGPUå½“å‰çš„çŠ¶æ€ã€‚è®­ç»ƒçš„æ—¶å€™ï¼Œå¯ä»¥ç”¨è¿™æ¡æŒ‡ä»¤æ¯éš”1ç§’çœ‹ä¸€ä¸‹æ˜¾å¡çŠ¶æ€ï¼šwatch -n 1 â€˜nvidia-smiâ€™ htopï¼šæ˜¯Linuxç³»ç»Ÿä¸­çš„ä¸€ä¸ªäº’åŠ¨çš„è¿›ç¨‹æŸ¥çœ‹å™¨ vscodeå…³é—­æ–‡ä»¶å¤¹ï¼š[Ctrl + K F] ä¸²å£è°ƒè¯• armç›¸æœºçš„åŒ… å¼€å­¦ä¸¤å‘¨çªç ´ tail nohup.outï¼šåœ¨å½“å‰è·¯å¾„ç”Ÿæˆä¸€ä¸ªnohup.out top htop ps -ef grep pstreeï¼šæŸ¥çœ‹è¿›ç¨‹ scp -r /root/lk root@43.224.34.73:/home/lk/cpfileï¼šLinux ä¹‹é—´æ‹·è´Secure Copy nautilus /fileï¼šç»ˆç«¯æ‰“å¼€æ–‡ä»¶ æ“ä½œæœåŠ¡å™¨æ—¶é‡åˆ°çš„é—®é¢˜é¼ æ ‡ä¸è§äº†/å¡æ­»ï¼Ÿctrl+alt+f1 å›åˆ°ç™»é™†ç•Œé¢ï¼Œé‡æ–°ç™»å½•ã€‚ ç»ˆç«¯å¦‚ä½•ç²˜è´´ï¼Ÿctrl+shift+vã€‚ æ‰¾ä¸åˆ°homeï¼Ÿç‚¹å¼€æ–‡ä»¶ç•Œé¢ï¼Œå·¦ä¾§æœ€ä¸‹æ ã€‚","link":"/2023/04/09/lab-experience/lab-notes/"},{"title":"","text":"Q-learning ä¸ºä»€ä¹ˆä¸ç”¨é‡è¦æ€§é‡‡æ ·ï¼ŸQ-learning æ˜¯å•æ­¥æ›´æ–°çš„ï¼Œtargetæ˜¯ç›´æ¥è·å¾—çš„ï¼Œè€Œä¸æ˜¯æ ¹æ®ç­–ç•¥æ¥ä¸‹æ¥å¾—åˆ°çš„ã€‚åä¹‹ï¼ŒTD(2)åŠä»¥ä¸Šå°±éœ€è¦é‡è¦æ€§é‡‡æ ·ã€‚ softmax æº¢å‡ºé—®é¢˜ï¼šeçš„10000æ¬¡æ–¹ï¼Œpytorchçš„æºç æ€ä¹ˆå¤„ç†çš„ï¼Ÿæ•°åˆ—æ‰€æœ‰æ•°å‡å»æ•°åˆ—çš„æœ€å¤§å€¼ï¼Œè¿™æ ·å’Œå‡ä¹‹å‰ä¸€æ¨¡ä¸€æ ·çš„ã€‚","link":"/2023/04/09/lab-experience/rl-notes/"},{"title":"","text":"æœåŠ¡å™¨åŸºæœ¬æ“ä½œæœåŠ¡å™¨ä¸Šçš„æœåŠ¡ ä¸€å·æœ äºŒå·æœ frpc frpc dokuwiki jupyterlab svn frpcæœåŠ¡ä½ç½®ï¼š /home/chensiji/ ï¼ˆå¦‚æœæ˜¯æœåŠ¡å™¨2ä½ç½®æ˜¯/home/asusï¼‰ 1.å¼€å¯æœåŠ¡æŒ‡ä»¤ï¼šnohup ./frpc -c frpc.ini &amp; *å¦‚æœæ˜¾ç¤ºæ— æ³•æ‰§è¡Œè¯¥æŒ‡ä»¤ï¼Œå¯ä»¥åœ¨å¼€å¤´åŠ ä¸ªsudo è§£é‡Šï¼š ./ æ‰§è¡Œ frpc å¯æ‰§è¡Œæ–‡ä»¶frpc -c ä½¿ç”¨é…ç½®æ–‡ä»¶ frpc.ini é…ç½®æ–‡ä»¶åç§° nohup {} &amp; ä½¿åå°è¿è¡Œï¼Œè¿è¡Œæ—¥å¿—è¾“å‡ºåˆ°å½“å‰ç›®å½•çš„nohup.out 2.æŸ¥çœ‹é…ç½®æ–‡ä»¶ï¼šcat frpc.ini ä¼šæ˜¾ç¤ºç±»ä¼¼å¦‚ä¸‹çš„å†…å®¹ï¼š [common] server_addr = 39.107.92.9 server_port = 7000 [ssh] type = tcp local_ip = 192.169.0.200 local_port = 22 â€¦ 3.å…³é—­è¿›ç¨‹ï¼š é¦–å…ˆç”¨å¦‚ä¸‹æŒ‡ä»¤æŸ¥çœ‹å½“å‰æ­£åœ¨è¿è¡Œçš„è¿›ç¨‹å·ï¼š ps -ef|grep frp ä¸Šå›¾ä¸­æ˜¾ç¤ºçš„11665ã€11666é‚£ä¸€åˆ—çš„æ•°å­—ä¸ºè¿›ç¨‹çš„è¿›ç¨‹å·ã€‚æ ¹æ®è¿›ç¨‹å·æˆ‘ä»¬å¯ä»¥å…³é—­ç›¸åº”çš„è¿›ç¨‹ã€‚ æ­£å¸¸å…³é—­ï¼šsudo kill &lt;è¿›ç¨‹å·&gt; å¼ºåˆ¶å…³é—­: sudo kill -9 &lt;è¿›ç¨‹å·&gt; åœ¨å°†ä¸Šè¿°æ‰€æœ‰è¿›ç¨‹éƒ½â€™killâ€™åï¼Œå¯ä»¥å‘ç°ä¼—å¤šæœåŠ¡çš„ç½‘ç»œè¿æ¥éƒ½å¤±æ•ˆäº†ï¼ˆgrepé‚£ä¸ªè¿›ç¨‹ä¸ç”¨â€™killâ€™ï¼ŒæŸ¥è¯¢è¿‡ç¨‹æœ¬èº«å°±æ˜¯ä¸ªè¿›ç¨‹ï¼‰ï¼š ä¹‹åéœ€è¦ç”¨å¼€å¯æœåŠ¡çš„æŒ‡ä»¤å¼€å¯è¿™éƒ¨åˆ†æœåŠ¡(è§1) dokuwikiä¸ç”¨ç»´æŠ¤ï¼Œå¼€æœºå°±æœ‰ jupyterlabéœ€è¦å…ˆåˆ‡æ¢åˆ°ç”¨æˆ·ub-d504ï¼Œå› ä¸ºä¹‹å‰çš„æ–‡ä»¶éƒ½åœ¨è¿™ä¸ªç”¨æˆ·ä¸‹å¼€å¯çš„ï¼Œç”¨åˆ«çš„ç”¨æˆ·åœ¨åŒæ ·ä½ç½®å¯åŠ¨jupyter labå¯èƒ½ä¼šå¯¼è‡´æƒé™è®¿é—®é—®é¢˜åˆ‡æ¢ç”¨æˆ·ï¼š su ub-d504ï¼ˆç”¨æˆ·åï¼‰ *å¯†ç å¯ä»¥è¯¢é—®æœ‰å…³è´Ÿè´£äºº éœ€è¦å…ˆè¿›å…¥condaç¯å¢ƒï¼Œæ‰èƒ½ä½¿ç”¨æŒ‡ä»¤ï¼Œå› ä¸ºæˆ‘ä»¬çš„jupyteræ˜¯å®‰è£…condaæ—¶é™„å¸¦çš„æœåŠ¡*å…·ä½“å¯è§condaéƒ¨åˆ† 1.å¯åŠ¨æŒ‡ä»¤ nohup jupyter lab &amp; è¦è®©jupyter labåœ¨åå°è¿è¡Œï¼Œå¦åˆ™é€€å‡ºç›´è¿è¿æ¥åjupyter labçš„æœåŠ¡ä¹Ÿå¤±æ•ˆã€‚ 2.å…³é—­è¿›ç¨‹ ps -ef|grep jupyter|awk {â€˜print $2â€™}|xargs kill è§£é‡Šï¼š ç®¡é“ç¬¦å·ï¼Œå°†å‰è€…çš„è¾“å‡ºä½œä¸ºåè€…çš„è¾“å…¥ grep jupyter å¯¹äºè¾“å…¥è¿›æ¥çš„å†…å®¹ï¼ŒæŒ‰è¡ŒæŸ¥æ‰¾åŒ…å«â€jupyterâ€çš„å†…å®¹å¹¶è¾“å‡º awk {â€˜print $2â€™} æŠŠè¾“å…¥æŒ‰ç©ºæ ¼åˆ†å¼€æˆå¤šé¡¹ï¼Œæ‰“å°ç¬¬äºŒé¡¹ xargs æŠŠå‰é¢çš„è¾“å…¥ä½œä¸ºåé¢å‘½ä»¤çš„å‚æ•° kill ç›´æ¥æ ¹æ®è¿›ç¨‹å·å…³é—­è¿›ç¨‹ svnä½ç½® /srv/svn_repo/Lab 1.å¯åŠ¨æŒ‡ä»¤ sudo svnserve -d -r /srv/svn_repo â€“listen-port 3501 -d: å·²å®ˆæŠ¤æ¨¡å¼å¯åŠ¨ -rï¼šæŒ‡å®šsvnç‰ˆæœ¬åº“æ ¹ç›®å½•ï¼Œè¿™æ ·æ˜¯ä¾¿äºå®¢æˆ·ç«¯ä¸ç”¨è¾“å…¥å…¨è·¯å¾„å°±å¯ä»¥è®¿é—®ç‰ˆæœ¬åº“ 2.åœæ­¢æœåŠ¡ ps -ef|grep svn æŸ¥è¯¢è¿›ç¨‹å· kill &lt;è¿›ç¨‹å·&gt;","link":"/2023/04/09/lab-experience/server-operation/"},{"title":"","text":"YouCompleteMe å®‰è£…github é¡¹ç›®åœ°å€ï¼šhttps://github.com/ycm-core/YouCompleteMe è¯¥é¡¹ç›®æœ‰å­æ¨¡å—ï¼Œgithub è¢«å¢™çš„æƒ…å†µä¸‹å¾ˆéš¾å…‹éš†ã€‚æˆ‘ ssh è¿æ¥å¯¼å®éªŒå®¤çš„æ— äººæœºä¸ºä¹‹ vim é…ç½®è¯¥æ’ä»¶ï¼Œä¸æ˜¯å¾ˆæ‡‚æ€ä¹ˆå‘½ä»¤è¡Œç¿»å¢™ã€‚å› æ­¤ï¼Œæˆ‘æ˜¯æœ¬åœ°ç”µè„‘ç¿»å¢™å…‹éš†åï¼Œå†è¾“å…¥å¦‚ä¸‹æŒ‡ä»¤å…‹éš†å®ƒçš„å­æ¨¡å—ã€‚ 1git submodule update --init --recursive é’ˆå¯¹ github è¢«å¢™ï¼Œå¯ç”¨å·¥å…·ï¼šdev-sidecarï¼Œpigchaã€‚ å…‹éš†äº†å­æ¨¡å—åï¼Œä¸Šä¼ è‡³ onedriveï¼Œå¹¶è·å–ä¸‹è½½é“¾æ¥ã€‚åœ¨ linux ç»ˆç«¯è¾“å…¥å¦‚ä¸‹æŒ‡ä»¤ä¸‹è½½ï¼š 1wget -c &lt;url&gt; -O &lt;/path/name&gt; è§£å‹ zip 1unzip &lt;filename&gt; æŒ‰æ•™ç¨‹å®‰è£…ä¾èµ–åŒ…ï¼šhttps://github.com/ycm-core/YouCompleteMe#linux-64-bit åœ¨ .vimrc ä¸­åŠ å…¥ ycm-core/YouCompleteMe åï¼Œç¼–è¯‘ YCMã€‚ 1234cd ~/.vim/bundle/YouCompleteMepython3 install.py --all(æ‰€æœ‰è¯­è¨€è¯­æ³•æ£€æŸ¥) or python3 install.py --clangd-completer(Cç³»åˆ—è¯­è¨€è¯­æ³•æ£€æŸ¥) or python3 install.py (æ²¡æœ‰è¯­æ³•æ£€æŸ¥) å¯èƒ½å‡ºç°çš„é—®é¢˜ï¼š Your C++ compiler does NOT fully support C++17 è§£å†³ï¼šhttps://stackoverflow.com/questions/65284572/your-c-compiler-does-not-fully-support-c17 ä¸‹è½½ clangdï¼šhttps://www.cnblogs.com/zi-wang/p/13550305.html ç¼–è¯‘ç”Ÿæˆ ycm_coreï¼Œhttps://github.com/ycm-core/YouCompleteMe/wiki/Full-Installation-Guide æ³¨æ„ï¼šæ›´æ–° Vim è‡³ 8.1 å…ˆå…‹éš† 8.1.2424 ç‰ˆæœ¬çš„ vim 1git clone -b &lt;tag&gt; url æŒ‰ç…§å¦‚ä¸‹æ•™ç¨‹é…ç½®ï¼šhttps://github.com/ycm-core/YouCompleteMe/wiki/Building-Vim-from-source æŸ¥çœ‹ç‰ˆæœ¬ 1vim --version |grep VIM æŸ¥çœ‹æ˜¯å¦æ”¯æŒ python3 1vim --version |grep python","link":"/2023/04/09/lab-experience/youcompleteme-installation/"},{"title":"[ml][rv] domain adaptation","text":"27 Domain Adaptationè®­ç»ƒèµ„æ–™è·Ÿæµ‹è¯•èµ„æ–™çš„åˆ†å¸ƒæ˜¯ä¸ä¸€æ ·çš„ï¼Œå«åš ==Domain Shift==ã€‚ è§£å†³åŠæ³•æ˜¯ ==Domain Adaptation==ï¼Œå®ƒä¹Ÿå¯ä»¥çœ‹åšæ˜¯ ==Transfer Learning== çš„ä¸€ç§ã€‚ Transfer Learning ï¼šåœ¨ A ä»»åŠ¡ä¸Šå­¦åˆ°çš„æŠ€èƒ½å¯ä»¥è¢«ç”¨åœ¨ B ä»»åŠ¡ä¸Š Domain Adaptationï¼šä½ çš„è®­ç»ƒèµ„æ–™æ˜¯ä¸€ä¸ª Domainï¼Œä½ çš„æµ‹è¯•èµ„æ–™æ˜¯å¦å¤–ä¸€ä¸ª Domainï¼Œä½ åœ¨è®­ç»ƒèµ„æ–™ä¸Šé¢å­¦åˆ°çš„èµ„è®¯å¯ä»¥è¦æŠŠå®ƒç”¨åˆ°å¦å¤–ä¸€ä¸ª Domain ä¸Šã€‚ Domain Shiftä¸¤è€…å¯èƒ½æƒ…å†µã€‚ä¸€ï¼Œè¾“å…¥èµ„æ–™å³è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ†å¸ƒä¸åŒã€‚äºŒï¼Œè¾“å…¥è·Ÿè¾“å‡ºè™½ç„¶åˆ†å¸ƒç›¸åŒçš„ï¼Œä½†å®ƒä»¬ä¹‹é—´çš„å…³ä¿‚å˜äº†ï¼Œæ¯”å¦‚è®­ç»ƒé›†å«åš 0 çš„ä¸œè¥¿åœ¨æµ‹è¯•é›†é‡Œå«åš 1ã€‚ ä»Šå¤©åªè€ƒè™‘å‰è€…ã€‚è®°æµ‹è¯•é›†ä¸º ==Target Domain==ï¼Œè®­ç»ƒé›†ä¸º ==Source Domain==ã€‚ Domain Adaptationåˆ†ä¸‰ç§æƒ…å†µè€ƒè™‘ï¼š å…¶ä¸€ï¼Œåœ¨ Target Domain ä¸Šæœ‰ä¸€å¤§å †çš„èµ„æ–™ä¸”é…æœ‰ Labelï¼Œé‚£å°±ç›´æ¥æ‹¿ Target Domain çš„èµ„æ–™æ¥è®­ç»ƒã€‚ å…¶äºŒï¼Œåœ¨ Target Domain ä¸Šæœ‰ä¸€ç‚¹ç‚¹çš„èµ„æ–™ä¸”é…æœ‰ Labelï¼Œé‚£å°±æ‹¿ä»–ä»¬æ¥å¾®è°ƒï¼Œå³ä¸è¦åœ¨ Target Domain ä¸Šçš„èµ„æ–™ä¸Šè·‘å¤ªå¤šçš„ Iterationã€‚ å…¶ä¸‰ï¼Œåœ¨ Target Domain ä¸Šæœ‰ä¸€å¤§å †çš„èµ„æ–™ä½†æ²¡æœ‰ Labelã€‚æ‰¾ä¸ª Feature Extractorï¼Œå®ƒä¼šæŠŠ Source å’Œ Target ä¸ä¸€æ ·çš„éƒ¨åˆ†æ‹¿æ‰ï¼ŒåªæŠ½å–å‡ºå®ƒä»¬å…±åŒçš„éƒ¨åˆ†ã€‚ å…¶å››ï¼Œåœ¨ Target Domain ä¸Šæœ‰ä¸€ç‚¹ç‚¹çš„èµ„æ–™ä¸”æ²¡æœ‰ Labelã€‚æœ‰ä¸€ä¸ªæ–¹æ³•å«åš ==Testing Time Training==,å®ƒçš„ç¼©å†™æ˜¯ TTTã€‚ Domain Adversarial Trainingæ€éº¼æ‰¾å‡ºè¿™æ ·çš„ä¸€ä¸ª Feature Extractor å‘¢ï¼Ÿé‚£å…¶å®æˆ‘ä»¬å¯ä»¥æŠŠä¸€ä¸ªä¸€èˆ¬çš„ Classifier åˆ†æˆ Feature Extractor è·Ÿ Label Predictor ã€‚ Domain Adaptation çš„ä¸€ç§æ–¹æ³• ==Domain Adversarial Training== è®­ç»ƒ Feature Extractorï¼šè®© Source Domain çš„å›¾ç‰‡å¾—åˆ°çš„ Featureï¼Œè·Ÿ Target Domain çš„åˆ†ä¸å‡ºå·®å¼‚ã€‚ è®­ç»ƒ Domain Classifierï¼šäºŒå…ƒåˆ†ç±»å™¨ï¼ŒåŒºåˆ†è¿™ä¸ª feature æ˜¯æ¥è‡ªæ–¼ Source Domain,è¿˜æ˜¯æ¥è‡ªæ–¼ Target Domainã€‚ Domain Adversarial Training å¾ˆåƒæ˜¯ GANã€‚å¯ä»¥æŠŠ Feature Extractor æƒ³æˆæ˜¯ Generatorï¼ŒæŠŠ Domain Classifier æƒ³æˆæ˜¯ Discriminatorã€‚ Generator å¥½åƒä¼˜åŠ¿å¤ªå¤§äº†ï¼Œå®ƒåªè¦éƒ½è¾“å‡º 0 ä¸å°±æ— æ³•åŒºåˆ†äº†å—ï¼Ÿä¸è¡Œï¼Œéƒ½è¾“å‡º 0 è™½ç„¶ Domain Classifier æ— æ³•åŒºåˆ†ï¼Œä½† Label Predictor ä¹Ÿæ— æ³•åŒºåˆ†ï¼ æ¥ä¸‹æ¥è€ƒè™‘å‚æ•°ä¼˜åŒ–ã€‚Label Predictor è¦åšçš„äº‹æƒ…å°±æ˜¯è®©è¿™ä¸ª Source Domain çš„ Image åˆ†ç±»è¶Šæ­£ç¡®è¶Šå¥½ï¼Œå³æœ€å°åŒ– Lossï¼ˆäº¤å‰ç†µï¼Œåˆ†ç±»é—®é¢˜æœ‰äº¤å‰ç†µï¼‰ã€‚Domain Classifier è¦åšçš„äº‹æƒ…å°±æ˜¯è®© Domain çš„åˆ†ç±»è¶Šæ­£ç¡®è¶Šå¥½ï¼Œä¹Ÿæ˜¯æœ€å°åŒ–äº¤å‰ç†µã€‚ Feature Extractor è¦åšçš„äº‹æƒ…æ˜¯ï¼Œå®ƒåˆè¦ä¿è¯èƒ½è®© Label Predictor æœ‰ä¸ªå¥½ç»“æœï¼Œåˆè¦éª—è¿‡ Domain Classifierï¼Œæ•…æŠŠ loss è®¾ä¸º $L-L_d$ã€‚ Limitationåˆšæ‰è¿™æ•´å¥—æƒ³æ³•æœ‰ä¸€ä¸ªå°å°çš„é—®é¢˜ ç›´è§‰ä¸Šè®²å³è¾¹æ›´å¥½ï¼Œæ‰€ä»¥æˆ‘ä»¬æ˜¯ä¸æ˜¯åº”è¯¥è¦è®©å³è¾¹çš„çŠ¶å†µå‘ç”Ÿå‘¢ï¼Ÿæ€ä¹ˆåšå‘¢ï¼Ÿä¹Ÿè®¸ä¸€ä¸ªå¯èƒ½çš„æƒ³æ³•ï¼šæˆ‘ä»¬æ—¢ç„¶çŸ¥é“åˆ†ç•Œç‚¹åœ¨å“ªè£¡ï¼Œé‚£æˆ‘ä»¬åº”è¯¥è¦è®©è¿™äº›æ–¹å½¢è¿œç¦»è¿™ä¸€ä¸ªåˆ†ç•Œç‚¹ã€‚ Considering Decision Boundaryä»€éº¼å«åšç¦» Boundary è¶Šè¿œè¶Šå¥½å‘¢ï¼Ÿå¦‚æœä»Šå¤©è¾“å‡ºçš„ç»“æœéå¸¸åœ°é›†ä¸­ï¼Œå³ Entropy å°ï¼Œå«åšç¦» Boundary è¿œã€‚åä¹‹åˆ™è¿‘ã€‚ åˆ°ç›®å‰ç‚ºæ­¢éƒ½å‡è®¾è¯´ï¼ŒSource Domain è·Ÿ Target Domainï¼Œå®ƒçš„ç±»åˆ«éƒ½è¦æ˜¯ä¸€æ¨¡ä¸€æ ·ã€‚ä½†æ˜¯çœŸçš„ä¸€å®šä¼šè¿™æ ·å—ï¼Ÿ å®çº¿çš„åœˆåœˆä»£è¡¨ï¼ŒSource Domain è£¡é¢æœ‰çš„ä¸œè¥¿ï¼Œè¿™ä¸ªè™šå®çº¿çš„åœˆåœˆä»£è¡¨ Target Domain è£¡é¢æœ‰çš„ä¸œè¥¿ã€‚æ‰€ä»¥åœ¨è¿™ä¸ªå‰æä¹‹ä¸‹ï¼Œä½ è¯´ä½ è¦è®© Source Domain çš„ Data è·Ÿ Target Domain çš„ Dataï¼Œå®ƒä»¬çš„ Feature å®Œå…¨ Match åœ¨ä¸€èµ·ï¼Œé‚£æ„å‘³è‘—è¯´ï¼Œä½ ç¡¬æ˜¯è¦è®©è€è™å»å˜å¾—è·Ÿç‹—åƒï¼Œåˆ°æ—¶å€™ä½ å°±åˆ†ä¸å‡ºè€è™è¿™ä¸ªç±»åˆ«äº†ã€‚ Domain Generalizationä½†å…¶å®è¿˜æœ‰ä¸€ä¸ªæ›´ä¸¥å³»çš„çŠ¶å†µï¼Œå¦‚æœæˆ‘ä»¬å¯¹ Target Domain ä¸€æ— æ‰€çŸ¥çš„è¯æ€éº¼åŠå‘¢ï¼Ÿè¿™ç§æƒ…å†µé€šå¸¸å°±å« ==Domain Generalization==ã€‚ æˆ‘ä»¬æœŸå¾…æœºå™¨åœ¨ Testing çš„æ—¶å€™ï¼Œä¸ç®¡æ¥ä»€éº¼æ ·çš„ Domainï¼Œå®ƒéƒ½å¯ä»¥å¤„ç†ã€‚ Domain Generalization åˆåˆ†æˆä¸¤ç§çŠ¶å†µï¼šå…¶ä¸€ï¼Œè®­ç»ƒèµ„æ–™æœ¬æ¥å°±åŒ…å«äº†å„å¼å„æ ·ä¸åŒçš„ Domain çš„æ•°æ®ï¼›å…¶äºŒï¼Œè®­ç»ƒèµ„æ–™åªæœ‰ä¸€ä¸ª Domainï¼Œåš Data Augmentationã€‚","link":"/2022/07/06/machine-learning/2022-07-06-review-domain-adaptation/"},{"title":"[rv] reinforcement learning","text":"Reinforcement Learning P1 ï¼šBasicsSupervised Learningâ†’RLSupervised Learningï¼šç»™å®š label Self Supervised Learningï¼šè‡ªåŠ¨ç”Ÿæˆ label Unsupervised Learning(Auto-encoder)ï¼šæ²¡ç”¨åˆ°äººç±»çš„ labelï¼Œä½†äº‹å®ä¸Šä»ç„¶è¿˜æœ‰ label åªä¸è¿‡ä¸éœ€è¦ç”¨äººåŠ›ç”Ÿæˆ RLï¼šæœºå™¨å½“æˆ‘ä»¬ç»™å®ƒä¸€ä¸ªè¾“å…¥çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸çŸ¥é“æœ€ä½³çš„è¾“å‡ºï¼ˆlabelï¼‰åº”è¯¥æ˜¯ä»€ä¹ˆã€‚å¦‚ä¸‹æ£‹ã€‚ Outline Machine Learning â‰ˆ Looking for a Functionæœºå™¨å­¦ä¹ å°±æ˜¯æ‰¾ä¸€ä¸ª Functionï¼ŒReinforcement Learning ä¹Ÿæ˜¯ï¼Œè¿™ä¸ª Function å³ Actor æœ¬èº«ï¼Œè¦åšçš„å°±æ˜¯æœ€å¤§åŒ– reward ä¹‹æ€»å’Œã€‚ ä¾‹ï¼šAtari Space Invadorã€‚Actorï¼šæ“ä½œå¯¹è±¡ã€‚ç¯å¢ƒï¼šæ¸¸æˆåœºæ™¯ã€‚Observationï¼šæ¸¸æˆç”»é¢ã€‚ ä¾‹ï¼šå›´æ£‹ã€‚ç¨€ç– Rewardï¼Œåªæœ‰æ¸¸æˆç»“æŸï¼ˆè¾“ã€èµ¢ï¼‰æ‰èƒ½å¤Ÿæ‹¿åˆ° Rewardã€‚ Machine Learning is so simple â€¦â€¦Machine Learning ä¸‰ä¸ªæ­¥éª¤ï¼š å®šä¹‰å«å¾…æ±‚æœªçŸ¥æ•°çš„ Function å®šä¹‰ Loss Function Optimizationï¼Œminimize loss è€Œ RL å…¶å®ä¹Ÿæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ä¸‰ä¸ªæ­¥éª¤ Step 1: Function with UnknownFunction (in RL) = Actor, RL ä¸­çš„ Actor å³ç¥ç»ç½‘ç»œï¼Œé€šç§° Policy çš„ Networkã€‚ ç¥ç»ç½‘ç»œè¾“å…¥ï¼šthe observation of machine represented as a vector or a matrixã€‚ ç¥ç»ç½‘ç»œè¾“å‡ºï¼šeach action corresponds to a neuron in output layerã€‚ ä¸ºä»€ä¹ˆè¾“å‡ºç»“æœæ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Ÿå¼•å…¥éšæœºæ€§ã€‚ Step 2: Define â€œLossâ€ä»æ¸¸æˆå¼€å§‹åˆ°ç»“æŸçš„è¿™æ•´ä¸ªè¿‡ç¨‹è¢«ç§°ä¹‹ä¸ºä¸€ä¸ª ==Episode==, å°†æ•´ä¸ªæ¸¸æˆçš„è¿‡ç¨‹ä¸­ Actor æ¡å–éå¸¸å¤šçš„è¡Œä¸ºå¾—åˆ°çš„ Reward é€šé€šé›†åˆèµ·æ¥ä¾¿æ˜¯ ==Total Reward (Return)==ã€‚$R = \\sum^{T}_{t=1}r_t$ ã€‚ Return æ˜¯æœ€å¤§åŒ–çš„å¯¹è±¡ï¼Œæˆ‘ä»¬è¦æœ€å°åŒ– lossï¼Œå¯ä»¥å®šä¹‰ loss = -Rã€‚ Step 3: Optimizationå°†æ•´ä¸ªæ¸¸æˆçš„è¿‡ç¨‹ä¸­ s è·Ÿ a æ‰€å½¢æˆçš„è¿™ä¸ª Sequence å«åš Trajectoryã€‚ç¬¦å·è¡¨ç¤ºä¸º $\\tau = {s_1, a_1,s_2,a_2,â€¦}$ã€‚ é€šå¸¸è¯´ï¼ŒReward Function åœ¨å®šä¹‰çš„æ—¶å€™å’Œ Action ä¸ Observation éƒ½æœ‰å…³è”ã€‚å³ $r_i$ å’Œ $s_i$ å’Œ $a_i$ æœ‰å…³ç³»ã€‚ä¼˜åŒ– Return å°±è¡Œã€‚ ä½†æ˜¯ RL å›°éš¾ä¹‹å¤„åœ¨äºå®ƒä¸æ˜¯ä¸€ä¸ªä¸€èˆ¬çš„ Optimization çš„é—®é¢˜ã€‚ ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼ŒActor çš„è¾“å‡ºæ˜¯æœ‰éšæœºæ€§çš„ã€‚ Network è£¡é¢çš„æŸä¸€ä¸ª Layer æ¯æ¬¡äº§ç”Ÿå‡ºæ¥ç»“æœæ˜¯ä¸ä¸€æ ·çš„ã€‚ç¬¬äºŒï¼ŒEnvironment åªæ˜¯ä¸€ä¸ªé»‘ç›’ï¼Œä¸”åŒ…å«éšæœºæ€§ã€‚ ä¸ GAN çš„å¯¹æ¯”ã€‚ ç›¸åŒï¼šGAN ä¸­ è°ƒæ•´ Generator çš„å‚æ•°è®© Discriminator çš„è¾“å‡ºè¶Šå¤§è¶Šå¥½ã€‚RL ä¸­è°ƒæ•´ ACtor çš„å‚æ•°è®© Environment çš„ Reward è¶Šå¤§è¶Šå¥½ã€‚ ä¸åŒï¼šDiscriminator æ˜¯ Networkï¼Œä½† Environment åªæ˜¯ä¸ªé»‘ç›’ã€‚ä¸èƒ½ç”¨ GD è°ƒæ•´ Environmentã€‚ Policy GradientHow to control your actor å¯ä»¥æŠŠå®ƒæƒ³æˆä¸€ä¸ªåˆ†ç±»çš„é—®é¢˜ã€‚å³ s æ˜¯ Actor çš„è¾“å…¥, $\\hat{a}$(Ground Truth) å°±æ˜¯ Labelã€‚ è®¡ç®— Actor çš„è¾“å‡ºè·Ÿ Ground Truth ä¹‹é—´çš„ Cross-entropyï¼Œé‚£æ¥ä¸‹æ¥å°±å¯ä»¥å®šä¹‰ä¸€ä¸ª Lossã€‚æç¤ºï¼šæ ¹æ®äº¤å‰ç†µçš„å®šä¹‰ï¼Œé¢„æµ‹åˆ†å¸ƒå’ŒçœŸå®åˆ†å¸ƒæœ‰ç›¸åŒçš„åˆ†å¸ƒæ—¶äº¤å‰ç†µæœ€å°ã€‚Loss è¶Šå°ï¼Œå°±ç­‰ä»·äºé¢„æµ‹å€¼è¶Šæ¥è¿‘çœŸå®å€¼ã€‚ æ¨¡å‹è®­ç»ƒ ç”¨æ•°å€¼ A è¡¨ç¤ºä»£æ›¿ +1/-1ï¼Œå°±å¯ä»¥å®ç°è¡¨ç¤ºåŠ¨ä½œçš„å¥½åç¨‹åº¦ã€‚Loss æ”¹å†™ä¸ºï¼š$$L=\\sum A_ne_n$$ Value FunctionVersion 0ç”¨éšæœºçš„ Actor å»è·Ÿç¯å¢ƒåšäº’åŠ¨æ”¶é›†è®­ç»ƒèµ„æ–™è·å¾— ${s_i, a_i}$ã€‚å†æ ¹æ®æƒ…å†µå¥½åä¸ºä¹‹èµ‹äºˆ $r_i$ã€‚ æœ€ç®€å•çš„ä½†ä¸æ­£ç¡®çš„ç‰ˆæœ¬ã€‚çŸ­è§†è¿‘åˆ©ã€‚äº‹å®ä¸Šï¼Œæ¯ä¸€ä¸ªè¡Œä¸ºéƒ½ä¼šå½±å“åˆ°æ¥ä¸‹æ¥å‘ç”Ÿçš„äº‹æƒ…ã€‚ä¾‹ï¼šSpace Invador ä¸­ï¼Œç”±äºåªæœ‰å¼€ç«æ‰èƒ½å¾—åˆ°æ­£ Rewardï¼Œæ•…ä»–ä¼šä¸€ç›´å¼€ç«ã€‚ Reward Delayï¼šç‰ºç‰²çŸ­æœŸçš„åˆ©ç›Š,ä»¥æ¢å–æ›´é•¿ç¨‹çš„ç›®æ ‡ã€‚ Version 1==Cumulated Reward==ï¼šæŠŠå½“ä¸‹ä¸æœªæ¥æ‰€æœ‰çš„ Reward åŠ èµ·æ¥è¯„ä¼°ä¸€ä¸ª Action çš„å¥½åã€‚$$G_t = \\sum^{N}_{n=t} r_n$$ç”¨ $G_i$ è¡¨ç¤ºæ¯ä¸ª ${s_i, a_i}$ å¯¹åº”çš„ rewardã€‚ é—®é¢˜åœ¨äºï¼šæœªæ¥å‘ç”Ÿçš„å½±å“ä¸­ï¼Œæœ‰äº›å½±å“å¤§æœ‰äº›å½±å“å°ã€‚ Version 2åŠ ä¸Šé€’å‡æƒé‡ $\\gamma$ã€‚æœªæ¥çš„ reward ä¸­ï¼Œç¦»å½“ä¸‹è¿‘çš„è¡¨ç¤ºå½±å“æ›´å¤§ã€‚$$Gâ€™t = \\sum^{N}{n=t} \\gamma^{n-t}r_n$$ Version 3åšæ ‡å‡†åŒ–ï¼Œå› ä¸ºå¥½æˆ–åæ˜¯ç›¸å¯¹çš„ã€‚ ä¸€ä¸ªæœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯ï¼šæŠŠæ‰€æœ‰çš„ Gâ€™ éƒ½å‡æ‰ä¸€ä¸ª bï¼Œå³==Baseline==ã€‚ Policy Gradient å…¶ä¸­ï¼Œ$L = \\sum A_n e_n$ã€‚$A_n$ å°±æ˜¯ Rewardï¼Œ$e_n$ å°±æ˜¯äº¤å‰ç†µã€‚ ä¸€èˆ¬çš„ Trainingï¼ŒData Collection éƒ½æ˜¯åœ¨ For å¾ªç¯ä¹‹å¤–ã€‚ä½†åœ¨ RL è£¡é¢æ”¶é›†èµ„æ–™æ˜¯åœ¨ For å¾ªç¯è£¡é¢ã€‚è¿™æ„å‘³ç€æ›´æ–°ä¸€æ¬¡å‚æ•°ä»¥åï¼Œå°±è¦é‡æ–°æ”¶é›†èµ„æ–™ï¼Œå› æ­¤ RL çš„è®­ç»ƒè¿‡ç¨‹éå¸¸èŠ±æ—¶é—´ã€‚ ä¸ºä»€ä¹ˆä¸æŠŠ Data Collection æ”¾åœ¨ For å¾ªç¯ä¹‹å¤–ï¼Ÿå½¼ä¹‹ç ’éœœï¼Œå¾ä¹‹èœœç³–ã€‚å› ä¸ºç”± $Î¸_{i-1}$ æ‰€æ”¶é›†å‡ºæ¥çš„èµ„æ–™ä¸ä¸€å®šé€‚åˆæ‹¿æ¥ Update $Î¸_{i}$ çš„å‚æ•°ã€‚ æ•…åŒä¸€ä¸ª Action åŒä¸€ä¸ªè¡Œä¸ºï¼Œå¯¹äºä¸åŒçš„ Actor è€Œè¨€ï¼Œå®ƒçš„å¥½æ˜¯ä¸ä¸€æ ·çš„ã€‚æ›´æ–°åçš„ Actorï¼Œå¯èƒ½ Trajectory å°±ä¼šè·Ÿä¹‹å‰å‡ºç°åŒºåˆ«ã€‚ On-policy v.s. Off-policyè¢«è®­ç»ƒçš„ Actor ä¸è·Ÿç¯å¢ƒäº’åŠ¨çš„ Actor æ˜¯åŒä¸€ä¸ªå«åš ==On-policy Learning==ã€‚ åä¹‹ï¼Œä¸º ==Off-policy Learning==ã€‚ Off-policy çš„å¥½å¤„ï¼šä¸ç”¨ä¸€ç›´æ”¶é›†èµ„æ–™ã€‚å¯ä»¥æ”¶ä¸€æ¬¡èµ„æ–™ï¼Œå°± Update å‚æ•°å¾ˆå¤šæ¬¡ã€‚ æ˜¾ç„¶ä¸Šæ–‡æ‰€è¿°ä¸º On-policy Learningã€‚ Off-policy â†’ Proximal Policy Optimization(PPO)Off-policy çš„ç»å…¸ç®—æ³•ï¼š Proximal Policy Optimizationã€‚ Off-policy çš„é‡ç‚¹ï¼šåœ¨è®­ç»ƒçš„é‚£ä¸ª Networkï¼Œè¦çŸ¥é“è‡ªå·±è·Ÿåˆ«äººä¹‹é—´çš„å·®è·ï¼Œå®ƒè¦æœ‰æ„è¯†åˆ°å®ƒè·Ÿç¯å¢ƒäº’åŠ¨çš„é‚£ä¸ª Actor æ˜¯ä¸ä¸€æ ·çš„ã€‚ ä¾‹å­ï¼šä¸œæ–½æ•ˆé¢¦ï¼Œåˆ«çæ¨¡ä»¿ã€‚ Collection Training Data: ExplorationExplorationï¼šActor åœ¨æ¡å–è¡Œä¸ºçš„æ—¶å€™æœ‰éšæœºæ€§çš„ã€‚éšæœºæ€§å¤§ä¸€ç‚¹æ„å‘³ç€èƒ½å¤Ÿæ”¶é›†åˆ°æ¯”è¾ƒä¸°å¯Œçš„èµ„æ–™ã€‚å®ç°æ–¹æ³•ï¼šå¢å¤§ Actor çš„ Outputï¼ˆDistributionï¼‰çš„ Entropyï¼›åœ¨ Actor å‚æ•°ä¸ŠåŠ  Noiseã€‚ CriticCritic ç”¨ä»¥è¯„ä¼°ä¸€ä¸ª Actor çš„å¥½åã€‚Given actor ğœƒ, how good it is when observing ğ‘  (and taking action ğ‘)ã€‚ æœ¬è¯¾ç¨‹ä¸­ Critic å«åš ==Value Function==ï¼Œç”¨ $V^Î¸(s)$ æ¥è¡¨ç¤ºã€‚è¾“å‡ºä¸€ä¸ª scalarï¼ˆDiscounted Cumulated Rewardï¼‰ã€‚ æ•… Value Function çš„ä½œç”¨å°±æ˜¯ï¼šå¯¹æŸä¸€ä¸ªå‚æ•°ä¸º $\\theta$ çš„ Actor æ¥è¯´ï¼Œå¦‚æœå®ƒå·²ç»çœ‹åˆ°æŸä¸€ä¸ªæ¸¸æˆç”»é¢ sï¼Œé‚£æ¥ä¸‹æ¥ä¼šå¾—åˆ°çš„ Discounted Cumulated Reward åº”è¯¥æ˜¯å¤šå°‘ã€‚ DCR éœ€è¦æœªæ¥çš„ Reward æ¥è®¡ç®—ã€‚ä½†å½“ä¸‹æ€ä¹ˆçŸ¥é“æœªæ¥çš„ Reward å‘¢ï¼ŸValue Function çš„èƒ½åŠ›å°±æ˜¯è¦æœªåœå…ˆçŸ¥ã€‚ How to estimate $ V^Î¸(s) $Monte-Carlo (MC) based approachMCï¼šæŠŠ Actor æ‹¿å»è·Ÿç¯å¢ƒäº’åŠ¨å¾ˆå¤šè½®ï¼Œå¯ä»¥å¾—åˆ°æ¯è½®çš„ DCRã€‚ é‚£ä¹ˆ Value Function å°±å¾—åˆ°ä¸€ç¬”è®­ç»ƒèµ„æ–™ï¼Œè®­ç»ƒç›®æ ‡æ˜¯ï¼šå¦‚æœçœ‹åˆ° $s_a$ ä½œä¸ºè¾“å…¥ï¼Œé‚£å®ƒçš„è¾“å‡º $ V^Î¸(s_a) $ åº”è¯¥è¦è·Ÿ Gâ€™a è¶Šæ¥è¿‘è¶Šå¥½ã€‚ Temporal-difference (TD) approachä¸€è½®äº’åŠ¨å¯èƒ½æ— æ³•ç»ˆæ­¢æˆ–è€…å¾ˆé•¿ã€‚ TDï¼šä¸ç”¨ç©å®Œæ•´åœºæ¸¸æˆï¼Œæ‰èƒ½å¾—åˆ°è®­ç»ƒ Value çš„èµ„æ–™ã€‚è™½ç„¶æˆ‘ä»¬ä¸çŸ¥é“ï¼Œ$ V^Î¸(s_t)$ å’Œ $ V^Î¸(s_{t+1})$ åº”è¯¥æ˜¯ä»€ä¹ˆï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥è®© $ V^Î¸(s_t)$ ä¸ $ \\gamma V^Î¸(s_{t+1})$ çš„å·®å€¼é€¼è¿‘å·²çŸ¥çš„ $r_t$ã€‚ MC v.s. TD Version 3.5æŠŠ baseline è®¾æˆ $V^Î¸(S)$ã€‚æŠŠ ${s_t,a_t}$ å¯¹åº”çš„ Value å®šä¹‰ä¸ºï¼š$$A_t = Gâ€™_t-V^Î¸(s_t)$$ä¸ºä»€ä¹ˆè¿™æ ·å¯ä»¥ï¼Ÿæˆ‘ä»¬çŸ¥é“ $ V^Î¸(s_t)$æ˜¯çœ‹åˆ°æŸä¸€ä¸ªç”»é¢ $s_t$ ä»¥åï¼Œæ¥ä¸‹æ¥ä¼šå¾—åˆ°çš„ (åŠ æƒ) Rewardã€‚å®ƒå…¶å®æ˜¯ä¸€ä¸ªæœŸæœ›ï¼Œå› ä¸ºæœ‰éšæœºæ€§ï¼Œå³æ¯æ¬¡çš„ $a_t$ å¯èƒ½ä¸åŒï¼Œæ•…æ¯æ¬¡å¯èƒ½ä¼šå¾—åˆ°ä¸ä¸€æ ·çš„ Rewardã€‚ å›¾ä¸­ Gtâ€™ æ˜¯ sample æŸä¸€ä¸ª trajectory çš„ç»“æœï¼Œè€Œ$ V^Î¸(s_t)$ æ˜¯å¾ˆå¤šæ¡è·¯å¾„å¹³å‡ä»¥åçš„ç»“æœã€‚ é—®é¢˜åœ¨äºï¼šæŠŠä¸€ä¸ª sample å»å‡æ‰å¹³å‡ï¼Œè¿™æ ·ä¼šå‡†å—ï¼Ÿä¹Ÿè®¸è¿™ä¸ªsample ç‰¹åˆ«å¥½æˆ–ç‰¹åˆ«åã€‚ä¸ºä»€éº½ä¸æ˜¯æ‹¿å¹³å‡å»å‡æ‰å¹³å‡ï¼Ÿ Version 4æœ€åä¸€ä¸ªç‰ˆæœ¬ï¼šå¹³å‡å»å‡æ‰å¹³å‡ã€‚è¿™å°±æ˜¯ ==Advantage Actor-Critic==ã€‚ æŠŠ ${s_t,a_t}$ å¯¹åº”çš„ Value å®šä¹‰ä¸ºï¼š$$A_t = r_t+V^Î¸(s_{t+1})-V^Î¸(s_t)$$ Tip of Actor-CriticActor å’Œ Critic éƒ½æ˜¯ Networkï¼Œä»–ä»¬çš„è¾“å…¥å¯ä»¥å…¬ç”¨ CNNã€‚ Sparse RewardSparse Rewardï¼š$r_t$ = 0 in most casesã€‚ä¾‹å¦‚æ‹§èºä¸ã€‚ è§£å†³åŠæ³•ï¼šreward shapingã€‚ Imitation LearningActor å¯ä»¥ä¸ç¯å¢ƒäº’åŠ¨ï¼Œä½† reward function ä¸çŸ¥é“æ€ä¹ˆå®šä¹‰ã€‚ è§£å†³åŠæ³•ï¼šæ ¹æ®ä¸“å®¶çš„æ¼”ç¤º ${\\hat{\\tau_1}, \\hat{\\tau_2}, â€¦}$ è¿›è¡Œæ¨¡ä»¿å­¦ä¹ ã€‚ ä¾‹å­ï¼šè‡ªåŠ¨é©¾é©¶ï¼Œæœºæ¢°è‡‚æŠ“ä¸¾ã€‚ é—®é¢˜ï¼šä¸“å®¶ä»¬åªå¯¹æœ‰é™çš„è§‚å¯Ÿè¿›è¡ŒæŠ½æ ·ã€‚ Inverse Reinforcement Learningä½¿ç”¨ reward function æ‰¾åˆ°æœ€ä½³ actorã€‚ åŸåˆ™ï¼šThe teacher is always the bestã€‚ æ–¹æ³•è®ºï¼š å’Œ GAN çš„ç±»æ¯”ç†è§£ GAN ä¸­ Generator çš„ä¼˜åŒ–ç›®æ ‡æ˜¯äº§ç”Ÿè·Ÿ Ground Truth çš„å¾ˆåƒçš„ç»“æœï¼ŒIRL ä¸­ Actor çš„ä¼˜åŒ–ç›®æ ‡æ˜¯äº§ç”Ÿè·Ÿ Expert çš„å¾ˆåƒçš„ç»“æœã€‚ GAN ä¸­ Discriminator çš„ä¼˜åŒ–ç›®æ ‡æ˜¯äº§ç”Ÿåˆ†è¾¨ Ground Truth å’Œ Generator çš„è¾“å‡ºå€¼ï¼Œç»™ Ground Truth æ‰“é«˜åˆ†ï¼ŒIRL ä¸­ Reward åˆ™æ˜¯ç»™ Expert æ‰“é«˜åˆ†ã€‚","link":"/2022/07/06/machine-learning/2022-07-06-review-reinforcement-learning/"},{"title":"[ml][rv] generative adversarial network","text":"GAN_P1GenerationNetwork as Generatorè¾“å…¥ x å’Œä»ä¸€ä¸ªdistribution è£¡é¢ sample å‡ºæ¥çš„ zï¼Œè¾“å‡ºå˜æˆäº†ä¸€ä¸ªå¤æ‚çš„ distributionã€‚è¿™ç§è¾“å‡º distribution çš„ network ç§°ä¹‹ä¸º==generator==ã€‚ Why distributionä¸ºä»€ä¹ˆè¦è¾“å‡ºä¸€ä¸ªåˆ†å¸ƒï¼Ÿæœ‰æ—¶å€™éœ€è¦è¿™æ ·ã€‚ ä¾‹å­ï¼švideo predictionï¼Œå³ç»™æœºå™¨ä¸€æ®µçš„å½±ç‰‡ï¼Œç„¶åå®ƒè¦é¢„æµ‹æ¥ä¸‹æ¥ä¼šå‘ç”Ÿä»€éº¼äº‹æƒ…ã€‚è®­ç»ƒèµ„æ–™è£¡é¢åŒæ ·çš„è¾“å…¥ï¼Œæœ‰æ—¶å€™åŒæ ·çš„è½¬è§’æœ‰ä¸¤ç§å¯èƒ½æ€§ã€‚æ‰€ä»¥ä½ çš„ network å­¦åˆ°çš„å°±æ˜¯ä¸¤é¢è®¨å¥½ã€‚ ä»€éº¼æ—¶å€™æˆ‘ä»¬ä¼šç‰¹åˆ«éœ€è¦è¿™ï¼Ÿæˆ‘ä»¬çš„ä»»åŠ¡éœ€è¦ä¸€ç‚¹åˆ›é€ åŠ›çš„æ—¶å€™ã€‚é€šä¿—è®²ï¼Œä»¬æƒ³è¦æ‰¾ä¸€ä¸ªfunctionï¼Œä½†æ˜¯åŒæ ·çš„è¾“å…¥æœ‰å¤šç§å¯èƒ½çš„è¾“å‡ºï¼Œä»–ä»¬éƒ½æ˜¯å¯¹çš„ã€‚ Generative Adversarial Network (GAN)generative çš„ modelï¼Œå…¶ä¸­ä¸€ä¸ªéå¸¸çŸ¥åçš„å°±æ˜¯==generative adversarial network==ã€‚ Anime Face Generationä¾‹å­ï¼šè®©æœºå™¨ç”ŸæˆåŠ¨ç”»äººç‰©çš„,äºŒæ¬¡å…ƒäººç‰©çš„è„¸ã€‚ Discriminatoråœ¨GANè£¡é¢é™¤äº†==generator==ä»¥å¤–è¿˜æœ‰ä¸€ä¸ª ==discriminator==ã€‚ discriminaton ä¹Ÿæ˜¯ä¸ª networkï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼šæ‹¿ä¸€å¼ å›¾ç‰‡ä½œç‚ºè¾“å…¥ï¼Œå®ƒçš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ•°å€¼ã€‚è¶Šå¤§ä»£è¡¨è¶Šåƒæ˜¯çœŸå®çš„äºŒæ¬¡å…ƒå›¾åƒã€‚ Basic Idea of GANç‰©ç«å¤©æ‹©ã€‚å¯¹åº”åˆ° GANï¼Œæ¯å¶è¶å°±æ˜¯ generatorï¼Œé‚£å®ƒçš„å¤©æ•Œå°±æ˜¯ discriminatorã€‚ generator ç”ŸæˆäºŒæ¬¡å…ƒå›¾åƒã€‚discriminator åˆ†è¾¨äºŒæ¬¡å…ƒå›¾åƒã€‚ AlgorithmStep 0ï¼šåˆå§‹åŒ– generator å’Œ discriminator çš„å‚æ•°ã€‚Step 1: Fix generator G, and update discriminator Dä»è¿™ä¸ª gaussian distribution è£¡é¢å» sample ä¸€å † vectorï¼ŒæŠŠè¿™äº› vector ä¸¢åˆ° generator è£¡é¢ï¼Œå®ƒå°±åå‡ºä¸€äº›å›¾ç‰‡ã€‚ ä½ ä¼šæœ‰ä¸€ä¸ª databaseï¼Œè¿™ä¸ªdatabaseè£¡é¢ï¼Œæœ‰å¾ˆå¤šäºŒæ¬¡å…ƒäººç‰©çš„å¤´åƒã€‚ æ¥ä¸‹æ¥å°±æ‹¿çœŸæ­£çš„äºŒæ¬¡å…ƒäººç‰©å¤´åƒï¼Œè·Ÿ generator ç”¢ç”Ÿå‡ºæ¥çš„ç»“æœï¼Œå»è®­ç»ƒä½ çš„discriminatorã€‚discriminator å®ƒè®­ç»ƒçš„ç›®æ ‡æ˜¯è¦åˆ†è¾¨ï¼ŒçœŸæ­£çš„äºŒæ¬¡å…ƒäººç‰©è·Ÿ generator ç”¢ç”Ÿå‡ºæ¥çš„äºŒæ¬¡å…ƒäººç‰©ã€‚ è¿™å¯¹æ–¼ discriminator æ¥è¯´æ˜¯ä¸€ä¸ªåˆ†ç±»çš„é—®é¢˜ã€‚ä¹Ÿå¯ä»¥è¯´æ˜¯ regression çš„é—®é¢˜ã€‚ Step 2: Fix discriminator D, and update generator Gæˆ‘ä»¬æŠŠ generator ç”Ÿæˆçš„å›¾ç‰‡ä¸¢åˆ° Discriminator è£¡é¢ï¼ŒDiscriminator ä¼šç»™è¿™ä¸ªå›¾ç‰‡ä¸€ä¸ªåˆ†æ•°ï¼Œé‚£ generator æ˜¯è¦ Discriminator çš„è¾“å‡ºå€¼è¶Šå¤§è¶Šå¥½ ä¸¾ä¾‹æ¥è¯´ generator å¦‚æœæ˜¯äº”å±‚çš„ networkï¼ŒDiscriminator å¦‚æœæ˜¯äº”å±‚çš„ networkï¼ŒæŠŠå®ƒä»¬æ¥èµ·æ¥æˆ‘ä»¬å°±æŠŠå®ƒå½“ä½œæ˜¯ä¸€ä¸ªåå±‚çš„ network æ¥çœ‹å¾…ã€‚è¿™ä¸ªåå±‚çš„networkè£¡é¢ï¼Œå…¶ä¸­æŸä¸€éšè—å±‚çš„è¾“å‡ºå°±æ˜¯ä»£è¡¨ä¸€å¼ å›¾ç‰‡ã€‚ æˆ‘ä»¬è¦åšçš„äº‹æƒ…æ˜¯,æ•´ä¸ªå·¨å¤§çš„ network å•Š,å®ƒä¼šåƒä¸€ä¸ªå‘é‡ä½œç‚ºè¾“å…¥ï¼Œç„¶åä»–ä¼šè¾“å‡ºä¸€ä¸ªåˆ†æ•°,é‚£æˆ‘ä»¬å¸Œæœ›è°ƒæ•´è¿™ä¸ª networkï¼Œè®©è¾“å‡ºçš„åˆ†æ•°è¶Šå¤§è¶Šå¥½ã€‚==gradient ascent== æ¥ä¼˜åŒ–ã€‚ GAN_P2_Theory behind GANæ¥ä¸‹æ¥è®¨è®ºç‚ºä»€éº¼è¿™ä¸ª Generator è·Ÿ Discriminator çš„äº’åŠ¨ï¼Œå¯ä»¥è®©æˆ‘ä»¬çš„ Generatorç”¢ç”Ÿåƒæ˜¯çœŸæ­£çš„äººè„¸çš„å›¾ç‰‡ã€‚ é‚£æˆ‘ä»¬å…ˆæ¥å¼„æ¸…æ¥šè®­ç»ƒçš„ç›®æ ‡åˆ°åº•æ˜¯ä»€éº¼ï¼Œæˆ‘ä»¬æƒ³è¦ Minimize çš„æ˜¯è®© Generator äº§ç”Ÿçš„ Distribution å’Œ çœŸæ­£ Data çš„ Distribution è¶Šæ¥è¿‘è¶Šå¥½ã€‚ Div = Divergenceã€‚çº¢è‰²ä¸‹åˆ’çº¿çš„å‡½æ•°ä¹Ÿå°±è¡¨ç¤ºäº†æˆ‘ä»¬çš„ Loss Functionã€‚ å¸¸è§çš„ Divergence è®¡ç®—æ–¹æ³•ï¼š ä½†æ˜¯æˆ‘ä»¬è¿™è¾¹é‡åˆ°ä¸€ä¸ªå›°éš¾çš„é—®é¢˜ï¼Œè¿™ä¸ª Divergence å¾ˆéš¾ç®—çš„ã€‚è€Œ==GAN==æ˜¯ä¸€ä¸ªå¾ˆç¥å¥‡çš„åšæ³•,å®ƒ==å¯ä»¥çªç ´,æˆ‘ä»¬ä¸çŸ¥é“æ€éº¼è®¡ç®— Divergence çš„é™åˆ¶==ã€‚ æˆ‘ä»¬ä¸éœ€è¦çŸ¥é“ PG è·Ÿ Pdata å®ƒä»¬å®é™…ä¸Šçš„ Formulation ï¼ˆå¯¹åº”å…¬å¼çš„ P(x) å’Œ Q(x)ï¼‰é•¿ä»€éº¼æ ·å­ï¼Œåªè¦èƒ½ä» PG å’Œ Pdataè¿™ä¸¤ä¸ª Distributions Sample ä¸œè¥¿å‡ºæ¥ï¼Œå°±æœ‰åŠæ³•ç®— Divergenceã€‚ Discriminatorå¦‚ä½•åœ¨åªæœ‰åš Sample çš„å‰æä¹‹ä¸‹ä¼°æµ‹å‡º Divergenceï¼Ÿé‚£è¿™ä¸ªå°±æ˜¯è¦é  ==Discriminator== çš„åŠ›é‡ã€‚ Discriminator ä¼˜åŒ–çš„è¿‡ç¨‹ï¼Œä½ ä¹Ÿå¯ä»¥æŠŠå®ƒå†™æˆå¼å­ï¼š è¿™ä¸ª Discriminator å¯ä»¥å» MaximizeæŸä¸€ä¸ª Function,æˆ‘ä»¬è¿™è¾¹å«åš ==Objective Function==ï¼ˆæˆ‘ä»¬è¦ Maximize çš„ä¸œè¥¿,æˆ‘ä»¬ä¼šå« Objective Function,å¦‚æœ Minimize æˆ‘ä»¬å°±å«å®ƒ Loss Functionï¼‰ã€‚ $E_{y\\sim P_{data}}[logD(y)]$ æˆ‘ä»¬æœ‰ä¸€å † Y,å®ƒæ˜¯ä» Pdata è£¡é¢ Sample å‡ºæ¥çš„,ä¹Ÿå°±æ˜¯å®ƒä»¬æ˜¯çœŸæ­£çš„ Image,è€Œæˆ‘ä»¬æŠŠè¿™ä¸ªçœŸæ­£çš„ Image ä¸¢åˆ° D è£¡é¢,å¾—åˆ°ä¸€ä¸ªåˆ†æ•°å†å–$logD(y)$ $E_{y\\sim P_G}[log(1-D(y))]$ é‚£å¦å¤–ä¸€æ–¹é¢,æˆ‘ä»¬æœ‰ä¸€å † Y,å®ƒæ˜¯ä» PG ä» Generato r æ‰€ç”¢ç”Ÿå‡ºæ¥çš„,æŠŠè¿™äº›å›¾ç‰‡ä¹Ÿä¸¢åˆ° Discriminator è£¡é¢,å¾—åˆ°ä¸€ä¸ªåˆ†æ•°,å†å– $log(1 - D (y))$ é‚£è¿™è¾¹æœ€ç¥å¥‡çš„åœ°æ–¹æ˜¯è¿™ä¸€ä¸ªå¼å­ï¼Œè¿™ä¸ªçº¢æ¡†æ¡†è£¡é¢çš„æ•°å€¼,å®ƒè·Ÿ JS Divergence æœ‰å…³ã€‚å‡è®¾ PG è·Ÿ Pdata çš„ Divergence å¾ˆå°ï¼Œæ‰€ä»¥è¿™ä¸ª Objective è¿™ä¸ª V çš„ Maximum çš„å€¼å°±æ¯”è¾ƒå°ã€‚æ‰€ä»¥å°çš„ Divergenceï¼Œå¯¹åº”åˆ°å°çš„è¿™ä¸ª Objective Function çš„Maximum çš„å€¼ã€‚ Tips for GANæŠ€å·§ä¹‹ä¸€ï¼š ==WGAN==ã€‚ åœ¨æ­¤ä¹‹å‰å…ˆè®² JS Divergence æœ‰ä»€éº¼æ ·çš„é—®é¢˜ã€‚ JS divergence is not suitablePG è·Ÿ Pdata æœ‰ä¸€ä¸ªéå¸¸å…³é”®çš„ç‰¹æ€§æ˜¯ï¼šå®ƒä»¬é‡å çš„éƒ¨åˆ†å¾€å¾€éå¸¸å°‘ã€‚ åŸå› æœ‰äºŒï¼šå…¶ä¸€ï¼Œé‚£å›¾ç‰‡å…¶å®æ˜¯é«˜ç»´ç©ºé—´è£¡é¢çš„ä¸€ä¸ªä½ç»´çš„ Manifoldï¼ŒäºŒæ¬¡å…ƒäººç‰©çš„å¤´åƒå®ƒçš„åˆ†å¸ƒåœ¨é«˜ç»´çš„ç©ºé—´ä¸­å…¶å®æ˜¯éå¸¸ç‹­çª„çš„ã€‚å…¶äºŒï¼Œæˆ‘ä»¬å¯¹ PG è·Ÿ Pdata,å®ƒçš„åˆ†å¸ƒçš„ç†è§£æ¥è‡ªæ–¼ Sampleï¼Œå¦‚æœé‡‡æ ·ä¸å…¨æœ‰é‡å ä¹Ÿå‘ç°ä¸äº†ã€‚ JS Divergence æœ‰ä¸ªç‰¹æ€§ï¼Œæ˜¯ä¸¤ä¸ªæ²¡æœ‰é‡å çš„åˆ†å¸ƒï¼ŒJS Divergence ç®—å‡ºæ¥,å°±æ°¸è¿œéƒ½æ˜¯ Log2ã€‚å› æ­¤ç”¨ JS Divergence çš„æ—¶å€™ï¼Œä½ å°±å‡è®¾ä½ ä»Šå¤©åœ¨ Train ä¸€ä¸ª Binary çš„ Classifierï¼Œä½ ä¼šå‘ç°å®é™…ä¸Šä½ é€šå¸¸ Train å®Œä»¥åæ­£ç¡®ç‡å‡ ä¹éƒ½æ˜¯ 100%ã€‚ å› ç‚ºä½  Sample çš„å›¾ç‰‡æ ¹æœ¬å°±æ²¡å‡ å¼ ï¼Œå®ƒç›´æ¥ç”¨ç¡¬èƒŒæ¥åˆ†è¾¨ã€‚æ‰€ä»¥è¿™æ—¶å€™ accuracy æ²¡å•¥ç”¨ã€‚ Wasserstein Distanceå‡æƒ³ä½ åœ¨å¼€ä¸€å°æ¨åœŸæœº,é‚£ä½ æŠŠåˆ†å¸ƒ P æƒ³æˆæ˜¯ä¸€å †åœŸï¼ŒæŠŠåˆ†å¸ƒ Q æƒ³æˆæ˜¯ä½ è¦æŠŠåœŸå †æ”¾çš„ç›®çš„åœ°ï¼Œé‚£è¿™ä¸ªæ¨åœŸæœºæŠŠ P è¿™è¾¹çš„åœŸï¼ŒæŒªåˆ° Q æ‰€ç§»åŠ¨çš„å¹³å‡è·ç¦»å°±æ˜¯ Wasserstein Distanceã€‚ ä½†æ˜¯æ¨åœŸçš„åŠæ³•æœ‰å¾ˆå¤šç§ã€‚å› æ­¤å…‰åªæ˜¯è¦è®¡ç®—ä¸€ä¸ª Distanceï¼Œå±…ç„¶è¿˜è¦è§£ä¸€ä¸ª Optimization çš„é—®é¢˜ï¼Œè§£å‡ºè¿™ä¸ª Optimization çš„é—®é¢˜ï¼Œæ‰èƒ½ç®— Wasserstein Distanceã€‚å…ˆè®² Wasserstein Distance èƒ½ç»™æˆ‘ä»¬ä»€ä¹ˆå¥½å¤„ã€‚ ç”±å·¦å‘å³çš„æ—¶å€™ï¼ŒWasserstein Distance æ˜¯è¶Šæ¥è¶Šå°çš„ï¼Œè¡¨æ˜ Generator åœ¨è¿›æ­¥ã€‚JS Divergence å´ä¸å˜ã€‚ WGANç”¨ Wasserstein Distance æ¥å–ä»£ JS Divergence çš„æ—¶å€™ï¼Œè¿™ä¸ª GAN å°±å«åš WGANã€‚ æ¥ä¸‹æ¥ä½ ä¼šé‡åˆ°çš„é—®é¢˜å°±æ˜¯ï¼ŒWasserstein Distance æ˜¯è¦æ€éº¼ç®—ã€‚ è§£ä¸‹é¢è¿™ä¸ª Opimilazion çš„ Problemï¼Œè§£å‡ºæ¥ä»¥åä½ å¾—åˆ°çš„å€¼å°±æ˜¯ Wasserstein Distanceã€‚ å³æˆ‘ä»¬æƒ³è¦ Discriminator å¯¹ Pdata è¾“å‡ºè¶Šå¤§è¶Šå¥½ï¼Œå¯¹ PG çš„ è¾“å‡ºè¶Šå°è¶Šå¥½ã€‚ é™åˆ¶ï¼šD å¿…é¡»è¦æ˜¯ä¸€ä¸ª 1-Lipschitz çš„ Functionã€‚ 1-Lipschitz ä¸çŸ¥é“æ˜¯ä»€éº¼çš„è¯ä¹Ÿæ²¡å…³ä¿‚ã€‚å¯ä»¥æƒ³è±¡æˆ D å¿…é¡»è¦æ˜¯ä¸€ä¸ªè¶³å¤Ÿå¹³æ»‘çš„ Functionã€‚ å¦åˆ™ï¼Œå°±ä¼šå‡ºç°æ— é™å¤§çš„æƒ…å†µã€‚è¿™ä¼šå¯¼è‡´è¦ä¼˜åŒ–çš„ç›®æ ‡è¶Šæ¥è¶Šå¤§ï¼Œè¿™ä¸‹å°±åˆä¸èƒ½æ”¶æ•›åŠ›ï¼ˆæ‚²ã€‚ æ¥ä¸‹æ¥çš„é—®é¢˜å°±æ˜¯æ€éº¼åšåˆ° 1-Lipschitz çš„è¿™ä¸ªé™åˆ¶ã€‚ æƒ³æ³•ä¸€ï¼šåªéœ€ Train Network çš„æ—¶å€™ï¼Œè®© Training çš„é‚£ä¸ªå‚æ•°ï¼Œè¦æ±‚å®ƒæ”¾å¾—åœ¨ C è·Ÿ -C ä¹‹é—´ï¼Œå¦‚æœå‚æ•°æ›´æ–°åè¶…è¿‡å°±è®¾ä¸º C å°±è®¾ä¸º Cï¼Œå°äº -C å°±è®¾ä¸º -Cã€‚ä½†è¿™æ ·å…¶å®æŒºæ‹‰çš„ã€‚ æƒ³æ³•äºŒï¼šGradient Penaltyã€‚ æƒ³æ³•ä¸‰ï¼šSpectral Normalizationã€‚ GAN_P3æœ‰äº† WGAN å¹¶ä¸ä»£è¡¨è¯´ GAN å°±ä¸€å®šç‰¹åˆ«å¥½ Trainã€‚ç‚ºä»€éº¼ GAN å¾ˆéš¾è¢« Train èµ·æ¥ï¼Ÿ äº‹å®ä¸Š Generator è·Ÿ Discriminatorï¼Œå®ƒä»¬æ˜¯äº’ç›¸ç ¥ç ºæ‰èƒ½äº’ç›¸æˆé•¿çš„ï¼Œåªè¦å…¶ä¸­ä¸€è€…å‘ç”Ÿä»€éº¼é—®é¢˜åœæ­¢è®­ç»ƒï¼Œå¦å¤–ä¸€è€…å°±ä¼šè·Ÿè‘—åœä¸‹è®­ç»ƒã€‚ Conditional Generationåˆ°ç›®å‰ç‚ºæ­¢æˆ‘ä»¬è®²çš„ Generatorï¼Œå®ƒè¾“å…¥éƒ½æ˜¯ä¸€ä¸ªéšæœºçš„åˆ†å¸ƒè€Œå·²ï¼Œé‚£è¿™ä¸ªä¸è§å¾—éå¸¸æœ‰ç”¨ã€‚ æˆ‘ä»¬ç°åœ¨æƒ³è¦æ›´è¿›ä¸€æ­¥çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥æ“æ§ Generator çš„è¾“å‡ºï¼Œæˆ‘ä»¬ç»™å®ƒä¸€ä¸ª Condition xï¼Œè®©å®ƒæ ¹æ® x è·Ÿ z æ¥ç”¢ç”Ÿ yï¼Œé‚£è¿™æ ·çš„ Conditional Generationã€‚ æ™®é€šçš„ ==GAN== ä¸ä¹Ÿæ˜¯ä¸€ä¸ªæ ‡é‡ä¸€ä¸ªå‘é‡è¾“å…¥ï¼Ÿ å¦‚æœè¦åšæ–‡å­—å¯¹å›¾ç‰‡çš„ç”Ÿæˆï¼Œå®ƒå…¶å®æ˜¯ä¸€ä¸ª Supervised Learning çš„é—®é¢˜ã€‚ä½ éœ€è¦ä¸€äº› Label çš„ Dataï¼Œæ¯”å¦‚è¯´çº¢çœ¼ç›çš„äººå¤´åƒï¼Œæ‰èƒ½å¤Ÿè®­ç»ƒè¿™ç§ Conditional çš„ Generationã€‚ æ‰€ä»¥åœ¨è¿™æ ·çš„ä»»åŠ¡è£¡é¢ï¼Œæˆ‘ä»¬çš„ x å°±æ˜¯ä¸€æ®µæ–‡å­—ã€‚æ¯”å¦‚è¯´è¾“å…¥ Red Eyesï¼Œç„¶åæœºå™¨å°±å¯ä»¥ç”»ä¸€ä¸ªçº¢çœ¼ç›çš„è§’è‰²ï¼Œä½†æ¯æ¬¡ç”»å‡ºæ¥çš„è§’è‰²éƒ½ä¸ä¸€æ ·ã€‚ ä¹Ÿè®¸ä½ å°±å¯ä»¥å»æŠŠ Generator è®­ç»ƒå‡ºæ¥ï¼Œä½†è¿™æ ·çš„æ–¹æ³•æ˜¯é”™è¯¯çš„ã€‚å› ä¸ºè¿™æ ·çš„ Generator å®ƒåªè¦ç”¢ç”Ÿæ¸…æ™°çš„å›¾ç‰‡ï¼Œå°±å¯ä»¥éª—è¿‡ Discriminator äº†ï¼Œå®ƒä½•å¿…è¦å»ç®¡ Input æ–‡å­—å™è¿°æ˜¯ä»€éº¼ã€‚ æ‰€ä»¥åœ¨ Conditional GAN è£¡é¢ï¼Œ Discriminator ä¸æ˜¯åªåƒå›¾ç‰‡ yï¼Œå®ƒè¿˜è¦åƒ Condition xã€‚ é‚£æ€éº¼æ ·è®­ç»ƒè¿™æ ·çš„ Discriminator ï¼Ÿé‚£ä½ éœ€è¦æ–‡å­—è·Ÿå½±åƒæˆå¯¹çš„èµ„æ–™ï¼Œæ‰€ä»¥ Conditional GAN ä¸€èˆ¬çš„è®­ç»ƒéœ€è¦çš„ Data çš„ï¼Œæ˜¯éœ€è¦æœ‰æ ‡è¨»çš„èµ„æ–™çš„ã€‚ å…‰æ˜¯è¿™æ ·å­çš„ Positive Sample è¿˜ä¸å¤Ÿï¼Œè¿˜æœ‰ Negative Sampleï¼Œå³ç”¢ç”Ÿå¥½çš„å›¾ç‰‡æ–‡å­—å™è¿°é…ä¸ä¸Šçš„çŠ¶å†µã€‚ å†è€ƒè™‘ Image To Image çš„æƒ…å½¢ï¼Œåªæ˜¯ä»å½±åƒç”¢ç”Ÿå½±åƒ,æŠŠæ–‡å­—çš„éƒ¨åˆ†ç”¨å½±åƒå–ä»£æ‰è€Œå·²ã€‚æ–‡çŒ®ä¸Šå¦‚æœä½ è¦åšåˆ°æœ€å¥½ï¼Œå¾€å¾€å°±æ˜¯ GAN è·Ÿ Supervised Learningï¼ŒåŒæ—¶ä½¿ç”¨ã€‚ æ­¤å¤–ï¼Œè¾“å…¥çš„ label ä¹Ÿå¯ä»¥æ˜¯ multi-label çš„ã€‚ GAN_P4 Learning from Unpaired Dataæœ€åè®²ä¸€ä¸ªGANçš„ç¥å¥‡åº”ç”¨ï¼Œå®ƒæŠŠGANç”¨åœ¨==unsupervised Learning==ã€‚ æˆ‘ä»¬å¯èƒ½ä¼šé‡åˆ°ä¸€ä¸ªçŠ¶å†µï¼šæˆ‘ä»¬æœ‰ä¸€å † X æˆ‘ä»¬æœ‰ä¸€å † Yï¼Œä½† X è·Ÿ Y æ˜¯ä¸æˆå¯¹çš„ã€‚è¿™å«åš==unlabeled==çš„èµ„æ–™ã€‚ æˆ‘ä»¬è¿™è¾¹ä¸¾ä¸€ä¸ªä¾‹å­ï¼šå½±åƒé£æ ¼è½¬æ¢ã€‚X domain æ˜¯çœŸäººçš„ç…§ç‰‡ï¼ŒY domainçš„å›¾æ˜¯äºŒæ¬¡å…ƒäººç‰©çš„å¤´åƒã€‚è¿™ä¸ªä¾‹å­æ²¡æœ‰ä»»ä½•çš„æˆå¯¹çš„èµ„æ–™ã€‚ è§£å†³åŠæ³•ï¼šUnsupervised Conditional Generationã€‚ è¾“å…¥æ˜¯ä¸€ä¸ª Gaussian çš„åˆ†ä½ˆï¼Œè¾“å‡ºå¯èƒ½æ˜¯ä¸€ä¸ªå¤æ‚çš„åˆ†ä½ˆã€‚ç°åœ¨æˆ‘ä»¬åœ¨ç¨å¾®è½¬æ¢ä¸€ä¸‹æˆ‘ä»¬çš„æƒ³æ³•ï¼Œè¾“å…¥è¯´æ˜¯ X domain çš„å›¾ç‰‡çš„åˆ†ä½ˆï¼Œè¾“å‡ºè¯´æ˜¯ Y domain çš„å›¾ç‰‡çš„åˆ†ä½ˆã€‚ æŠŠè¾“å…¥æ”¹æˆ X domain å¾ˆç®€å•ï¼Œä¸ä»é«˜æ–¯åˆ†å¸ƒé‡Œé‡‡æ ·å°±è¡Œã€‚é‚£æ€éº¼è®©è¾“å‡ºå˜æˆæ˜¯Y domain çš„ distribution å‘¢ï¼Ÿ é‚£å°±è¦ä¸¤ä¸‰ä¸ª discriminatorï¼Œé‚£è¿™ä¸ª discriminator ç»™å®ƒçœ‹è¿‡å¾ˆå¤š Y domain çš„å›¾ï¼Œæ‰€ä»¥å®ƒèƒ½å¤Ÿåˆ†è¾¨ Y domain çš„å›¾è·Ÿä¸æ˜¯ Y domain çš„å›¾ã€‚ ä½†è¿™æ ·ä¸å¤Ÿï¼Œè¿˜å¾—ä¿è¯ç”Ÿæˆçš„äºŒæ¬¡å…ƒå¤´åƒè·Ÿè¾“å…¥çš„çœŸå®çš„ç…§ç‰‡æœ‰å…³è”ã€‚ ç”±äºæ²¡æœ‰æˆå¯¹æ•°æ®ï¼Œå› æ­¤æ— æ³•ç›´æ¥å¥—ç”¨ conditional GAN çš„æƒ³æ³•ã€‚å› ç‚ºåœ¨ conditional GAN è£¡é¢ï¼Œæˆ‘ä»¬æ˜¯æœ‰æˆå¯¹çš„èµ„æ–™æ¥è®­ç»ƒ discriminator çš„ã€‚ Cycle GANè¿™è¾¹è¿™ä¸ªæƒ³æ³•å«åš==Cycle GAN==ã€‚åœ¨Cycle GANè£¡é¢ä¼š train ä¸¤ä¸ª generatorã€‚ åœ¨è®­ç»ƒçš„æ—¶å€™å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„ç›®æ ‡ï¼šå¸Œæœ›è¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œä» X domain è½¬æˆ Y domain ä»¥åï¼Œè¦ä»Y domainè½¬å›åŸæ¥çš„ã€‚æˆ‘ä»¬è¦è®©åŸå›¾å’Œè¿˜åŸçš„å›¾è¶Šç›¸è¿‘è¶Šå¥½ã€‚è¿™å«åš ==Cycleçš„consistency==ã€‚ ä¸¤å¼ å›¾ç‰‡æœ¬è´¨ä¸Šå°±æ˜¯ä¸¤ä¸ªå‘é‡ï¼Œå®ƒä»¬ä¹‹é—´çš„è·ç¦»è¶Šæ¥è¿‘è¶Šå¥½ï¼Œå°±æ˜¯è¦ä¸¤å¼ å›¾ç‰‡è¶Šåƒè¶Šå¥½ã€‚ æ‰€ä»¥ç°åœ¨è¿™è¾¹æˆ‘ä»¬æœ‰ä¸‰ä¸ªNetworkï¼š ç¬¬ä¸€ä¸ªgenerator,å®ƒçš„å·¥ä½œæ˜¯æŠŠXè½¬æˆY ç¬¬äºŒä¸ªgenerator,å®ƒçš„å·¥ä½œæ˜¯è¦æŠŠYè¿˜åŸå›åŸæ¥çš„X é‚£è¿™ä¸ªdiscriminator,å®ƒçš„å·¥ä½œä»ç„¶æ˜¯è¦çœ‹,è“è‰²çš„è¿™ä¸ªgeneratorå®ƒçš„è¾“å‡º,åƒä¸åƒæ˜¯Y domainçš„å›¾ è¿™æ—¶ä½ å¯èƒ½ä¼šæœ‰çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼šä½ åªèƒ½ä¿è¯ä¸¤ä¸ª domain çš„å›¾æœ‰å…³ç³»ï¼Œä½†è¿™ç§å…³ç³»çœŸçš„æœ‰æ„ä¹‰ï¼Ÿæ¯”å¦‚ä¸¤ä¸ª generator å­¦åˆ°çš„éƒ½æ˜¯å›¾ç‰‡åè½¬ï¼ŒåŒæ ·ä¹Ÿèƒ½ä¿è¯ cycle consistencyã€‚è¿™ä¸ªé—®é¢˜å®é™…ä¸Šä¸€èˆ¬ä¸å‡ºç°ã€‚ Cycle GAN å¯ä»¥æ˜¯åŒå‘çš„ã€‚ ä¸€äº›å…¶ä»–çš„ GANã€‚Disco GANã€Dual GAN è·Ÿ Cycle GAN æ²¡ä»€ä¹ˆä¸åŒã€‚ ç›¸æ¯”åªèƒ½åœ¨ä¸¤ç§é£æ ¼é—´è½¬æ¢çš„ Cycle GANï¼ŒStarGAN å¯ä»¥åšå¤šé£æ ¼å½±åƒé£æ ¼è½¬æ¢ã€‚ ä¸€äº›å…¶ä»–åº”ç”¨ï¼šæŠŠé•¿çš„æ–‡ç« å˜æˆç®€çŸ­çš„æ‘˜è¦ï¼›ç¿»è¯‘ï¼›éç£å¯¼å¼çš„è¯­éŸ³è¾¨è¯†ã€‚ Evaluation of Generationè¦è¯„ä¼° Generator çš„å¥½åå®Œå…¨ç”¨äººæ¥çœ‹æ˜¾ç„¶æœ‰å¾ˆå¤šçš„é—®é¢˜ã€‚åº”è¯¥æ¥ç‚¹å®¢è§‚çš„æ–¹æ³•ã€‚ æ¯”å¦‚è·‘ä¸€ä¸ªå½±åƒçš„åˆ†ç±»ç³»ç»Ÿï¼šæŠŠä½ çš„ GAN ç”¢ç”Ÿå‡ºæ¥çš„å›¾ç‰‡ï¼Œä¸¢åˆ°ä¸€ä¸ªçš„å½±åƒçš„åˆ†ç±»ç³»ç»Ÿè£¡é¢ï¼Œçœ‹å®ƒç”¢ç”Ÿä»€éº¼æ ·çš„ç»“æœã€‚ å¦‚æœå››ä¸åƒï¼Œé‚£å°±æ˜¯å‡åŒ€åˆ†å¸ƒåŠ›ã€‚ Diversity - Mode Collapseä½†æ˜¯å…‰ç”¨è¿™ä¸ªè¯„ä¼°çš„æ–¹æ³•ä¼šè¢«ä¸€ä¸ªå«åš ==Mode Collapse== çš„é—®é¢˜éª—è¿‡å»ã€‚ è¿™ä¼šå¯¼è‡´ Generative Model è¾“å‡ºæ¥çš„å›¾ç‰‡æ¥æ¥å»å»å°±æ˜¯é‚£å‡ å¼ å¯èƒ½å•ä¸€çš„å›¾ç‰‡ã€‚ é‚£ç‚ºä»€éº¼ä¼šæœ‰ Mode Collapse è¿™ç§ç°è±¡å‘ç”Ÿï¼Ÿç›´è§‰ä¸Šç†è§£ï¼Œè¿™ä¸ªåœ°æ–¹å°±æ˜¯ Discriminator çš„ä¸€ä¸ªç›²ç‚¹ï¼Œå‘ç°è¿™ä¸ªç›²ç‚¹åæ¯æ¬¡éƒ½æ•´è¿™ä¸€å‡ºã€‚ Diversity - Mode Droppingä½†æ˜¯æœ‰å¦å¤–ä¸€ç§æ›´éš¾è¢«ä¾¦æµ‹åˆ°çš„é—®é¢˜å«åš ==Mode Dropping==ã€‚ Mode Dropping çš„æ„æ€æ˜¯è¯´ï¼Œä½ çš„ç”¢ç”Ÿå‡ºæ¥çš„èµ„æ–™ï¼Œä½†çœ‹èµ·æ¥å¤šæ ·æ€§å¥½åƒä¹Ÿå¤Ÿã€‚ è¿™ç§é—®é¢˜éš¾ä»¥ä¾¦æµ‹ã€‚ä¸€ç§å¯èƒ½çš„æ–¹æ³•ï¼š å€ŸåŠ©æˆ‘ä»¬çš„ Image Classifierã€‚æ¯”å¦‚æŠŠ Generator ç”¢ç”Ÿ 1000 å¼ å›¾ç‰‡ï¼ŒæŠŠè¿™ 1000 å¼ å›¾ç‰‡è£¡,éƒ½ä¸¢åˆ° Image Classify è£¡é¢ï¼Œçœ‹è¾“å‡ºæ˜¯å“ªä¸ª classã€‚ æ¯å¼ å›¾ç‰‡ï¼Œéƒ½ä¼šç»™æˆ‘ä»¬ä¸€ä¸ª Distributionã€‚æŠŠæ‰€æœ‰å›¾ç‰‡çš„ Distribution åŠ èµ·æ¥å¹³å‡ï¼Œå¦‚æœå¾ˆé›†ä¸­è¯´æ˜å¤šæ ·æ€§ä¸è¡Œã€‚ Diversity è·Ÿ Quality å¥½åƒæ˜¯æœ‰ç‚¹äº’æ–¥ï¼Ÿå®åˆ™ä¸ç„¶ã€‚äºŒè€…è¯„ä¼°èŒƒå›´ä¸åŒã€‚Quality æ˜¯åªçœ‹ä¸€å¼ å›¾ç‰‡çš„åˆ†å¸ƒï¼Œè€Œ Diversity çœ‹çš„æ˜¯ä¸€å †å›¾ç‰‡å®ƒåˆ†å¸ƒçš„å¹³å‡ã€‚ è¿‡å»æœ‰ä¸€ä¸ªéå¸¸å¸¸è¢«ä½¿ç”¨çš„åˆ†æ•°,å«åš ==Inception Score==ã€‚å¦‚æœ Quality é«˜ï¼Œé‚£ä¸ª Diversity åˆå¤§ï¼Œé‚£ Inception Score å°±ä¼šæ¯”è¾ƒå¤§ã€‚ FrÃ©chet Inception Distance (FID)è¿˜æœ‰ä¸€ä¸ª Evaluation çš„ Measure,å« ==FrÃ©chet Inception Distance==ã€‚ ä½ å…ˆæŠŠä½ ç”¢ç”Ÿå‡ºæ¥çš„äºŒæ¬¡å…ƒçš„äººç‰©ï¼Œä¸¢åˆ° Inception Net è£¡é¢ï¼Œé‚£ä¸ª Inception Network è¾“å‡ºå®ƒçš„ç±»åˆ«ï¼Œé‚£ä½ å¾—åˆ°çš„å¯èƒ½å°±æ˜¯äººè„¸ï¼Œé‚£æ¯ä¸€å¼ äºŒæ¬¡å…ƒçš„äººç‰©çœ‹èµ·æ¥éƒ½æ˜¯äººè„¸ï¼Œé‚£æˆ‘ä»¬ä¸è¦æ‹¿é‚£ä¸ªç±»åˆ«ã€‚ æˆ‘ä»¬æ‹¿è¿›å…¥ Softmax ä¹‹å‰çš„ Hidden Layer çš„è¾“å‡ºã€‚æŠŠè¿™ä¸ªå‘é‡æ‹¿å‡ºæ¥ä»£è¡¨è¿™å¼ å›¾ç‰‡ã€‚ æˆ‘ä»¬æ‹¿å‡ºæ¥çš„æ˜¯ä¸€ä¸ªå‘é‡ï¼Œè€Œä¸æ˜¯æœ€åçš„ç±»åˆ«ã€‚é‚£è™½ç„¶æœ€ååˆ†ç±»çš„ç±»åˆ«å¯èƒ½æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯åœ¨å†³å®šæœ€åçš„ç±»åˆ«ä¹‹å‰ï¼Œè¿™ä¸ªå‘é‡å°±ç®—éƒ½æ˜¯äººè„¸ï¼Œå¯èƒ½è¿˜æ˜¯ä¸ä¸€æ ·çš„ã€‚ å‡è®¾çœŸå®çš„å›¾ç‰‡è·Ÿç”¢ç”Ÿå‡ºæ¥çš„å›¾ç‰‡å®ƒä»¬éƒ½æ˜¯ Gaussians çš„ Distributionï¼Œç„¶åå»**è®¡ç®—è¿™ä¸¤ä¸ª Gaussians Distribution ä¹‹é—´çš„==FrÃ©chet Distance==**ã€‚å› ç‚ºå®ƒæ˜¯ä¸€ä¸ª Distanceï¼Œæ‰€ä»¥è¿™ä¸ªå€¼å°±æ˜¯è¶Šå°è¶Šå¥½ï¼Œä»£è¡¨è¿™ä¸¤ç»„å›¾ç‰‡è¶Šæ¥è¿‘ã€‚ ä½†å®é™…ä¸Šå›¾ç‰‡ä¸ä¸€å®šæ˜¯ Gaussians Distributionï¼Œä¸”è¦æº–ç¡®å¾—åˆ°ä½ çš„ Network å®ƒçš„åˆ†å¸ƒéœ€è¦ç”¢ç”Ÿå¤§é‡çš„ Sample æ‰èƒ½åšåˆ°ã€‚","link":"/2022/07/06/machine-learning/2022-07-06-review-generative-adversarial-network.md/"},{"title":"[ml][rv] pattern recognition","text":"1. æ€»è§ˆ è€ƒæ ¸å½¢å¼ ä¸»è¦è€ƒå¯¹æ¦‚å¿µçš„ä¸€äº›ç†è§£ï¼Œä¾‹å¦‚è¯´åç½®æ–¹å·®åˆ†è§£å’Œè¿‡æ‹Ÿåˆæ¬ æ‹Ÿåˆä¹‹é—´çš„å…³ç³» è®¡ç®—æœ‰ä½†ä¸æ˜¯å¤ªå¤š åœ¨ç†è§£çš„åŸºç¡€ä¸Šå¯¹ç®—æ³•è¿›è¡Œè®°å¿†ï¼Œæ¯”å¦‚ PCA &amp; LDAï¼Œä»–ä»¬çš„ç›®æ ‡å‡½æ•°ä¼˜åŒ–è¿™äº›éƒ½æ˜¯è¦çŸ¥é“çš„ 2. æå–ç‰¹å¾ æå–ç‰¹å¾ï¼šNormalization(Chap. 9), PCA(Chap. 5), FLD(Chap. 6), Sparse(Chap. 11), â€¦PCA æ— ç›‘ç£ï¼ŒFLD æœ‰ç›‘ç£åœ°åˆ©ç”¨æ ‡ç­¾å»æå–ç‰¹å¾çš„æ–¹æ³•Sparse æ²¡æœ‰è¯¦ç»†åœ°å»è®² Normalization å¯ä»¥æŠŠèŒƒå›´ä» [0, 1] æ‹‰ä¼¸è‡³ä»»æ„èŒƒå›´ã€‚ å¦‚æœæŸä¸€ç»´åº¦çš„æœ€å¤§å€¼ç­‰äºæœ€å°å€¼ï¼Œè¿™ä¸ªç»´åº¦çš„æ•°æ®å¯ä»¥ä¸¢æ‰ã€‚ å¦‚æœ 0 å€¼åœ¨åŸå§‹æ•°æ®ä¸­ä»£è¡¨ â€œç©ºâ€ï¼Œé‚£ä¹ˆåº”è¯¥æŠŠå®ƒè§„èŒƒæˆ0ã€‚ å¦‚æœæµ‹è¯•æ ·ä¾‹çš„æ•°æ®èŒƒå›´å¤§äº 0 æˆ– å¤§äº 1ï¼Œæœ‰æ—¶å€™ç®—æ³•å¿…é¡»è¦æ±‚ [0, 1]ï¼Œé‚£ä¹ˆå¯ä»¥æŠŠå°äº 0 çš„å€¼è®¾ä¸º 0ï¼Œå¤§äº 1 åŒç†ï¼Œå¦‚æœç®—æ³•ä¸è¦æ±‚å…¶å®ä¹Ÿå¯ä»¥è¿™ä¹ˆåšã€‚ å¦‚æœèƒ½çœ‹å‡ºæŸç»´æ•°æ®ç¬¦åˆé«˜æ–¯åˆ†å¸ƒï¼Œé‚£ä¹ˆä¹Ÿå¯ä»¥åŒ–ä¸ºæ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼š L-1 è§„èŒƒåŒ–ï¼šå¦‚æœå€¼éè´Ÿï¼Œè§„èŒƒåŒ–åæ ·ä¾‹å„ç»´ä¹‹å’Œä¸º 1 L-2 è§„èŒƒåŒ–ï¼šæŠŠæ•°æ®è§„èŒƒåŒ–ä¸ºå•ä½å‘é‡ PCAé¦–å…ˆè¦ä¼šåš SVD åˆ†è§£ã€‚ FLDæ€æƒ³ï¼šæŠŠæ•°æ®ç‚¹è¿›è¡ŒæŠ•å½±ï¼Œä½¿å¾—ä¸åŒç±»åˆ«ä¹‹é—´çš„æ•°æ®è·ç¦»å°½å¯èƒ½å¤§ã€‚ å¯åˆ†æ€§çš„ç»å¯¹è¦ç´ ï¼šä¸¤ä¸ªå‡å€¼ä¹‹é—´çš„è·ç¦» + ä¸¤ä¸ªæ ‡å‡†å·®ã€‚è¦å®ç°åˆ†ç±»ï¼Œå°±éœ€è¦æœ€å¤§åŒ–è¿™äºŒè€…çš„æ¯”ä¾‹ã€‚ æ³¨ï¼šPCA å’Œ FLD ä¸­çš„ X çš„å°ºå¯¸éƒ½æ˜¯ (dim x 1) ã€‚å› è€Œï¼Œ$$a^Ta$$ çš„ç»“æœæ˜¯ä¸€ä¸ªå€¼ï¼Œ$$aa^T$$ çš„ç»“æœæ˜¯ä¸€ä¸ªçŸ©é˜µã€‚ äºŒåˆ†ç±»çš„ FLDï¼š $$w$$ï¼šæŠ•å½±æ–¹å‘ $$m_i$$ ï¼šé›†åˆ i çš„å‡å€¼ $$C_i$$ ï¼šé›†åˆ i çš„åæ–¹å·®çŸ©é˜µ $$C_i = \\frac{1}{N_i} \\sum_{x \\in X_i} (x-m_i)(x-m_i)^T$$ ä¼ ç»Ÿ FLD ç”¨æ•£åº¦çŸ©é˜µè€Œä¸æ˜¯ç”¨åæ–¹å·®çŸ©é˜µï¼Œæ•£åº¦çŸ©é˜µ $$S_i = N_iC_i$$ ç±»é—´æ•£åº¦çŸ©é˜µ &amp; ç±»å†…æ•£åº¦çŸ©é˜µï¼š $$S_B=(m_1-m_2)(m_1-m_2)^T \\S_W = S_1+S_2$$ ç›®æ ‡å‡½æ•°ï¼ˆç¬¬ä¸€è¡Œçš„ m æ˜¯æŠ•å½±åçš„å‡å€¼ï¼Œç¬¬äºŒè¡Œçš„ m æ˜¯å‘é‡ï¼‰ï¼š $$J = \\frac{(m_1-m_2)^2}{\\sigma_1^2+\\sigma_2^2} \\= \\frac{(m_1^T w-m_2^Tw) ^ 2}{\\sigma_1^2+\\sigma_2^2} \\= \\frac{w^T(m_1-m_2)(m_1-m_2)^Tw}{w^T(C_1+C_2)w} \\= \\frac{w^TS_Bw}{w^TS_Ww} \\$$ å¦‚æœä¸€ä¸ªå‡å€¼å‘é‡æ‰®æ¼”äº†æ‰€å±ç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬çš„ä»£ç†ï¼Œé‚£ä¹ˆå°±å¯ä»¥ç”¨å‡å€¼å‘é‡é›†åˆçš„æ•£åº¦çŸ©é˜µä»£æ›¿ $$S_B$$ $$\\sum^{2}_{i=1}(m_i - \\overline{m})(m_i - \\overline{m}) ^T \\\\overline{m} = \\frac{m_1+m_2}{2}$$ ä¹‹åå°±å¯ä»¥è®¡ç®—ä»¥åŠè§„èŒƒåŒ–äº†ã€‚ è€ƒè™‘è‡³å¤šç±»åˆ«å‘¢ï¼Ÿ ç±»å†…æ•£åº¦çŸ©é˜µ $$S_W = \\sum ^{K}{k=1} S_k = \\sum ^{K}{k=1}N_kC_k = \\sum ^{K}{k=1} \\sum{x \\ in X_k}(x-m_i)(x-m_i)^T$$ æ€»æ•£åº¦çŸ©é˜µ $$S_T = \\sum ^{N}{i=1}(x_i-m)(x_i-m)^T \\m = \\frac{1}{N} \\sum^{N}{i=1}x_i$$ ç±»é—´æ•£åº¦çŸ©é˜µ $$S_B =\\sum ^{K}_{k=1}N_k(m_k-m)(m_k-m)^T$$ è§„å¾‹ï¼šæ€»æ•£åº¦çŸ©é˜µ = ç±»å†…æ•£åº¦çŸ©é˜µ + ç±»é—´æ•£åº¦çŸ©é˜µã€‚ å¤šåˆ†ç±»é—®é¢˜ä¸­ï¼Œç±»é—´æ•£åº¦çŸ©é˜µä¸å†æ˜¯ç§©ä¸º 1 çš„çŸ©é˜µï¼Œç®—æ³• 6.1 ä¸å¯ç”¨ï¼Œæ•…æ±‚è§£å¦‚ä¸‹å¹¿ä¹‰ç‰¹å¾å€¼é—®é¢˜æ¥æ‰¾æœ€ä½³æŠ•å½±æ–¹å‘ï¼š $$S_B w = \\lambda S_W w$$ å½“ $S_W$ å¯é€†ï¼Œå¹¿ä¹‰ç‰¹å¾å€¼é—®é¢˜ç­‰ä»·äºï¼š $$S_W ^ {-1} S_B w = \\lambda w$$ é‚£ä¹ˆå¦‚ä½•æ‰¾æ›´å¤šæŠ•å½±æ–¹å‘ï¼ˆé™ä½æ›´å¤šç»´åº¦ï¼‰å‘¢ï¼Ÿç±»ä¼¼ PCAï¼Œåªè¦ä½¿ç”¨ä¸å‰ K-1 ä¸ªæœ€å¤§å¹¿ä¹‰ç‰¹å¾å€¼å¯¹åº”çš„å¹¿ä¹‰ç‰¹å¾å‘é‡å³å¯ Sparseå«ä¹‰ï¼šæœ€å°åŒ– $$l_0$$$ normï¼ˆå‘é‡ x çš„éé›¶å…ƒç´ ä¸ªæ•°ï¼‰ $$minimize\\ ||x||_0 \\subject\\ to\\ Ax=y$$ 3. åˆ†ç±»å™¨ åˆ†ç±»å™¨ï¼škNN, SVM, Decision Tree, Ensemble, Regression, NN, CNNkNN, SVM å‰ä¸¤ä¸ªé‡è¦ï¼Œåé¢éƒ½æ˜¯ç®€å•æä¸€ä¸‹CNN ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ä¸ªç‰¹å¾æå–çš„æ–¹æ³• kNNï¼ˆæœºå™¨å­¦ä¹ ï¼‰ç†è§£ä¸”ä¼šç”¨ ç¼ºé™·ä»¥åŠè§£å†³åŠæ³• å‡ºç°å¹³å±€ï¼šå¯ä»¥ç»™ä¸åŒçš„æ ·æœ¬æ–½åŠ ä¸åŒçš„æƒé‡ï¼ŒåŠ å¼ºä¾èµ–æ ·æœ¬çš„æƒé‡ï¼Œé™ä½ä¸å¯ä¿¡èµ–æ ·æœ¬çš„å½±å“ã€‚ ç¦»ç¾¤ç‚¹ å¤æ‚åº¦ O(nd) [dæ˜¯è®¡ç®—è·ç¦»çš„ä»£ä»·] SVMï¼ˆæœºå™¨å­¦ä¹ ï¼‰Decision Tree + Regressionï¼ˆæœºå™¨å­¦ä¹ ï¼‰EnsembleNNCNN4. æ¦‚ç‡æ¨¡å‹ æ¦‚ç‡æ¨¡å‹ (Chap. 8)ï¼šå‚æ•°ä¼°è®¡ï¼Œéå‚ï¼ŒHMMï¼ŒGMMå‚æ•°ä¼°è®¡ï¼šç‚¹ä¼°è®¡ï¼Œè´å¶æ–¯ä¼°è®¡ï¼ŒHMMéå‚æ•°ä¼°è®¡ï¼šKDEè¦çŸ¥é“ HMM çš„éšé©¬å°”å¯å¤«æ€§è´¨ + è¦çŸ¥é“ GMM çš„æ¦‚å¿µ æ¦‚ç‡æ¨¡å‹ï¼šè®¡ç®—å˜é‡çš„æ¦‚ç‡æˆ–è€…æ¦‚ç‡åˆ†å¸ƒçš„æ¨¡å‹ã€‚ å‚æ•°ä¼°è®¡ï¼šå‡è®¾ PDF æœä»æŸç§å‡½æ•°å½¢å¼ï¼Œå½“æŒ‡å®šå…¶æ‰€æœ‰å‚æ•°å€¼ä¹‹åï¼ŒPDF å°±å®Œå…¨ç¡®å®šï¼Œä¼°è®¡ PDF å°±æ˜¯ä¼°è®¡å‚æ•°ã€‚ éå‚æ•°ä¼°è®¡ï¼šéå‚æ•°ä¸ä»£è¡¨æ— å‚æ•°ï¼ˆå…è®¸æ— é™ï¼‰ï¼Œç”¨è®­ç»ƒæ•°æ®ç›´æ¥ä¼°è®¡ç©ºé—´ä¸­ä»»æ„ç‚¹çš„å¯†åº¦ p(x|D)ã€‚ ç”Ÿæˆæ¨¡å‹ï¼šä¼°è®¡ p(x|y=i) å’Œ p(y=i)ï¼Œæ ¹æ®è´å¶æ–¯å®šç†æ±‚ p(y=i|x) åˆ¤åˆ«æ¨¡å‹ï¼šç›´æ¥ä¼°è®¡ p(y=i|x) è¿™äº›æ¨¡å‹éƒ½æœ‰ä¸¤ä¸ªæ­¥éª¤ï¼šæ¨ç†å’Œå†³ç­–ï¼Œåˆ†åˆ«æ˜¯ä¼°è®¡å„ç§å¯†åº¦å‡½æ•°ï¼Œæ ¹æ®ä¼°è®¡å¾—åˆ°çš„PDFå¯¹ä»»æ„çš„ï¼Ÿç»™å‡ºè¾“å‡ºã€‚ ç‚¹ä¼°è®¡ï¼ˆå‚ï¼‰ç‚¹ä¼°è®¡ï¼ˆpoint estimationï¼‰æ˜¯ç”¨æ ·æœ¬ç»Ÿè®¡é‡æ¥ä¼°è®¡æ€»ä½“å‚æ•°ï¼Œå…¸å‹çš„å¦‚ MLE å’Œ MAPï¼ŒæŠŠ $$\\theta$$ è§†ä½œå›ºå®šå‚æ•°ï¼Œç›®çš„æ˜¯æ‰¾è¿™ä¸ªæœ€ä½³å‚æ•°ã€‚ p(D|theta) ä¸æ˜¯ PDFï¼Œä½† p(x|theta) æ˜¯ã€‚ likelihood function of MLEï¼š $$l(\\theta) = p(D|\\theta) = \\prod_{i}p(x_i|\\theta)$$ é«˜æ–¯åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå¯ä»¥é€šè¿‡å¯¹ $ll(\\theta)$ æ±‚åå¾®åˆ†å¾—åˆ°ç»“æœï¼š $$\\mu = \\frac{1}{n} \\sum^{n}{i=1}x_i \\\\sigma^2 = \\frac{1}{n} \\sum^{n}{i=1}(x_i-\\mu)(x_i-\\mu)^T$$ æœ€å¤§åéªŒä¼°è®¡ï¼ˆMAPï¼‰ï¼šæŠŠå‚æ•° theta è‡ªèº«çš„å–å€¼å¯èƒ½æ€§è€ƒè™‘è¿›æ¥ã€‚å¦‚æœä¸€æ— æ‰€çŸ¥å°±ç­‰ä»·äº MLEã€‚ $$\\theta = argmax_{\\theta} l(\\theta)p(\\theta)$$ æ¸è¿›æ€§è´¨ï¼ˆasymptotic propertyï¼‰ï¼Œå¦‚ä¸€è‡´æ€§ï¼ˆconsistencyï¼‰ï¼šéšæ ·æœ¬å®¹é‡å¢å¤§æ”¶æ•›åˆ°å‚æ•°çœŸå€¼çš„ä¼°è®¡é‡ å…¶ä»–æ€§è´¨ï¼Œæ— åä¼°è®¡ï¼ˆunbiased estimateï¼‰ï¼šæŒ‡ä¼°è®¡é‡çš„æœŸæœ›å’Œè¢«ä¼°è®¡é‡çš„çœŸå€¼ç›¸ç­‰ å®Œæˆ inference åï¼Œå¦‚ä½•å†³ç­–ï¼Ÿæ ¹æ®å‚æ•°å¾—åˆ°åéªŒæ¦‚ç‡ p(y|x;theta) å¾—å‡ºç»“æœï¼Œåœ¨ 0-1 é£é™©æ—¶ï¼Œé€‰æ‹©æ¦‚ç‡å¤§çš„å°±è¡Œã€‚ è´å¶æ–¯ä¼°è®¡ï¼ˆå‚ï¼‰ç‚¹ä¼°è®¡æ˜¯æŠŠ $\\theta$ çœ‹æˆå›ºå®šå‚æ•°ï¼Œè€Œè´å¶æ–¯ä¼°è®¡ p(theta|D) æ˜¯ä¼°è®¡ä¸€ä¸ª $$\\theta$$ çš„åˆ†å¸ƒï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå€¼ï¼ˆç‚¹ï¼‰ï¼ é«˜æ–¯åˆ†å¸ƒå‚æ•°çš„è´å¶æ–¯ä¼°è®¡ï¼šè®¾å‚æ•° theta çš„å…ˆéªŒåˆ†å¸ƒ p(theta)ï¼Œæ•°æ® X = {x1, â€¦ , xn}ï¼Œä¼°è®¡ p(theta|D)ã€‚è¿™é‡Œå‡è®¾å•å˜é‡ï¼Œåªä¼°è®¡ p(theta|D) çš„é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ muï¼Œæ–¹å·® sigma^2 å·²çŸ¥ï¼š æ ¹æ®å·²çŸ¥çš„å…ˆéªŒé«˜æ–¯åˆ†å¸ƒ P(theta) = N(mu0, sigma0^2) æ ¹æ®è´å¶æ–¯å®šç†å’Œç‹¬ç«‹æ€§ï¼Œå¯ä»¥å¾— p(theta|D) = ä¼°è®¡å‡å€¼ &amp; æ–¹å·®ä¸ºï¼š å…±è½­å…ˆéªŒconjugate priorï¼šè‹¥ p(x|theta) ï¼Œå­˜åœ¨å…ˆéªŒ p(theta)ï¼Œä½¿å¾— p(x|theta) å’Œ p(theta) æœ‰ç›¸åŒçš„å‡½æ•°å½¢å¼ï¼Œä»è€Œç®€åŒ–æ¨å¯¼å’Œè®¡ç®—ã€‚å¦‚é«˜æ–¯åˆ†å¸ƒçš„å…±è½­å…ˆéªŒåˆ†å¸ƒä»ç„¶æ˜¯é«˜æ–¯åˆ†å¸ƒã€‚ å®Œæˆ inference åï¼Œå¦‚ä½•å†³ç­–ï¼Ÿè¾“å‡ºä¸€ä¸ªåˆ†å¸ƒï¼Œç»“æœé€šå¸¸æ ¹æ®æœŸæœ›å†³å®šã€‚ KDEï¼ˆéå‚ï¼‰å¸¸ç”¨çš„å‚æ•°å½¢å¼åŸºæœ¬éƒ½æ˜¯å•æ¨¡çš„ï¼Œä¸è¶³ä»¥æè¿°å¤æ‚çš„æ•°æ®åˆ†å¸ƒã€‚å› æ­¤åº”è¯¥ç›´æ¥ä»¥è®­ç»ƒæ•°æ®è‡ªèº«æ¥ä¼°è®¡åˆ†å¸ƒã€‚ ä¾‹ï¼šç›´æ–¹å›¾ã€‚æ¯ç»´ n ä¸ªbinï¼Œé‚£ä¹ˆ n ç»´åº”è¯¥ä¿å­˜å¤šå°‘ä¸ªbinçš„å‚æ•°ï¼Ÿ$$n^d$$ã€‚å¤ªå¤§äº†ï¼Œä¸”ä¸å…‰æ»‘ï¼ ç»™å®šä¸€ç»„æå–äºæœªçŸ¥åˆ†å¸ƒ p(x) çš„æ•°æ® $x_1,x_2,â€¦,x_n$ ï¼Œä»»ä¸€ç‚¹ x å¤„çš„æ ¸å¯†åº¦ä¼°è®¡å®šä¹‰ä¸ºï¼š $$\\hat{p}(x) = \\frac{1}{nh} \\sum^{n}_{i=1}K(\\frac{x-x_i}{h})$$ $$K(x) \\ge0, \\int K(x)dx=1$$ KDE æ ¸å‡½æ•°ä¸ SVM çš„ä¸åŒï¼šåœ¨æ¦‚ç‡ä¼°è®¡ä¸­è¢«ç”¨äºä¼°è®¡ç›®æ ‡ç‚¹å‘¨å›´çš„æ¦‚ç‡å¯†åº¦ã€‚è€Œåœ¨SVMä¸­ï¼Œè¢«ç”¨äºè®¡ç®—ä¸¤ç‚¹é—´çš„æ ¸ç©ºé—´è·ç¦»ã€‚ è¿ç»­çš„ã€‚ çª—å®½ç¡®å®šï¼šä½¿å¾—ä¼°è®¡çš„ç§¯åˆ†å‡æ–¹è¯¯å·® (mean integral square error,MISE) è¾¾åˆ°æœ€å°ï¼Œå¦‚ä¸‹å¼ $$MISE{\\hat{p}h(x)}=E[\\int^{\\inf}{-\\inf}{\\hat{p}_h(x)-p(x)}dx]$$ HMMï¼ˆæœºå™¨å­¦ä¹ ï¼‰éšé©¬å°”å¯å¤«æ€§è´¨ $$P(X_t|X_{1:t-1})=P(X_t|X_{t-1})$$ ï¼Œæ— è®°å¿†æ€§ï¼Œå½“å‰çŠ¶æ€çš„åªè·Ÿä¸Šä¸€ä¸ªçŠ¶æ€æœ‰å…³ç³»ã€‚ éšæœºè¿‡ç¨‹ï¼ˆstochastic processï¼‰ $${X(t), t\\in T}$$ æ˜¯ä¸€ç³»åˆ—éšæœºå˜é‡çš„é›†åˆï¼Œç”¨äºæè¿°ä¸€äº›è¿‡ç¨‹çš„æ—¶é—´è¿›åŒ–ï¼Œç›®çš„æ˜¯å¸Œæœ›è¿‡å»å¯¹ç°åœ¨æœ‰å¸®åŠ©ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºæ¯ä¸ª $$t \\in T$$, $$X(t)$$ æ˜¯ä¸€ä¸ªéšæœºå˜é‡ã€‚ç´¢å¼• t é€šå¸¸è¢«è§£é‡Šä¸ºæ—¶é—´ï¼Œå› æ­¤æŠŠ $$X(t)$$ ä½œä¸º t æ—¶æµç¨‹çš„çŠ¶æ€ã€‚ Bï¼šemission probability å‘å‡ºè§‚å¯Ÿå€¼çš„æ¦‚ç‡ã€‚$$b_j(k)=Pr(O_t=V_k|Q_t=S_j)$$ã€‚å½“æœªçŸ¥çŠ¶æ€ä¸º $$S_j$$ æ—¶è§‚å¯Ÿåˆ°ä¸º $$V_k$$ çš„æ¦‚ç‡ã€‚ Problem 1. Evaluation æ¦‚å¿µï¼šç»™å®šå·²çŸ¥ $$\\lambda = (A,B,\\pi)$$ çš„ HMM æ¨¡å‹ï¼Œä»¥åŠä¸€ä¸ªå®Œæ•´çš„è¾“å‡ºåºåˆ— $$o=o_{1:T}$$ï¼Œæ±‚è¯¥æ¨¡å‹è§‚å¯Ÿåˆ°è¯¥è¾“å‡ºåºåˆ—çš„æ¦‚ç‡ $$P(O|\\lambda)$$ã€‚ ä½œç”¨ï¼šçœ‹å‡ºæ­¤æ¨¡å‹å¯¹è¯¥è§‚å¯Ÿåºåˆ—çš„æˆç»©ï¼Œä»è€Œåœ¨å¤šä¸ªæ¨¡å‹ä¸­é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ã€‚ ç®—æ³• Naive å‡è®¾éšçŠ¶æ€åºåˆ— $q_{1:T}$ å·²çŸ¥ï¼š $$Pr(o_{1:T}|\\lambda, q_{ 1:T}) = \\prod^{T}{t=1}Pr(o_t|q_t, \\lambda) = \\prod^{T}{t=1}b_{q_i}(o_i)$$ åˆ™å¿…æœ‰ $$Pr(o_{1:T}|\\lambda) = Pr(o_{1:T}, q_{1:T}|\\lambda) =\\sum_{all\\ Q}Pr(o_{1:T}|\\lambda, q_{ 1:T})Pr(q_{1:T}|\\lambda)$$ æ—¶é—´å¤æ‚åº¦ $$O(TN^T)$$ å¯¹ Naive çš„è§‚å¯Ÿä¸ä¼˜åŒ–â€”â€”æå– $$b_i(o_i)$$ $$Pr(o_{1:T}|\\lambda)=\\sum_{i=1}^{N}Pr(o_{1:T},Q_T=S_i|\\lambda)\\=\\sum_{i=1}^{N}Pr(o_{1:T-1},Q_T=S_i|\\lambda)Pr(O_T=V_k|Q_T=S_i,\\lambda)\\=\\sum_{i=1}^{N}Pr(o_{1:T-1},Q_T=S_i|\\lambda)b_i(o_T)$$ å¯¹ Naive çš„è§‚å¯Ÿä¸ä¼˜åŒ–â€”â€”æå– $$A_{ji}$$ $$Pr(o_{1:T-1},Q_T=S_i|\\lambda) = \\sum_{j=1}^{N}Pr(o_{1:T-1},Q_{T-1}=S_j|\\lambda)A_{ji}$$ æ ¹æ® 2. å’Œ 3. çš„æå–ä¼˜åŒ–ï¼Œå¯å¾— $$Pr(o_{1:T}|\\lambda)=\\sum_{i=1}^{N}Pr(o_{1:T},Q_T=S_i|\\lambda)\\=\\sum_{i=1}^{N}Pr(o_{1:T-1},Q_T=S_i|\\lambda)b_i(o_T)\\=\\sum_{i=1}^{N}(b_i(o_T)\\sum_{j=1}^{N}Pr(o_{1:T-1},Q_{T-1}=S_j|\\lambda)A_{ji}) \\$$ å‰å‘ç®—æ³• forward å®šä¹‰ $$\\alpha_{t}(i)=Pr(o_{1:t},Q_t=S_i|\\lambda)$$ã€‚å«ä¹‰ï¼šå¯¹äºå·²çŸ¥å‚æ•° $$\\lambda$$ çš„æ¨¡å‹ï¼Œè·å¾—è§‚æµ‹åºåˆ— $$o_{1:T}$$ ä¸” t æ—¶åˆ»éšçŠ¶æ€ä¸º $$S_i$$ çš„æ¦‚ç‡ã€‚ åˆå§‹åŒ–ï¼š$$\\alpha_1(i)=Pr(o_{1},Q_1=S_i|\\lambda) = Pr(Q_1=S_i|\\lambda)Pr(o_{1}|Q_1=S_i,\\lambda) = Pr(Q_1=S_i|\\lambda)b_i(o_1)$$ å‰å‘é€’æ¨ï¼š $$\\alpha_{t+1}(i)=[\\sum^{N}{j=1} Pr(o{1:t},Q_t=S_j|\\lambda)A_{ji}]b_i(o_{t+1})\\=[\\sum^{N}{j=1} a{t}(j)A_{ji}]b_i(o_{t+1})$$ ç»“æœï¼š$$Pr(o_{1:T}|\\lambda)=\\sum^{N}{i=1}Pr(o{1:T},Q_T=S_i|\\lambda)=\\sum^{N}_{i=1} \\alpha_T(i) $$ å¤æ‚åº¦ï¼š$$O(TN^2)$$ â‘¤ åå‘ç®—æ³• backward å®šä¹‰ $$\\beta_t(i) = Pr(o_{t+1:T}|Q_t=S_i, \\lambda)$$ã€‚å«ä¹‰ï¼šå¯¹äºå·²çŸ¥å‚æ•° $$\\lambda$$ çš„æ¨¡å‹ï¼Œå·²çŸ¥ t æ—¶åˆ»çŠ¶æ€ä¸º $$S_i$$ï¼Œæœªæ¥è§‚æµ‹åˆ° $$o_{t+1:T}$$ çš„æ¦‚ç‡ã€‚ åˆå§‹åŒ–ï¼š$$\\beta_T(i) = 1$$ã€‚ åå‘æ›´æ–°ï¼š $$\\beta_t(i) = \\sum^{N}{j=1}A{ij}b_j(o_{t+1})\\beta_{t+1}(j)$$ è¾“å‡ºï¼š$$Pr(o_{1:T}|\\lambda)=\\sum^{N}{i=1}\\pi{i}b_i(o_{1})\\beta_{1}(i)$$ Problem 2ï¼šDecoding æ¦‚å¿µï¼šç»™å®šå·²çŸ¥ $$\\lambda = (A,B,\\pi)$$ çš„ HMM æ¨¡å‹ï¼Œä»¥åŠä¸€ä¸ªå®Œæ•´çš„è¾“å‡ºåºåˆ— $$o=o_{1:T}$$ï¼Œæ±‚ä¸€ä¸ªå®Œå…¨æŒ‡å®šçš„éšå˜é‡åºåˆ— $$q_{1:T}$$ çš„å€¼ã€‚ ä½œç”¨ï¼šè¯­éŸ³è¯†åˆ«ä¸­çŠ¶æ€å¯èƒ½æœ‰å®é™…æ„ä¹‰ï¼ˆå„éŸ³èŠ‚ï¼‰ï¼Œå¯ä»¥ç”¨æ¥è§‚å¯Ÿæ¨¡å‹ç»“æ„ï¼Œä¼˜åŒ–æ¨¡å‹ã€‚ ç®—æ³•ï¼š Problem 3ï¼šLearning æ¦‚å¿µï¼šå‘ç° $$\\lambda = (A,B,\\pi)$$ï¼Œä½¿å¾—å¯¹äºå›ºå®šçš„ Nï¼ŒTï¼Œå’Œè§‚å¯Ÿå€¼ Oï¼Œä¼¼ç„¶æ¦‚ç‡ $$P(O|\\lambda)$$ æœ€å¤§ã€‚ ä½œç”¨ï¼šæœ€é‡è¦çš„é—®é¢˜ ç›®å‰æ— æ³•å‘ç°å…¨å±€æœ€ä¼˜è§£ï¼Œå¸¸ç”¨ Baum-Welch ç®—æ³•ã€‚ 5. ä¼˜åŒ–æ–¹æ³• ä¼˜åŒ–æ–¹æ³•ï¼šæå€¼æ¡ä»¶ï¼Œå¯¹å¶ï¼ŒKKTï¼ŒGDï¼ŒSGDï¼ŒEMï¼Œè¦çŸ¥é“å‡¸ä¼˜åŒ–å’Œéå‡¸ä¼˜åŒ–ï¼Œè¦çŸ¥é“å‡¸ä¼˜åŒ–çš„è¯ï¼Œæå€¼å°±æ˜¯æœ€ä¼˜ç‚¹ï¼Œé‚£ä¹ˆæ‰¾æœ€ä¼˜ç‚¹å°±æ˜¯å¯¼æ•°ç­‰äº0è¦ç›´åˆ° SVM é‡Œé¢çš„å¯¹å¶é—®é¢˜ï¼ŒSVM æ²¡æœ‰æ˜¾å¼æœ€ä¼˜è§£ï¼Œå› æ­¤å¯ä»¥ç”¨ GDï¼ŒRegression æœ‰æ˜¾å¼æœ€ä¼˜è§£åœ¨ç¥ç»ç½‘ç»œé‡Œé¢ä¸€èˆ¬ç”¨ SGDï¼ŒSGD è¦æœ‰ä¸€ä¸ªæ¦‚å¿µï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬è¦ç”¨ SGD å’Œ GDï¼Ÿè¦çŸ¥é“äºŒè€…åŒºåˆ«ï¼Œè¿˜å¾—çŸ¥é“ SGD ä¼˜ç‚¹è¦å¯¹æ¦‚ç‡æ¨¡å‹çš„å‚æ•°è¿›è¡Œä¼°è®¡çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ç”¨ EM è¿›è¡Œå‚æ•°ä¼°è®¡ï¼Œæ¯”å¦‚ HMM å‡¸ä¼˜åŒ–å®šä¹‰ï¼š $$minimize \\ f_0(x) \\subject \\ to \\ f_i(x)&lt;=b_i,\\ \\ i=1,â€¦,m$$ å…¶ä¸­ï¼Œç›®æ ‡å‡½æ•°å’Œçº¦æŸå‡½æ•°éƒ½æ˜¯å‡¸å‡½æ•°ï¼Œå³ $$f_i(\\alpha x+\\beta y) &lt;= \\alpha f_i(x) + \\beta f_i(y) \\\\alpha + \\beta = 1,\\ \\alpha &gt;=0, \\ \\beta&gt;=0$$ [SVM ä¸­çš„å¯¹å¶ &amp; KKTï¼ˆæœºå™¨å­¦ä¹ ï¼‰GD &amp; SGDéšæœºæ¢¯åº¦ä¸‹é™æ¯æ¬¡åªç”¨ä¸€ä¸ªæ ·æœ¬ï¼Œå¯¹äºæœ€ä¼˜åŒ–å‡¸é—®é¢˜ï¼Œè™½ç„¶ä¸æ˜¯æ¯æ¬¡è¿­ä»£å¾—åˆ°çš„æŸå¤±å‡½æ•°éƒ½å‘ç€å…¨å±€æœ€ä¼˜æ–¹å‘ï¼Œ ä½†æ˜¯å¤§çš„æ•´ä½“çš„æ–¹å‘æ˜¯å‘å…¨å±€æœ€ä¼˜è§£çš„ï¼Œæœ€ç»ˆçš„ç»“æœå¾€å¾€æ˜¯åœ¨å…¨å±€æœ€ä¼˜è§£é™„è¿‘ã€‚ä½†æ˜¯ç›¸æ¯”äºæ‰¹é‡æ¢¯åº¦ï¼Œè¿™æ ·çš„æ–¹æ³•æ›´å¿«ï¼Œæ›´å¿«æ”¶æ•›ã€‚ æ‰¹é‡æ¢¯åº¦ä¸‹é™æ¯æ¬¡æ›´æ–°æ—¶ç”¨æ‰€æœ‰æ ·æœ¬ã€‚å¯¹äºæœ€ä¼˜åŒ–å‡¸é—®é¢˜ï¼Œå¯ä»¥è¾¾åˆ°ä¸€ä¸ªå…¨å±€æœ€ä¼˜ã€‚å¦‚æœæ ·æœ¬ä¸å¤šçš„æƒ…å†µä¸‹ï¼Œå½“ç„¶æ˜¯è¿™æ ·æ”¶æ•›çš„é€Ÿåº¦ä¼šæ›´å¿«ã€‚ä½†æ˜¯å¾ˆå¤šæ—¶å€™ï¼Œæ ·æœ¬å¾ˆå¤šï¼Œæ›´æ–°ä¸€æ¬¡è¦å¾ˆä¹…ã€‚ EM &amp; GMMï¼ˆæœºå™¨å­¦ä¹ ï¼‰æµ™å¤§ 6. è·ç¦»åº¦é‡ ï¼ˆæ ·æœ¬ä¹‹é—´çš„ï¼‰è·ç¦»åº¦é‡ï¼šl-p èŒƒæ•°, DTW, â€¦è¦çŸ¥é“å¦‚ä½•åº¦é‡ä¸¤ä¸ªä¸åŒæ—¶é—´åºåˆ—çš„æ ·æœ¬ä¹‹é—´çš„è·ç¦»DTW åŠ¨æ€æ—¶é—´è§„æ•´ $$l_0$$ èŒƒæ•°ï¼šå‘é‡ x çš„éé›¶å…ƒç´ çš„ä¸ªæ•° DTWï¼ˆDynamic Time Warpingï¼‰ï¼šåŠ¨æ€æ—¶é—´è§„æ•´ æ€§è´¨ï¼š1. åŒ¹é…æ˜¯é¡ºåºçš„ 2. æ¯ä¸ª $$x_i$$ æˆ– $$y_i$$ éƒ½è¦æœ‰å¯¹åº”çš„åŒ¹é… 3. ä¸€ä¸ª $$x_i$$ å¯ä»¥å’Œå¤šä¸ª $$y_j$$ åŒ¹é…ï¼Œåä¹‹äº¦ç„¶ é€’æ¨å…¬å¼ï¼š ç†µå•å˜é‡ $$H=-\\sum^{m}_{i=1}p_ilog_2p_i$$ $$h=-\\int p(x)ln(p(x))dx$$ åŒå˜é‡ $$H(x,y)=-\\sum_{x}\\sum_{y}P(x,y)log_2P(x,y)$$ $$h=-\\int p(x,y)ln(p(x,y))dxdy$$ $$H(X|Y) = \\sum_{y}P(y)H(X|Y=y) =-\\sum_{y}P(y)\\sum_{x}P(X=x|Y=y)log_2P(X=x|Y=y) \\= -\\sum_{x,y}P(x,y)log_2 \\frac{P(x,y)}{p(y)}$$ $$h(x,y) = -\\int p(x,y)ln\\frac{p(x,y)}{p(y)}dxdy$$ ç†µä¹‹é—´çš„å…³ç³» H(X,Y)=H(X)+H(Y|X)=H(Y)+H(X|Y) H(X|Y)&lt;H(X) H(Y|X)&lt;H(Y) äº’ä¿¡æ¯ $$I(X;Y)=H(X)-H(X|Y) = \\sum_{x,y}P(x,y)log_2 \\frac{P(x,y)}{P(x)P(y)}$$ KL æ•£åº¦ $$KL(P||Q)=\\sum_{i} P_ilog_2\\frac{P_i}{Q_i}$$ $$KL(P||Q) \\ge 0$$ï¼Œç­‰å·æˆç«‹æ¡ä»¶ï¼š$$P_i=Q_i$$ã€‚ä¸å¯¹ç§°ã€‚ äº¤å‰ç†µ $$CE(P,Q)=-\\sum_{i}P_ilog_2Q_i \\CE(P,Q)=H(p)+KL(P||Q)=-\\sum_{i}P_ilog_2P_i+\\sum_{i} P_ilog_2\\frac{P_i}{Q_i}$$ 7. æŸå¤±å‡½æ•° æŸå¤±å‡½æ•°ï¼šsquare, hinge, exponential, logistic, cross entropy, â€¦çº¿æ€§å›å½’ï¼šsquareSVMï¼šhingeAdaboostï¼šexpé€»è¾‘å›å½’ï¼šlogisticç¥ç»ç½‘ç»œï¼šcross entropy Squareï¼ˆæœºå™¨å­¦ä¹ ï¼‰å½¢å¼ï¼š $$L(f,y)=(f-y)^2$$ çº¿æ€§å›å½’ä¸­çš„ Squareï¼š $$L=\\sum^{N}_{i=1}(y_i-\\theta^Tx_i)$$ Hingeè¯‘ä¸ºé“°é“¾æŸå¤±ã€‚ å½¢å¼ï¼š $$L(y,f(x)) = max(0,1-yf(x)),$$ SVM ä¸­çš„ Hingeï¼š $$L = \\frac{1}{2C}||w||^2+\\sum^{N}_{i=1}max(0, 1-y_i(\\theta^Tx_i+b))$$ Expè¯‘ä¸ºæŒ‡æ•°æŸå¤±ã€‚ å½¢å¼ï¼š $$L(y, f(x)) = exp[-yf(x)]$$ Adaboost ä¸­çš„ Expï¼š $$L(y, f(x)) = \\frac{1}{n} \\sum^{n}_{i=1} exp[-y_if(x_i)]$$ Logisticï¼ˆæœºå™¨å­¦ä¹ ï¼‰å½¢å¼ï¼š $$L(y,f(x))=\\sum_{l}y^l ln P(y^l=1|x^l,w)+(1-y^l)ln P(y^l=0|x^l,w) \\=\\sum_{l}y^l(w_0+\\sum^{n}{i=1}w_ix_i^l)-ln(1+exp(w_0+\\sum^{n}{i=1}w_ix_i^l))$$ Cross entropyå½¢å¼ï¼š $$L(y,f(x)) = -\\sum^{n}_{i=1}y_i logf(x_i)$$ 8. è¯„ä»·å‡†åˆ™ è¯„ä»·å‡†åˆ™ï¼šAcc, ROC, AP, Recall (TPR, true position rate), Precision, Bayes error, Bias-varianceæ¦‚å¿µæŒæ¡Bayes errorï¼šå–ä¸€ä¸ªåéªŒæ¦‚ç‡æœ€å¤§çš„å»ä½œä¸ºæ¨¡å‹é¢„æµ‹çš„è¾“å‡ºBias-varianceï¼šæŠŠæ¨¡å‹çš„è¯¯å·®åšä¸€ä¸ªåæ‰§æ–¹å·®åˆ†è§£ï¼Œéœ€è¦ç›´åˆ°æ¨¡å‹çš„åç½®å’Œæ–¹å·®ï¼Œä»¥åŠæ˜¯ç”±ä»€ä¹ˆå†³å®šçš„ PPT 3-4","link":"/2022/07/06/machine-learning/2022-07-06-review-pattern-recognition-courses/"},{"title":"[ml][nt] support vector machine","text":"æ²¡æœ‰å…è´¹çš„åˆé¤å®šç†ï¼šåœ¨ä¸è€ƒè™‘å…ˆéªŒæ¦‚ç‡çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰ç®—æ³•çš„æ€§èƒ½ä¸€æ ·ã€‚å³æ²¡æœ‰ä¸å­˜åœ¨é€‚ç”¨äºæ‰€æœ‰çš„é—®é¢˜çš„ç®—æ³•ï¼Œä¸å­˜åœ¨æ™®é€‚æ€§çš„ç®—æ³•ï¼Œä»»ä½•ä¸¤ä¸ªç®—æ³•ï¼Œä»¥åŠå®ƒä»¬è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ï¼Œåœ¨æ‰€æœ‰çš„ç°å®é—®é¢˜çš„é›†åˆé¢å‰æ˜¯æ— ä¼˜åŠ£çš„ï¼Œå®ƒä»¬çš„æ€§èƒ½çš„æ•°å­¦æœŸæœ›å€¼æ˜¯ä¸€æ ·çš„ã€‚ å°½ç®¡å¦‚æ­¤ï¼Œé€‚åˆå¤§éƒ¨åˆ†æƒ…å†µçš„ç®—æ³•ä¾ç„¶æ˜¯å­˜åœ¨çš„ã€‚ çº¿æ€§å¯åˆ†ï¼ˆLinear Separableï¼‰ï¼šå­˜åœ¨ä¸€æ¡ç›´çº¿åˆ†å¼€ä¸¤ç±»ã€‚çº¿æ€§ä¸å¯åˆ†ï¼ˆLinear Unseparableï¼‰ï¼šåä¹‹ã€‚ åŒæ ·åœ°ï¼Œå¯ä»¥å»¶ä¼¸è‡³é«˜ç»´ã€‚ç”¨æ•°å­¦æ–¹å¼è¡¨ç¤ºï¼š ä¸¤ä¾§æ­£è´Ÿå·æ˜¯äººä¸ºå®šä¹‰çš„ï¼Œå°†æƒé‡å’Œåç½®å–åï¼Œä¸¤ä¾§ç¬¦å·ä¹Ÿä¾¿å–åã€‚ çº¿æ€§å¯åˆ†çš„ä¸¥æ ¼å®šä¹‰ï¼šä¸€ä¸ªæ ·æœ¬è®­ç»ƒé›† $${(X_i, y_i), â€¦, (X_N,y_N)}$$ åœ¨ i=1-N çº¿æ€§å¯åˆ†ï¼Œæ˜¯æŒ‡å­˜åœ¨ $$(w_1, w_2, b)$$ ä½¿å¾—å¯¹ i=1-Nï¼Œéƒ½æœ‰ï¼š $$(1)\\ è‹¥y_i=+1, åˆ™w_1x_{i1}+w_2x_{i2}+b&gt;0 \\(2)\\ è‹¥y_i=-1, åˆ™w_1x_{i1}+w_2x_{i2}+b&lt;0$$ çº¿æ€§å¯åˆ†å®šä¹‰çš„ç®€åŒ–å½¢å¼ï¼š å¦‚æœ $$y_i$$ = +1 æˆ– -1ï¼Œä¸€ä¸ªæ ·æœ¬è®­ç»ƒé›† $${(X_i, y_i), â€¦, (X_N,y_N)}$$ åœ¨ i=1-N çº¿æ€§å¯åˆ†ï¼Œæ˜¯æŒ‡å­˜åœ¨ $$(w_1, w_2, b)$$ ä½¿å¾—å¯¹ i=1-Nï¼Œéƒ½æœ‰ï¼š $$y_i(w^TX_i+b)&gt;0$$ è¯¾åæ€è€ƒï¼š â‘  ä½ èƒ½å¦ç»™å‡ºå®é™…ç”Ÿæ´»ä¸­è®­ç»ƒæ ·æœ¬é›†æ˜¯çº¿æ€§å¯åˆ†å’Œçº¿æ€§ä¸å¯åˆ†çš„ä¾‹å­ï¼Ÿå¤§å¤šæ•°å®é™…ç”Ÿæ´»ä¸­çš„ä¾‹å­æ˜¯çº¿æ€§å¯åˆ†è¿˜æ˜¯çº¿æ€§ä¸å¯åˆ†ï¼Ÿ â‘¡ æˆ‘ä»¬å¯¹äºçº¿æ€§å¯åˆ†å’Œçº¿æ€§ä¸å¯åˆ†çš„å®šä¹‰åªæ˜¯å±€é™äºäºŒåˆ†ç±»é—´é¢˜ï¼Œè¯·å¯¹ç±»åˆ«æ•°å¤§äº 2 çš„æƒ…å†µï¼Œç»™å‡ºçº¿æ€§å¯åˆ†ä¸çº¿æ€§ä¸åˆ†ä¸¥æ ¼çš„æ•°å­¦å®šä¹‰ã€‚ â‘¢ è¯·é€šè¿‡æ•°å­¦å®šä¹‰ä¸¥æ ¼è¯æ˜ï¼Œåœ¨äºŒåˆ†ç±»æƒ…å†µä¸‹ï¼Œå¦‚æœä¸€ä¸ªæ•°æ®é›†æ˜¯çº¿æ€§å¯åˆ†çš„ï¼Œé‚£ä¹ˆä¸€å®šå­˜åœ¨æ— æ•°å¤šä¸ªè¶…å¹³é¢å¯ä»¥æŠŠè¿™ä¸¤ä¸ªç±»åˆ«å®Œå…¨åˆ†å¼€ã€‚ çº¿æ€§å¯åˆ†çš„è§£æ³•æ”¯æŒå‘é‡æœºç®—æ³•æ­¥éª¤ï¼šâ‘  è§£å†³çº¿æ€§å¯åˆ†é—®é¢˜ â‘¡ å†å°†çº¿æ€§å¯åˆ†é—®é¢˜ä¸­è·å¾—çš„ç»“è®ºæ¨å¹¿åˆ°çº¿æ€§ä¸å¯åˆ†æƒ…å†µ ä¾‹å­ï¼šä¸‰ç§åˆ†å‰²æŒ‰ç…§å…è´¹åˆé¤å®šç†åº”è¯¥éƒ½ä¸€æ ·ï¼Œä¸ºä»€ä¹ˆä¼šè§‰å¾— 2 æ¯”è¾ƒå¥½ï¼Ÿå› ä¸ºå»ºç«‹åœ¨è¿™æ ·ä¸€ä¸ªå…ˆéªŒå‡è®¾ï¼šè®­ç»ƒæ ·æœ¬çš„ä½ç½®åœ¨ç‰¹å¾ç©ºé—´ä¸Šæœ‰æµ‹é‡è¯¯å·®ï¼Œè¿™æ ·çš„è¯ 2 ä¼šæœ‰æ›´é«˜çš„å®¹é”™ç‡ã€‚ é‚£ä¹ˆå¦‚ä½•ç”»å‡º2çº¿ï¼Ÿä¹Ÿå°±æ˜¯SVMç®—æ³•çš„æ­¥éª¤â‘ ã€‚ æŠŠä¸€æ¡åˆ†å‰²çº¿å¹³è¡Œåœ°å¾€ä¸¤ä¾§ç§»åŠ¨ï¼Œç›´åˆ°æ“¦åˆ°ä¸¤è¾¹çš„æ ·æœ¬ã€‚ä»¤å¹³è¡Œçº¿æ“¦åˆ°çš„æ ·æœ¬ä¸ºæ”¯æŒå‘é‡ï¼ˆsupport vectorï¼‰ï¼Œå¹³è¡Œçº¿çš„é—´éš”ç§°ä¸ºé—´éš”ï¼ˆmarginï¼‰ï¼ŒSVMå°±æ˜¯è¦è®©é—´éš”åšæœ€å¤§çš„é‚£ä¸€ä¸ªåˆ†å‰²çº¿ã€‚ ä½†è¯¥æ–¹æ³•ä¸å”¯ä¸€ï¼Œä¸è¯¥çº¿å¹³è¡Œçš„çº¿éƒ½æ˜¯é—´éš”æœ€å¤§çš„ã€‚ä¸ºä¿è¯å”¯ä¸€æ€§ï¼Œåº”ä½¿è¿™æ¡çº¿åœ¨ä¸¤æ¡å¹³è¡Œçº¿ä¸­å¤®ã€‚ æ€»ç»“æ¡ä»¶ï¼šâ‘  è¯¥ç›´çº¿åˆ†å¼€äº†ä¸¤ç±» â‘¡ è¯¥ç›´çº¿æœ€å¤§åŒ–é—´éš” â‘¢è¯¥ç›´çº¿å¤„äºé—´éš”çš„ä¸­é—´ï¼Œåˆ°æ‰€æœ‰æ”¯æŒå‘é‡è·ç¦»ç›¸ç­‰ã€‚ åŸºäºä»¥ä¸‹äº‹å®ï¼š â‘  ç›¸åŒè¶…å¹³é¢ $$w^Tx+b=0 ä¸\\(\\alpha w^T)x+(ab)=0æ˜¯åŒä¸€ä¸ªè¶…å¹³é¢(\\alpha \\neq 0)$$ â‘¡ ç‚¹åˆ°ç›´çº¿/é¢çš„è·ç¦»å…¬å¼ $$d=\\frac{|w^Tx+b|}{||w||}$$ æˆ‘ä»¬è¦çš„å°±æ˜¯æœ€å¤§åŒ– margin åˆ° support vector ä¹‹é—´çš„è·ç¦»ï¼ æ®äº‹å®ä¸€ï¼Œå¼•å‡ºSVMæœ€éš¾ç†è§£çš„éƒ¨åˆ†ï¼šç”¨ a å»ç¼©æ”¾ w å’Œ bã€‚åœ¨ SVM ä¸­ï¼Œæˆ‘ä»¬ä¼šå‘ç°æˆ‘ä»¬ä¼šä»¤æ”¯æŒå‘é‡åˆ°ç‚¹çš„è·ç¦»è¿™ä¸€åˆ†å¼çš„åˆ†å­æ˜¯ 1ï¼Œä¸ºä»€ä¹ˆå¯ä»¥è¿™ä¹ˆè®¾å‘¢ï¼Ÿ å› ä¸ºå¯¹äºå¯¹äºä¸€ä¸ª $$(w, b)$$ï¼Œå¯ä»¥å¯¹é½è¿›è¡Œä»»æ„çš„ç­‰æ¯”ä¾‹æ”¾ç¼©å¾—åˆ° $$(aw, ab)$$ï¼ŒäºŒè€…æ‰€è¡¨ç¤ºçš„è¶…å¹³é¢æ˜¯ä¸å˜çš„ï¼Œä½†æ˜¯ä¼šä½¿å¾—åˆ†å­çš„å¤§å°å˜åŒ–ï¼Œå› æ­¤å¯ä»¥ä½¿å¾—ï¼š $$|w^Tx_0+b|=1, \\ x_0ä¸ºæ”¯æŒå‘é‡ \\ |w^Tx_0+b|&gt;1, \\ x_0éæ”¯æŒå‘é‡$$ è¿™æ ·æˆ‘ä»¬å°±å¤§å¹…ç®€åŒ–äº†è¦ä¼˜åŒ–çš„å¯¹è±¡ã€‚ä¹Ÿå³ $$d=\\frac{|w^Tx+b|}{||w||} = \\frac{1}{||w||}$$ å› è€Œé—®é¢˜è½¬æ¢ä¸ºæœ€å°åŒ– w çš„æ¨¡ã€‚å®æ“ä¸­ä¸ºæ–¹ä¾¿æ±‚å¯¼å®šä¹‰ä½œå¦‚ä¸‹å½¢å¼ï¼š $$æœ€å°åŒ–ï¼š\\frac{1}{2}||w||^2 \\é™åˆ¶æ¡ä»¶ï¼šy_i(w^TX_i+b) &gt;= 1,(i=1-N) \\||w||^2 = \\sum^{m}_{i=1}w_i^2$$ å…¶ä¸­ï¼Œ$$y_i$$ çš„ä½œç”¨æ˜¯åè°ƒè¶…å¹³é¢çš„ä½œç”¨ï¼ŒåŒçº¿æ€§å¯åˆ†ä¸­çš„ä½œç”¨ä¸€æ ·ã€‚ä¸Šè¿°çš„ 1 å¯ä»¥æ”¹æˆåˆ«çš„æ•´æ•°ï¼Œç›¸å½“äºæ”¾ç¼©çš„æ—¶å€™é‡‡ç”¨äº†ä¸åŒçš„å°ºåº¦ã€‚ å› è€Œï¼ŒSVMé—®é¢˜è½¬ä¸ºä¸€ä¸ªå‡¸ä¼˜åŒ–ä¸­çš„äºŒæ¬¡è§„åˆ’é—®é¢˜ã€‚ äºŒæ¬¡è§„åˆ’é—®é¢˜çš„å®šä¹‰ï¼šâ‘ ç›®æ ‡å‡½æ•°(Objective Function)æ˜¯äºŒæ¬¡é¡¹ã€‚â‘¡é™åˆ¶æ¡ä»¶æ˜¯ä¸€æ¬¡é¡¹ï¼ˆè¿™é‡Œçš„ä¸ç­‰å¼å°±æ˜¯ä¸€æ¬¡é¡¹ï¼‰ã€‚è¿™æ ·çš„é—®é¢˜è¦ä¹ˆæ— è§£ï¼Œè¦ä¹ˆæœ‰å”¯ä¸€æœ€å°å€¼ã€‚ å·²çŸ¥å‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå¿…æœ‰å…¨å±€å”¯ä¸€çš„æå€¼ï¼Œå¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™è§£å†³ã€‚å…·ä½“çš„è§£å†³æ–¹æ³•ï¼Œéœ€å­¦ä¹ ã€Šæœ€ä¼˜åŒ–ã€‹ã€‚ è¯¾åæ€è€ƒï¼š â‘  æ”¯æŒå‘é‡æœºçš„é™åˆ¶æ¡ä»¶å¦‚æœä»å¤§äºç­‰äº1å˜æˆå¤§äºç­‰äº2ï¼Œåˆ™(w, b)ä¼šå˜æˆ(aw , ab) ã€‚å¦‚æœ Xi å’Œ w æ˜¯ M ç»´å‘é‡ï¼Œé‚£ä¹ˆ a æ˜¯å¤šå°‘ï¼Ÿ â‘¡ è¯æ˜åœ¨çº¿æ€§å¯åˆ†æ¡ä»¶ä¸‹ï¼Œæœ‰ä¸”åªæœ‰å”¯ä¸€ä¸€æ¡ç›´çº¿æ»¡è¶³ SVM çš„ä¸‰ä¸ªæ¡ä»¶ã€‚ çº¿æ€§ä¸å¯åˆ†çš„è§£æ³•è€ƒè™‘çº¿æ€§ä¸å¯åˆ†çš„æƒ…å†µï¼Œéœ€è¦é€‚å½“æ”¾æ¾é™åˆ¶æ¡ä»¶ï¼Œå¦åˆ™ä»¥ä¸Šé—®é¢˜æ— è§£ã€‚ åŸºæœ¬æ€è·¯æœ‰ä¸ºä¸ºæ¯ä¸ªè®­ç»ƒæ ·æœ¬åŠå…¶æ ‡ç­¾è®¾ç½®æ¾å¼›å˜é‡ï¼ˆslack variableï¼‰Î´ã€‚ å› æ­¤ï¼Œé™åˆ¶æ¡ä»¶æ”¹å†™ä¸ºï¼š $$y_i(w^TX_i+b) &gt;= 1-\\delta_i,(i=1-N)$$ å½“ç„¶è¿˜è¦åŠ å…¥æ–°çš„é™åˆ¶ä½¿å¾— $$\\delta$$ åœ¨ä¸€ä¸ªåˆç†èŒƒå›´å†…ã€‚æœ€ç»ˆï¼Œè¯¥é—®é¢˜æ”¹å†™ä¸ºï¼š $$æœ€å°åŒ–ï¼š\\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i\\ æˆ–\\ \\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i^2 \\é™åˆ¶æ¡ä»¶ï¼š (1)\\ \\delta_i&gt;=0,(i=1-N)\\(2)\\ y_i(w^TX_i+b) &gt;= 1-\\delta_i,(i=1-N)$$ æ¯”ä¾‹å› å­Cï¼Œèµ·åˆ°å¹³è¡¡åŠ æ³•ä¸¤ä¾§çš„ä½œç”¨ï¼Œæ˜¯äººä¸ºè®¾å®šçš„è¶…å‚æ•°ã€‚å®æ“ä¸­ï¼Œè¦ä¸æ–­å˜åŒ–Cï¼ŒåŒæ—¶æµ‹è¯•ç®—æ³•çš„æ•ˆæœï¼Œç„¶åé€‰ä¸ªæœ€å¥½çš„ã€‚ä¸¤ä¸ªæœ€å°åŒ–å½¢å¼éƒ½æ˜¯äºŒæ¬¡å‹ã€‚C è®¾å°½å¯èƒ½å¤§ï¼Œå¯ä»¥å°½å¯èƒ½å‘çº¿æ€§çš„ç»“æœé æ‹¢ã€‚ ä¸€ä¸ªå¤±è´¥çš„æƒ…å†µï¼šçº¿æ€§æ¨¡å‹çš„è¡¨ç°åŠ›æ˜¯ä¸å¤Ÿçš„ã€‚ è¯¾åæ€è€ƒï¼š â‘  åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä½ èƒ½å¦è®¾è®¡å‡ºä¸€ä¸ªè¿™æ ·çš„éçº¿æ€§å˜æ¢ï¼Œå°†è¿™ä¸ªåˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§å¯åˆ†å‘¢ï¼Ÿ éçº¿æ€§å˜æ¢é’ˆå¯¹çº¿æ€§æ¨¡å‹è¡¨ç°åŠ›ä¸å¤Ÿçš„æƒ…å†µï¼Œå› è€Œéœ€è¦æ‰©å¤§å¯é€‰å‡½æ•°èŒƒå›´ã€‚SVMä¸­ï¼Œä¼šå°†ç‰¹å¾ç©ºé—´æŠŠä½ç»´æ˜ å°„åˆ°é«˜ç»´ï¼Œå†ä½¿ç”¨çº¿æ€§è¶…å¹³é¢åˆ†ç±»ã€‚ å®šç†ï¼šåœ¨ä¸€ä¸ª M ç»´ç©ºé—´ä¸Šéšæœºå– N ä¸ªè®­ç»ƒæ ·æœ¬éšæœºçš„å¯¹æ¯ä¸ªè®­ç»ƒæ ·æœ¬èµ‹äºˆæ ‡ç­¾ +1 æˆ– -1ï¼Œè¿™äº›è®­ç»ƒæ ·æœ¬çº¿æ€§å¯åˆ†çš„æ¦‚ç‡ä¸º P(M)ï¼Œå½“ M è¶‹äºæ— ç©·å¤§æ—¶ï¼ŒP(M) = 1ã€‚ æ„é€ æ˜ å°„ $$\\varphi(x)$$ ä¾¿æ˜¯å…³é”®ã€‚å‡è®¾å·²çŸ¥æ˜ å°„ $$\\varphi(x)$$ï¼Œåˆ™æ”¹ä¸ºï¼š $$æœ€å°åŒ–ï¼š\\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i\\ æˆ–\\ \\frac{1}{2}||w||^2 + C\\sum^{N}{i=1}\\delta_i^2 \\é™åˆ¶æ¡ä»¶ï¼š (1)\\ \\delta_i&gt;=0,(i=1-N)\\(2)\\ y_i(w^T\\varphi(X_i)+b) &gt;= 1-\\delta_i,(i=1-N)$$ æ­¤æ—¶ï¼Œw çš„ç»´åº¦å’Œæ˜ å°„åçš„å‘é‡ç»´åº¦ç›¸åŒã€‚è§£æ³•æ˜¯å’Œä½ç»´å®Œå…¨ç±»ä¼¼çš„ã€‚ ä¸ºç ”ç©¶ $$\\varphi(x)$$ çš„å½¢å¼ï¼Œå¼•å…¥æ ¸å‡½æ•°çš„æ¦‚å¿µã€‚å®æ“ä¸­æˆ‘ä»¬ä¸ç”¨çŸ¥é“ $$\\varphi(x)$$ çš„å…·ä½“å½¢å¼ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯æ ¸å‡½æ•°ï¼š å³å¯¹äºä»»æ„ä¸¤ä¸ªå‘é‡ï¼Œæœ‰ $$K(X_1,X_2)=\\varphi(X_1)^T\\varphi(X_2)$$ é‚£ä¹ˆä»ç„¶èƒ½é€šè¿‡ä¸€äº›æŠ€å·§è·å¾—æ ·æœ¬çš„ç±»åˆ«ï¼Œä»è€Œå®Œæˆå¯¹æ ·æœ¬ç±»åˆ«çš„é¢„æµ‹ã€‚å…·ä½“é€šè¿‡ä¸ºä»€ä¹ˆæŠ€å·§å°†åœ¨ä¹‹åæè¿°ã€‚åœ¨æ­¤å…ˆä¸¾ä¾‹è¯´æ˜æ ¸å‡½æ•°ä»¥åŠä½ç»´åˆ°é«˜ç»´çš„æ˜ å°„ $$\\varphi(x)$$ ä¹‹é—´çš„ç›¸äº’å…³ç³»ã€‚ å‡è®¾ $$\\varphi(x)$$ æ˜¯ä¸€ä¸ªæŠŠäºŒç»´å‘é‡æ˜ å°„ä¸ºä¸‰ç»´å‘é‡çš„æ˜ å°„ï¼š $$X=[x_1,x_2]^T \\\\phi(X)=\\phi([x_1,x_2]^T)=[x_1^2,x_1x_2,x_2^2]$$ å‡è®¾æœ‰ X1 å’Œ X2ï¼Œé‚£ä¹ˆæ ¸å‡½æ•°ä¸ºï¼š $$K(X_1,X_2)=\\phi(X_1)^T\\phi(X_2) \\=[x_{11}^2,x_{11}x_{12},x_{12}^2][x_{21}^2,x_{21}x_{22},x_{22}^2]^T \\= x_{11}^2x_{21}^2+x_{11}x_{12}x_{21}x_{22}+x_{12}^2x_{22}^2$$ åä¹‹ï¼Œå·²çŸ¥æ ¸å‡½æ•° K æ±‚ phiï¼ˆxï¼‰ã€‚ $$K(X_1,X_2)=(x_{11}x_{21}+x_{12}x_{22}+1)^2 \\= x_{11}^2x_{21}^2+x_{12}^2x_{22}^2+1+2x_{11}x_{21}x_{12}x_{22}+2x_{11}x_{21}+2x_{12}x_{22} \\= \\phi(X_1)^T\\phi(X_2)$$ æ ¹æ®å®šä¹‰å’Œè§‚å¯Ÿï¼Œ $$\\phi(X)=\\phi([x_1,x_2]^t) \\= [x_1^2,x_2^2,1,\\sqrt{2}x_1x_2,\\sqrt{2}x_1,\\sqrt{2}x_2]^T$$ å› è€Œï¼Œæ ¸å‡½æ•° K å’Œæ˜ å°„ phi ä¸€ä¸€æ˜ å°„ã€‚ä½†æ˜¯ K éœ€è¦æ»¡è¶³ä¸€å®šæ¡ä»¶æ‰å¯å†™ä½œä¸¤ä¸ª phi å†…ç§¯çš„å½¢å¼ã€‚å…·ä½“æ¡ä»¶å¦‚ä¸‹ï¼šï¼ˆMercerâ€™s Theoremï¼‰ $$K(X_1,X_2) èƒ½å†™æˆ \\phi(X_1)^T\\phi(X_2)çš„å……è¦æ¡ä»¶ï¼š$$ $$â‘  K(X_1,X_2)=K(X_2,X_1)ï¼ˆäº¤æ¢æ€§ï¼‰\\â‘¡ \\forall C_i(i= 1\\sim N),\\forall Næœ‰\\sum^{N}{i=1}\\sum^{N}{j=1}C_iC_jK(X_i,X_j) \\ge0 ï¼ˆåŠæ­£å®šæ€§è´¨ï¼‰$$ è™½ç„¶æ— æ³•çŸ¥é“ phi çš„å…·ä½“å½¢å¼ï¼Œä½†æ˜¯å¯ä»¥çŸ¥é“ wx+b çš„å€¼ï¼Œè¿›è€ŒçŸ¥é“æ‰€å±ç±»åˆ«ã€‚ å¯¹å¶é—®é¢˜å…·ä½“ç ”ç©¶å·²çŸ¥ K ä¸çŸ¥ phi æ±‚ SVM çš„ä¼˜åŒ–é—®é¢˜ã€‚ åŸé—®é¢˜ï¼ˆPrime problemï¼‰ $$æœ€å°åŒ–ï¼šf(w) \\é™åˆ¶æ¡ä»¶ï¼šg_i(w) \\le 0,i=1\\sim K \\h_i(w) = 0,i=1\\sim K$$ å¯¹å¶é—®é¢˜ï¼ˆDual problemï¼‰ $$L(w,\\alpha,\\beta)=f(w)+\\sum^{K}{i=1}\\alpha_ig_i(w)+\\sum^{M}{i=1}\\beta_ih_i(w) \\=f(w)+\\alpha^Tg(w)+\\beta^Th(w)$$ å…¶ä¸­ï¼Œ $$\\alpha = [\\alpha_1,\\alpha_2,â€¦,\\alpha_K]^T \\\\beta = [\\beta_1,\\beta_2,â€¦,\\beta_M]^T \\g(w) = [g_1(w),g_2(w),â€¦,g_K(w)]^T \\h(w) = [h_1(w),h_2(w),â€¦,h_M(w)]^T$$ åœ¨å®šä¹‰äº† L å‡½æ•°çš„åŸºç¡€ä¸Šï¼Œå®šä¹‰å¯¹å¶é—®é¢˜å¦‚ä¸‹ï¼šéå†å®šä¹‰åŸŸé‡Œçš„ wï¼Œæ‰¾åˆ°ä½¿å¾— L æœ€å°çš„é‚£ä¸ª wï¼ŒåŒæ—¶æŠŠæœ€å°çš„è¿™ä¸ªå‡½æ•°å€¼èµ‹å€¼ç»™ theta å‡½æ•°ã€‚ ä¸ªäººç†è§£ï¼šå…ˆé€šè¿‡éå† w å¾—åˆ°æœ€å°çš„ Lã€‚å¾—åˆ°æœ€å°çš„ L åå°±æ‰¾åˆ°äº†å¯¹åº”çš„ wï¼Œæ­¤æ—¶ w å·²çŸ¥ï¼Œalpha å’Œ beta æœªçŸ¥ï¼Œå› è€Œå¾—åˆ° alpha å’Œ beta çš„ theta å‡½æ•°ã€‚ä¹‹åå†æœ€å¤§åŒ–è¿™ä¸ªå‡½æ•°ã€‚ ç»¼åˆä¸¤ä¸ªé—®é¢˜çš„å®šä¹‰ï¼Œå¾—åˆ°ä»¥ä¸‹å®šç†ï¼š å®šç†ä¸€ï¼š è¿™ä¸ªå®šç†å‘Šè¯‰æˆ‘ä»¬åŸé—®é¢˜çš„è§£æ€»æ˜¯å¤§äºç­‰äºå¯¹å¶é—®é¢˜çš„è§£ã€‚æˆ‘ä»¬æŠŠ f(w*) - theta(alpha*, beta*) å®šä¹‰ä¸ºå¯¹å¶å·®è·ï¼ˆDUALITY GAPï¼‰ã€‚å¯¹å¶å·®è·æ˜¾ç„¶å¤§äºç­‰äº0ã€‚ å¼ºå¯¹å¶å®šç†ï¼š ç®€å•ç‚¹è¯´ï¼ŒåŸé—®é¢˜çš„ç›®æ ‡å‡½æ•°æ˜¯å‡¸å‡½æ•°ï¼Œé™åˆ¶æ¡ä»¶æ˜¯çº¿æ€§å‡½æ•°ï¼Œé‚£ä¹ˆå¯¹å¶å·®è·ä¸º0ã€‚å…·ä½“è¯æ˜å¯ä»¥è¯¾åé˜…è¯»ã€‚ æ ¹æ®å®šç†ä¸€æ¨å‡ºçš„ä¸ç­‰å¼ï¼š è‹¥ f(w*) = theta(alpha*, beta*) ï¼ˆç®€å•ç‚¹è¯´ï¼Œå°±æ˜¯åŸé—®é¢˜å’Œå¯¹å¶é—®é¢˜çš„è§£ç›¸ç­‰çš„æ—¶å€™ï¼‰ï¼Œåˆ™æ ¹æ®å®šç†ä¸€ï¼Œæ˜¾ç„¶å¯ä»¥æ¨å‡ºï¼Œå¯¹äºæ‰€æœ‰çš„ i=1~Kï¼Œè¦ä¹ˆ alpha_i = 0ï¼Œè¦ä¹ˆ g(w*) = 0ã€‚è¿™ä¸ªæ¡ä»¶å°±æ˜¯ KKT æ¡ä»¶ã€‚ æœ€ç»ˆæ±‚è§£å°†åŸé—®é¢˜è½¬æ¢ä¸ºå¯¹å¶é—®é¢˜ï¼Œä»¥å®Œæˆé—®é¢˜çš„æ±‚è§£ã€‚ æ”¯æŒå‘é‡æœºçš„åŸé—®é¢˜æ»¡è¶³å¼ºå¯¹å¶å®šç†ã€‚å›é¡¾ SVM çš„ä¼˜åŒ–é—®é¢˜ï¼š ç»“åˆåŸé—®é¢˜çš„å®šä¹‰ï¼Œéœ€è¦æŠŠå‰ä¸¤ä¸ªé™åˆ¶æ¡ä»¶æ”¹æˆå°äºç­‰äº 0 çš„å®šä¹‰ã€‚é™åˆ¶æ¡ä»¶å–åï¼Œé‚£ä¹ˆæœ€å°åŒ–ä¸­ä¹Ÿè¦å–åã€‚ ä¸¤ä¸ªé™åˆ¶æ¡ä»¶éƒ½çº¿æ€§çš„ï¼Œç›®æ ‡å‡½æ•°æ˜¯å‡¸çš„ï¼Œæ»¡è¶³å¼ºå¯¹å¶å®šç†ã€‚ SVM ä¸­ä¸å­˜åœ¨ h(x) çš„æƒ…å†µã€‚å› æ­¤ï¼Œå¯ä»¥æŠŠ SVM çš„å¯¹å¶é—®é¢˜å†™ä½œå¦‚ä¸‹å½¢å¼ï¼š tipsï¼šå¯¹å¶é—®é¢˜ä¸­çš„ w æŒ‡çš„æ˜¯æœªçŸ¥å˜é‡ï¼Œæ­¤æ—¶ï¼ŒæœªçŸ¥å˜é‡ w åŒ…æ‹¬ (w, sigma, beta)ã€‚æ±‚å¾®åˆ†ï¼Œå¾—ä¸‹å¼ï¼š æ ¹æ® â‘¡ æ¶ˆå»çº¢æ¡†ï¼Œæ ¹æ® â‘¢ æ¶ˆå»è“æ¡†ï¼š åŸå¼è¿˜å‰©ä¸‰é¡¹ï¼š æ•´ç†ä¹‹åï¼ŒåŒ–ç®€ä¸ºï¼š é—®é¢˜ä¸­ï¼Œå·²çŸ¥çš„æ˜¯æ‰€æœ‰çš„ xï¼Œy ä»¥åŠæ ¸å‡½æ•° Kã€‚è¿™æ˜¯ä¸€ä¸ªå‡¸çš„é—®é¢˜ï¼Œå¯ä»¥ç”¨ SMO ç®—æ³•æ±‚è§£ã€‚ ä½†åŒ–æˆè¿™æ ·åï¼Œè¿˜æ²¡å®Œã€‚è¿™æ ·æ±‚å‡ºäº† alpha è¿˜è¦æ±‚ omega å’Œ biasã€‚ ä½†æ˜¯æ±‚ omega å²‚ä¸æ˜¯åˆå¾—çŸ¥é“æ˜ å°„å‡½æ•°ï¼Ÿå®åˆ™ä¸ç”¨ï¼Œå› ä¸ºå®é™…ä¸Šæˆ‘ä»¬ä¸éœ€è¦çŸ¥é“ omegaã€‚è€ƒè™‘æµ‹è¯•æµç¨‹ï¼š æµ‹è¯•æ ·æœ¬ x è¾“å…¥ï¼Œè‹¥ omega^T phi(x) + b&gt;= 0 åˆ™ y=+1ï¼Œåä¹‹ y=-1ã€‚ å®é™…ä¸Šï¼Œ omega^T phi(x) = sum_i_N alpha_i y_i K(xi, x)ã€‚åˆæŠŠ phi åŒ–ç®€æ‰äº†ï¼Œåªéœ€è¦ç”¨æ ¸å‡½æ•° K å»ç®—å°±è¡Œã€‚ æ¥ä¸‹æ¥åˆ†ææ±‚ biasï¼Œå…ˆæŠŠ SVM é—®é¢˜ä¸­çš„ KKT æ¡ä»¶åˆ—å‡ºï¼š å‡å®š alpha_i éƒ½ç®—å‡ºæ¥äº†ï¼Œé‚£ä¹ˆä¸€å®šèƒ½æ‰¾å‡ºä¸€ä¸ª alpha_i æ˜¯ 0&lt;alpha_i&lt;C çš„ã€ï¼Ÿã€‘ã€‚é¦–å…ˆå–ä¸€ä¸ª alpha_i æ˜¯ 0&lt;alpha_i&lt;C çš„ï¼Œå¯å¾— beta_i = c-alpha_i &gt; 0ï¼Œå¯å¾— epsilon_i = 0ã€‚æœ‰ alpha_i != 0 å¯å¾— â‘¡ ä¸­ååŠå¼ï¼Œæ ¹æ®è¯¥å¼æ±‚è§£ bï¼š åœ¨å®é™…è¿ç®—ä¸­ï¼Œå¯ä»¥å–æ‰€æœ‰æ»¡è¶³æ¡ä»¶ 0&lt;alpha_i&lt;C çš„ alpha_iï¼Œæ±‚å‡ºå¯¹åº” b ï¼Œç„¶ååšå¹³å‡ã€‚ æ€»ç»“å¦‚ä¸‹ï¼š","link":"/2022/07/06/machine-learning/2022-07-06-support-vector-machine/"},{"title":"","text":"ï¿½ï¿½ï¿½Ø±ï¿½Ò¶Ë¹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Naive Bayesian Classifierï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ X ï¿½ï¿½Ã¿ï¿½ï¿½Î¬ï¿½È¶ï¿½ï¿½ï¿½ï¿½ï¿½É¢ï¿½ï¿½ ï¿½ï¿½ X ï¿½ï¿½Ã¿ï¿½ï¿½Î¬ï¿½È¶ï¿½ï¿½Ç¶ï¿½ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ø£ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½Ğ¸ï¿½Ó¦ï¿½Ã½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¼ï¿½ï¿½ï¿½ï¿½à£¬ï¿½ï¿½Ò»ï¿½ï¿½ï¿½Ä¼ï¿½ï¿½ï¿½Ö»ï¿½ï¿½ï¿½ï¿½ï¿½à£¨ï¿½Ç·ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¼ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ë£ºÒ»ï¿½ï¿½ï¿½Ê¼ï¿½ d ï¿½ï¿½ï¿½ï¿½ï¿½d in c_1 ï¿½ï¿½ d in c_2 Ñµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ {(d_i, y_I)}_{i=1-N}ï¿½ï¿½d={w1, w2, â€¦, wn} ï¿½ï¿½Ã¿ï¿½ï¿½ï¿½Ê¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Ñ§Ï°Ä¿ï¿½ê£ºP(d|c_1) ï¿½ï¿½ P(d|c_2) P(d|C) = P({w1, w2, â€¦, wn} | C) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½Ù£ï¿½w ï¿½ï¿½ï¿½ï¿½ï¿½ï±»ï¿½ï¿½ï¿½ï¿½Îªï¿½ï¿½ï¿½Ê£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½È»ï¿½Ü¶à£¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¿ï¿½ï¿½ï¿½ï¿½ï¿½ŞµÄ£ï¿½ï¿½ï¿½Ë¿ï¿½ï¿½Ô±ï¿½ï¿½ï¿½É¢ï¿½ï¿½Ê¾ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½Ú£ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½Ç¶ï¿½ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ï¿½Îªï¿½ï¿½ï¿½ï¿½ï¿½ëµ¥ï¿½ï¿½Ö®ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ïµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½òµ¥µï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï£¬ï¿½ï¿½ï¿½Ô¼ï¿½ï¿½ï¿½ ï¿½Ú³ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»Ğ©ï¿½ï¿½Îªï¿½ï¿½ï¿½ÓµÄ±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¶ï¿½ğ£¬±ã²»ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½ P(d|C) = P({w1, w2, â€¦, wp} | C) = [ï¿½Û³ï¿½ i in n]P(w_i|C) P(w_i|C_j) = count(w_i, c_j) / [ï¿½Û¼ï¿½w in V]count(w, c_j)ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ j=1-2ï¿½ï¿½ P(C_i) = count(C_i) / count(C) ï¿½ï¿½P(d|c_1)P(c_1) &gt; P(d|c_2)P(c_2) ï¿½ï¿½ d in c_1ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½Ü´ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Î´ï¿½ï¿½Ñµï¿½ï¿½ï¿½ï¿½ï¿½Ğ³ï¿½ï¿½Ö¹ï¿½ï¿½ï¿½ï¿½ï¿½Ã´ P(d|c) [ï¿½ï¿½ï¿½ï¿½cÈ¡ï¿½Ä¸ï¿½] ï¿½ï¿½ï¿½ï¿½ 0ï¿½ï¿½Îªï¿½ï¿½Ö¹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä½ï¿½ï¿½ï¿½ï¿½ã¹«Ê½ï¿½ï¿½ï¿½Â£ï¿½ P(w_i|C_j) = count(w_i, c_j) + 1/ [ï¿½Û¼ï¿½w in V]count(w, c_j) + |V|ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ j=1-2ï¿½ï¿½ ï¿½ï¿½Ë¹ï¿½Ü¶Èºï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ {x_i}_{i=1-n} in Cï¿½ï¿½X_i ï¿½ï¿½Ò»Î¬ï¿½ï¿½ï¿½ï¿½ï¿½ $P(X|C) = \\frac{1}{\\sqrt{2\\pi \\sigma}}e ^ {- \\frac{(x-\\mu)^2}{2\\sigma^2}}$ $\\mu = \\frac{1}{N} \\sum^{N}_{i=1}X_i$ $\\sigma^2=\\frac{1}{N-1}\\sum^{N}_{i=1}(X_i-\\mu)^2$ [ï¿½ï¿½Æ«ï¿½ï¿½ï¿½ï¿½] ï¿½ï¿½ï¿½ï¿½ï¿½Ò»Î¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ö¤ï¿½ï¿½ï¿½ï¿½Î¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ $P(X|C)=\\frac{1}{\\sqrt{(2\\pi)^d |\\sum|}}exp[-\\frac{1}{2}(x-\\mu)^T\\sum^{-1}(x-\\mu)]$ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ $\\sum $ ï¿½ï¿½ $\\mu$ï¿½ï¿½ï¿½ï¿½ï¿½Ã¼ï¿½ï¿½ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¿ï¿½êº¯ï¿½ï¿½ï¿½ï¿½ $E(\\mu, \\sum)=\\sum^{N}_{i=1}lnP(x_i|C)$ ï¿½ï¿½ï¿½Ú¼ï¿½ï¿½è£ºï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ {X_i}_{i=1-N} ï¿½ï¿½ï¿½ï¿½Í¬ï¿½Ö²ï¿½ ï¿½ï¿½ ï¿½è¶¨ $\\mu$ ï¿½ï¿½$\\sum$ Ê¹ï¿½ï¿½ï¿½ï¿½ {x_i} ï¿½Ä¸ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ò£¬¾ï¿½ï¿½ï¿½ï¿½Ö¤ï¿½ï¿½ï¿½Îºï¿½È¥ï¿½Ë½â¡£ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÒªÇ¿ï¿½ï¿½ï¿½ï¿½ï¿½ã£¬ï¿½ï¿½ï¿½ï¿½ï¿½Ê·ï¿½ï¿½à·¨Òªï¿½ï¿½ï¿½ï¿½Ä¼ï¿½ï¿½ã£º ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ X ï¿½Ä¸ï¿½ï¿½Ê·Ö²ï¿½ï¿½Ä¾ï¿½ï¿½ï¿½ï¿½ï¿½Ê½ï¿½ï¿½Ò²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ P(X|C)ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê½ï¿½ï¿½ï¿½Ğ£ï¿½ï¿½ï¿½Ò»Ğ©ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ë¹ï¿½ï¿½ï¿½Ê·Ö²ï¿½ï¿½ï¿½Îª $\\mu, \\sum$ï¿½ï¿½ ï¿½ï¿½ ï¿½Ã¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Å»ï¿½Ä¿ï¿½êº¯ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ ï¿½Ğµï¿½ï¿½Å»ï¿½ï¿½ï¿½ï¿½â£¬ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½Ú¸ï¿½Ë¹ï¿½ï¿½ï¿½ï¿½ï¿½Ç¸ï¿½Í¹ï¿½Äºï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½ï¿½È«ï¿½ï¿½ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ú¿ï¿½ï¿½ï¿½Ö±ï¿½ï¿½ï¿½ï¿½Î¢ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÚºÜ¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã²»ï¿½ï¿½ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½Ø£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½İ¶ï¿½ï¿½Â½ï¿½ï¿½ÈµÈ¡ï¿½ ï¿½ï¿½Ë¹ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ ï¿½ï¿½ó£¬¾ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ã²»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½ï¿½ï¿½â¡£Ò²ï¿½ï¿½ï¿½ï¿½Ï¸ï¿½Ë¹Ä£ï¿½Í£ï¿½Gaussian Mixture Modelï¿½ï¿½ï¿½ï¿½","link":"/2023/04/09/machine-learning/lec3_%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1/"},{"title":"[ml][rv] sysu-courses","text":"1. çº¿æ€§å›å½’ + é€»è¾‘å›å½’ TIPSï¼šä»€ä¹ˆæ˜¯çº¿æ€§å›å½’é€»è¾‘å›å½’ï¼ŒæŸå¤±å‡½æ•°æœ‰å¯èƒ½å¸¦æ­£åˆ™é¡¹ï¼Œä¸ºä»€ä¹ˆè¦åŠ æ­£åˆ™é¡¹å› ä¸ºè¦é˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒæŸå¤±å‡½æ•°è¦æ€ä¹ˆå®šä¹‰ï¼Œæ¢¯åº¦ä¸‹é™å¥½å¤„æœ‰ä»€ä¹ˆåå¤„æœ‰ä»€ä¹ˆï¼Œæœ€ä¼˜å‚æ•°è¡¨è¾¾å¼æ€ä¹ˆå†™çš„ æŸå¤±å‡½æ•° æœ€ä¼˜å‚æ•°è¡¨è¾¾å¼ æŸå¤±å‡½æ•°å¸¦æ­£åˆ™é¡¹çš„åŸå› ï¼ˆè¡¥ï¼‰ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆã€‚[é˜²æ­¢è¿‡æ‹Ÿåˆçš„å¦ä¸€ç§æ–¹æ³•ï¼šk-foldäº¤å‰éªŒè¯] å®šä¹‰ï¼ˆè¡¥ï¼‰ï¼š å›å½’æ¨¡å‹ çº¿æ€§æ¨¡å‹ï¼š å¯¹äºä¸Šå¼ï¼Œå‡è®¾b=0ï¼Œåˆ™æ˜“å¾—ï¼š çŸ©é˜µå½¢å¼å¯ä»¥å†™ä½œä¸ºï¼š æ˜¾ç„¶ï¼Œæˆ‘ä»¬çš„ç›®çš„å°±æ˜¯æ±‚ä½ç½®å‚æ•° thetaï¼Œå¦‚ä½•æ±‚è§£ï¼Ÿæ„é€ æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆmaximum likelihood estimatorï¼ŒMLEï¼‰ï¼Œæ‰¾åˆ° theta ä½¿å¾—ä¼¼ç„¶æ¦‚ç‡æœ€å¤§ã€‚ æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„åˆç†æ€§åœ¨äºè¿™æ ·ä¸€ä¸ªå‡è®¾ï¼šæ—¢ç„¶èƒ½å‡ºç°è¿™æ ·ä¸€ä¸ªæ•°æ®åˆ†å¸ƒï¼Œé‚£ä¹ˆå¯ä»¥å‡è®¾åœ¨å½“å‰çš„ theta æƒ…å†µä¸‹ï¼Œå‡ºç°è¯¥æ•°æ®åˆ†å¸ƒçš„æ¦‚ç‡æ˜¯å¾ˆå¤§çš„ã€‚å› æ­¤å¯ä»¥è¿›è¡Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€‚ æœ€å¤§ä¼¼ç„¶çš„æ±‚è§£å¯ä»¥æœ‰ä¸¤ç§ï¼šåˆ†ææ³•ï¼Œå³ä»¤å¾®åˆ†=0ï¼›è¿­ä»£æ³•ï¼Œå³ï¼ˆéšæœºï¼‰æ¢¯åº¦ä¸‹é™ã€‚ åŸºäºç‹¬ç«‹åŒåˆ†å¸ƒçš„å‡è®¾ï¼Œn ä¸ªæ•°æ®ç‚¹çš„æ¦‚ç‡å¯ä»¥è¡¨ç¤ºä¸ºï¼š é—®ï¼šä¸ºä»€ä¹ˆè¿™é‡Œçš„ p(x_i) å¯ä»¥è¡¨ç¤ºæˆ1ï¼Ÿ é—®é¢˜è½¬åŒ–ä¸ºï¼š ä¸ºç®€ä¾¿è®¡ç®—ï¼Œä¸€èˆ¬æ±‚å¯¹æ•° MLEï¼š ç¬¬ä¸€é¡¹å¯¹äº theta è€Œè¨€æ˜¯å¸¸æ•°é¡¹ï¼Œçœå»ï¼Œæ•…æœ€ç»ˆä¼˜åŒ–ç›®æ ‡ä¸ºï¼š ç­‰ä»·äºï¼š å¦‚ä½•é€šè¿‡æ¢¯åº¦ä¸‹é™æ±‚è§£å‚æ•°ï¼š ä¸ºä¿è¯å¯¹æ•°ä¼¼ç„¶æ˜¯å‡¸çš„ï¼Œæ±‚äºŒé˜¶å¯¼ï¼ˆHessianï¼‰çŸ©é˜µï¼š å¦‚æœ X æ˜¯æ»¡ç§©çš„ï¼Œé‚£ä¹ˆ XX å°±æ˜¯æ­£å®šçš„ï¼Œå› æ­¤ theta_{MLE} = minimumã€‚ç”¨æ­£åˆ™åŒ–å¤„ç†é€€åŒ–æƒ…å†µ ä»¤æ¢¯åº¦ä¸º 0ï¼Œè§£å¾—ï¼š æ®æ­¤å¯ä»¥åˆ©ç”¨ä¸€äº›çŸ©é˜µæ–¹å¼æ±‚è§£ï¼Œæ–¹æ³•æœ‰ Cholesky Factorization ç­‰ã€‚ æŠ‘æˆ–æ˜¯æ¢¯åº¦ä¸‹é™æ±‚è§£ theta_{MLE}ï¼ˆrho æ˜¯å­¦ä¹ ç‡ï¼‰ï¼š å…¶ä¸­ï¼Œå¯¹æ•°ä¼¼ç„¶æ±‚å¾®åˆ†å¾—åˆ°çš„ç³»æ•° 2 è¢«å¹¶å…¥ rhoã€‚ æ›´å¥½çš„åŠæ³•â€”â€”éšæœºæ¢¯åº¦ä¸‹é™ï¼š åœ¨éçº¿æ€§çš„æƒ…å†µï¼Œå¯ä»¥é‡‡ç”¨éçº¿æ€§å˜æ¢ï¼Œå¦‚ splines, radial basis functions ç­‰ã€‚ é€»è¾‘å›å½’ è¦çŸ¥é“çš„å°±æ˜¯ wï¼Œå¯¹äº w çš„å–å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä»¤ï¼š $$\\omega = argmax_{\\omega} \\prod_{l} P(y^l|x^l,w)$$ å…¶ä¸­ï¼Œ$$y^l$$ å’Œ $$x^l$$ å–ä¹‹äºè®­ç»ƒé›†ã€‚ä¸Šå¼å†™ä½œ log-likelihoodï¼š æ ¹æ® y åªèƒ½å– 0 æˆ– 1 çš„æ€§è´¨ï¼ŒæŠŠ argmax å³è¾¹çš„ sum å†™ä½œä¸‹å¼ï¼š å†™å‡º loss æ–¹ç¨‹ï¼Œç›´æ¥å¼€å¯¼ï¼ æ¢¯åº¦ä¸‹é™ï¼š åŠ å…¥æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆçš„ç‰ˆæœ¬ï¼š 2. è¿‡æ‹Ÿåˆä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆ Low training error does not imply good expected performance é™ä½è¿‡æ‹Ÿåˆçš„æ–¹æ³• Reduce number of features + Keep all the features, but reduce values of parameters â‘  æŸå¤±å‡½æ•°åŠ å…¥æ­£åˆ™é¡¹ â‘¡ k-foldäº¤å‰éªŒè¯ 3. è®­ç»ƒæ–¹æ³• ä»€ä¹ˆæ˜¯è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆï¼Œè¿‡æ‹Ÿåˆï¼šè®­ç»ƒé›†æŸå¤±å‡½æ•°è¯¯å·®å°ï¼Œæµ‹è¯•é›†å¤§ã€‚æ€ä¹ˆé¿å…è¿‡æ‹Ÿåˆï¼ŸåŠ å…¥æ­£åˆ™é¡¹ï¼Œä½¿ä»–è®­ç»ƒé›†æ²¡é‚£ä¹ˆå¥½ï¼Œå¢åŠ æ¨¡å‹çš„å»¶å±•æ€§ï¼›k-æŠ˜äº¤å‰éªŒè¯çš„kä»€ä¹ˆæ„æ€ï¼Œåˆ†æ•°æ®é›†æ€ä¹ˆåˆ†ï¼Œå¯ä»¥éšæœºä¹Ÿå¯ä»¥ä¸éšæœº ä¸€ä¸ªè¡¡é‡æ¨¡å‹å¥½åçš„æŒ‡æ ‡ï¼š è®­ç»ƒé›†-çŸ«æ­£é›†-æµ‹è¯•é›† ä½¿ç”¨éªŒè¯é›†æ˜¯ä¸ºäº†å¿«é€Ÿè°ƒå‚ï¼Œ(ç½‘ç»œå±‚æ•°ï¼Œç½‘ç»œèŠ‚ç‚¹æ•°ï¼Œè¿­ä»£æ¬¡æ•°ï¼Œå­¦ä¹ ç‡ï¼‰ã€‚å¦å¤–ç”¨éªŒè¯é›†è¿˜å¯ä»¥ç›‘æ§æ¨¡å‹æ˜¯å¦å¼‚å¸¸ï¼ˆè¿‡æ‹Ÿåˆï¼‰ï¼Œç„¶åå†³å®šæ˜¯ä¸æ˜¯è¦æå‰åœæ­¢è®­ç»ƒã€‚ ç•™å‡ºæ³•ï¼ˆHold-out methodï¼‰ æŠŠæ•°æ®é›†åˆ†æ­¤è®­ç»ƒé›†(2/3)å’Œæµ‹è¯•é›†(1/3)ï¼Œç»å¸¸ä½¿ç”¨çš„æƒ…å†µï¼šæœ‰å‡ åƒä¸ªç¤ºä¾‹ï¼Œæ¯ä¸ªç±»æœ‰å‡ ç™¾ä¸ªå®ä¾‹ã€‚ æ›´å¤§çš„æµ‹è¯•é›†å¯ä»¥å¾—åˆ°æ›´ç²¾ç¡®çš„é”™è¯¯ç‡ä¼°è®¡ã€‚ æœ‰æ—¶æœ‰äº›ç±»çš„å®ä¾‹å¾ˆå°‘ï¼Œæ­¤æ—¶å°±è¦ç”¨ Stratified (åˆ†å±‚) sampleï¼Œç¡®ä¿æ¯ä¸ªç±»åœ¨è®­ç»ƒæµ‹è¯•é›†ä¸­çš„æ¯”ä¾‹å¤§è‡´ç›¸ç­‰ï¼Œè¿™å¯ä»¥å‡å°‘æ¨¡å‹æ–¹å·®ã€‚ Repeated hold-out method åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œéšæœºé€‰æ‹©ä¸€å®šæ¯”ä¾‹æ•°æ®è¿›è¡Œè®­ç»ƒï¼ˆå¯èƒ½åˆ†å±‚ï¼‰ã€‚å¯¹ä¸åŒè¿­ä»£çš„é”™è¯¯ç‡è¿›è¡Œå¹³å‡ï¼Œä»¥å¾—å‡ºæ€»ä½“é”™è¯¯ç‡ã€‚ ä»ä¸æ˜¯æœ€ä½³ï¼šä¸åŒçš„æµ‹è¯•é›†é‡å ï¼Œä½†æˆ‘ä»¬å¸Œæœ›æ¯ä¸ªæ•°æ®éƒ½è¢«è‡³å°‘æµ‹è¯•ä¸€æ¬¡ã€‚ k-fold cross validation â‘  æ•°æ®åˆ†æˆ k ç­‰åˆ†ä¸ªå­é›†ã€‚â‘¡ æ¯æ¬¡é€‰ k ä»½ä¸­æœªé€‰æ‹©è¿‡çš„ä¸€ä»½å½“æµ‹è¯•é›†ï¼Œå…¶ä»–è®­ç»ƒé›†ã€‚ æ¯ä¸ªå­é›†åœ¨äº¤å‰éªŒè¯å°±åˆ†å±‚è¿‡äº†ã€‚æ€» estimate å°±æ˜¯å„æ¬¡ estimate çš„å¹³å‡ã€‚ k-fold cross validation with validation and test sets è¿™æ˜¯ä¸ªç¨å¾®ä¸é‚£ä¹ˆç²¾ç»†çš„æ–¹æ³• â‘  æ•°æ®åˆ†æˆ k ç­‰åˆ†ä¸ªå­é›†ã€‚â‘¡ æ¯æ¬¡é€‰ k ä»½ä¸­æœªé€‰æ‹©è¿‡çš„ä¸€ä»½å½“æµ‹è¯•é›†ï¼Œå‰©ä½™çš„é€‰ä¸ªå½“éªŒè¯é›†ï¼Œå…¶ä»–å°±æ˜¯è®­ç»ƒé›†ã€‚ æœ€ä¼˜çš„ kï¼š10ï¼Œå®éªŒè¯æ˜å¯ä»¥å¾—åˆ°æœ€ç²¾ç¡®çš„ estimateã€‚ Bootstrap method æˆ‘ä»¬éšæœºåœ°ä»æ•°æ®é›†ä¸­æŠ½å–å‡º n ä¸ªæ•°æ®ç»„æˆä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼ˆå…è®¸é‡å¤ï¼‰ã€‚ ç”±äºåªåœ¨ 63% çš„æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå› æ­¤æµ‹è¯•é›†ä¸Šçš„ error estimate ä¸å¤ªå¥½ï¼Œæ•…è”åˆè®­ç»ƒé›†ä¸Šçš„ errorï¼š é‡å¤ä»¥ä¸Šè¿‡ç¨‹å¤šæ¬¡ï¼Œå¹³å‡ç»“æœã€‚ æ€»ç»“ï¼š hold-out methodï¼šlarge data cross-validation methodï¼š middle-sized data leave-one-out and bootstrap methodï¼šsmall data 4. å†³ç­–æ ‘ å†³ç­–æ ‘åšåˆ†ç±»çš„ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œç†µçš„å®šä¹‰ ç†µçš„æ±‚è§£ $$log(p_i)$$ å®šä¹‰ä¸ºä¿¡æ¯é‡ã€‚ æ¡ä»¶ç†µçš„æ±‚è§£ æ±‚è§£å¯¹åº”å±æ€§çš„ä¿¡æ¯å¢ç›Š å†³ç­–æ ‘çš„æ„å»º é¢„å‰ªæï¼Œåå‰ªæ 5. SVM æ ‡å‡†çš„SVMæ˜¯ä¸ªçº¿æ€§çš„åˆ†ç±»å™¨ï¼ŒåŸºæœ¬æ€æƒ³ï¼šæ‰¾å‡ºä¸€ä¸ªåˆ†ç•Œé¢ï¼Œè®©åˆ†ç•Œé¢ç¦»æ­£è´Ÿæ ·æœ¬çš„è·ç¦»æœ€å¤§ï¼Œä¸éœ€è¦èƒŒç­”å¯¹äº†å¤§æ¦‚æ„æ€å°±è¡Œï¼ŒæŸå¤±å‡½æ•°æ€ä¹ˆå®šä¹‰ï¼Œä¸éœ€è¦ä¼šæ±‚è§£ï¼Œä¸ºä»€ä¹ˆå¼•å…¥æ ¸å‡½æ•°ï¼Œæœ‰ä»€ä¹ˆåŠŸèƒ½ SVM çš„åŸºæœ¬æ€æƒ³ æ‰¾å‡ºä¸€ä¸ªåˆ†ç•Œé¢ï¼Œè®©åˆ†ç•Œé¢ï¼ˆmarginï¼‰ç¦»æ­£è´Ÿæ ·æœ¬ï¼ˆsupport vectorï¼‰çš„è·ç¦»æœ€å¤§ ç‚¹åˆ°ç›´çº¿çš„è·ç¦»ï¼š SVM çš„æŸå¤±å‡½æ•° Hinge æŸå¤±å‡½æ•° $$L(y, f(x)) = [1-yf(x)]+ \\z+=\\begin{cases}z,z \\ge 0 \\0,z \\le 0\\end{cases}$$ SVM çš„ä¼˜åŒ–ç›®æ ‡ $$æœ€å°åŒ–ï¼š\\frac{1}{2}||w||^2 + C\\sum^{N}_{i=1}\\delta_i\\ \\é™åˆ¶æ¡ä»¶ï¼š (1)\\ \\delta_i&gt;=0,(i=1-N)\\(2)\\ y_i(w^TX_i+b) &gt;= 1-\\delta_i,(i=1-N)$$ SVM çš„æŸå¤±å‡½æ•° $$\\frac{1}{2}||w||^2+C\\sum^{N}_{i=1}max(0, 1-y_i(wx_i+b))$$ æå‡ºå…¬å› å­ Cï¼Œç­‰ä»·äº $$\\frac{1}{2C}||w||^2+\\sum^{N}_{i=1}max(0, 1-y_i(wx_i+b))$$ å‚è€ƒï¼šhttps://blog.csdn.net/guofei_fly/article/details/102750900 SVM ä¸­çš„æ ¸å‡½æ•° é«˜ç»´éçº¿æ€§è®¡ç®—èµ„æºæ¶ˆè€—å¤§ï¼Œæ•…æ˜ å°„åˆ°çº¿æ€§ä½ç»´ã€‚ æ ¹æ®å¯¹ SVM ä¼˜åŒ–é—®é¢˜çš„è§‚å¯Ÿï¼Œå¯ä»¥å¾—çŸ¥æ•°æ®ç‚¹åªä»¥ç‚¹ç§¯çš„å½¢å¼å‡ºç°ï¼š å› æ­¤ï¼Œæ— éœ€è€ƒè™‘å…·ä½“çš„æ˜ å°„ phi å‡½æ•°çš„å½¢å¼ï¼Œåªéœ€è¦è€ƒè™‘æ ¸å‡½æ•°ï¼š ä¸¾ä¾‹è€Œè¨€ï¼š è¦æ±‚æ ¸å‡½æ•°æ»¡è¶³ Mercer functionï¼Œå³è¦æ±‚æ­£å®šï¼ˆå¯¹äºnxnçš„çŸ©é˜µï¼Œentry[i,j]=K(xi,xj)ï¼‰ã€‚ åŸºæœ¬çš„æ ¸å‡½æ•°ï¼š 6. PCA PCAåŸºæœ¬æ€æƒ³ï¼šé™ç»´ï¼ŒæŠŠæœ€å…³é”®çš„ç»´åº¦æ‰¾å‡ºæ¥ã€‚PCAæ— ç›‘ç£çš„ã€‚ PCAä¸‰ç§ç†è§£çš„è§’åº¦ï¼šé€šè¿‡é‡æ„è¯¯å·®æœ€å°æ¨å‡ºPCAçš„å®šä¹‰å…¬å¼ï¼›é€šè¿‡æ–¹å·®æœ€å¤§çš„æ€æƒ³æ¨å‡ºPCAï¼›é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£çš„æ–¹æ³•æ¨å‡ºPCAã€‚ PCAæœ‰è¿›è¡Œä¸€äº›å‡è®¾çº¦æŸï¼Œå¦‚ä¸¤ä¸¤æ–¹å‘ä¹‹é—´æ­£äº¤ã€‚æ¨å¯¼è¿‡ç¨‹è¦çŸ¥é“ï¼Œæ¯”å¦‚PCAé‡æ„è¯¯å·®çš„æ¨å¯¼ã€‚PCAæœ‰ä»€ä¹ˆç¼ºç‚¹ï¼šè¦æ±‚æ–¹å‘æ­£äº¤ï¼Œè€Œè¿™ä¸ä¸€å®šæ˜¯åˆç†çš„ã€‚ PCA çš„åŸºæœ¬æ€æƒ³ é™ç»´ï¼ŒæŠŠæœ€å…³é”®çš„ç»´åº¦æ‰¾å‡ºæ¥ï¼Œä»¥ä»£è¡¨å¤§éƒ¨åˆ†çš„ä¿¡æ¯ã€‚ PCA çš„ä¸‰ç§ç†è§£è§’åº¦ï¼šæœ€å°é‡æ„è¯¯å·® æ­£äº¤çš„æ¦‚å¿µï¼š æ­£äº¤å®šç†ï¼ˆä¸¾ä¸ªä¾‹å­å°±èƒ½ç†è§£ï¼Œ$$\\alpha_{i}$$ ç±»ä¼¼æŠ•å½±é•¿åº¦ï¼‰ï¼š å½“å‰çš„ç›®æ ‡ï¼Œå°±æ˜¯æ‰¾åˆ°è¿™å‡ ä¸ªæ­£äº¤å‘é‡ï¼Œä»¥æœ€å¥½ åœ°è¡¨ç¤ºåŸæ•°æ®ã€‚ PCA(ä¸»æˆåˆ†åˆ†æ)æ‰€å¯¹åº”çš„æ•°å­¦ç†è®ºæ˜¯ SVDã€‚è€Œå¥‡å¼‚å€¼åˆ†è§£æœ¬èº«æ˜¯å®Œå…¨ä¸éœ€è¦å¯¹çŸ©é˜µä¸­çš„å…ƒç´ åšæ ‡å‡†åŒ–æˆ–è€…å»ä¸­å¿ƒåŒ–çš„ã€‚ä½†æ˜¯å¯¹äºæœºå™¨å­¦ä¹ ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¯¹çŸ©é˜µï¼ˆä¹Ÿå°±æ˜¯æ•°æ®ï¼‰çš„æ¯ä¸€åˆ—å…ˆè¿›è¡Œæ ‡å‡†åŒ–ã€‚ Frobenius norm $$||X||{F} = \\sqrt{\\sum{i} \\sum_j X_{i,j}^2}$$ PCA çš„ä¸‰ç§ç†è§£è§’åº¦ï¼šæœ€å¤§åŒ–æ–¹å·® æœ€å¤§åŒ–æ–¹å·®ç­‰ä»·äºå°½å¯èƒ½å¤šåœ°ä¿ç•™åŸå§‹æ•°æ®çš„ä¿¡æ¯ã€‚ ä»¥å…¶ä¸­ä¸€ä¸ªæŠ•å½±åæ ‡æ–¹å‘ $$u_1$$ ä¸ºä¾‹ï¼Œæ±‚å…¶æ–¹å·®è¡¨è¾¾å¼ï¼š ç±»ä¼¼å‰æ–‡æ‰€è¿°ï¼Œè¦ä½¿çš„ var æœ€å¤§ï¼Œç­‰ä»·äºè®© $$u_1$$ æ˜¯ S çš„é‚£ä¸ªæœ€å¤§ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ã€‚ PCA çš„ä¸‰ç§ç†è§£è§’åº¦ï¼šSVD åˆ†è§£ 7. èšç±» kæ˜¯ä»€ä¹ˆï¼Ÿkä¸ªèšç±»ã€‚åˆå§‹é€‰å–çš„kä¸ªç‚¹å¯ä»¥æ˜¯éšæœºçš„ä¹Ÿå¯ä»¥æ˜¯è‡ªå·±å®šä¹‰çš„ã€‚kmeansä¸ºä»€ä¹ˆå¯ä»¥æ”¶æ•›ï¼Ÿå¯ä»¥é€šè¿‡å®éªŒçš„æ–¹æ³•æ¥äº†è§£kçš„é€‰å–ã€‚ä¸åŒçš„åˆå§‹çŠ¶æ€ä¼šå¯¼è‡´ä¸åŒçš„ç»“æœã€‚ K-Means èšç±»çš„æ€æƒ³ åœ¨æ•°æ®é›†ä¸­æ ¹æ®ä¸€å®šç­–ç•¥é€‰æ‹©Kä¸ªç‚¹ä½œä¸ºæ¯ä¸ªç°‡çš„åˆå§‹ä¸­å¿ƒï¼Œç„¶åå°†æ•°æ®åˆ’åˆ†åˆ°è·ç¦»è¿™Kä¸ªç‚¹æœ€è¿‘çš„ç°‡ä¸­ï¼Œä½†å½¢æˆçš„æ–°ç°‡å¹¶ä¸ä¸€å®šæ˜¯æœ€å¥½çš„åˆ’åˆ†ï¼Œå› æ­¤ç”Ÿæˆçš„æ–°ç°‡ä¸­ï¼Œé‡æ–°è®¡ç®—æ¯ä¸ªç°‡çš„ä¸­å¿ƒç‚¹ï¼Œç„¶ååœ¨é‡æ–°è¿›è¡Œåˆ’åˆ†ï¼Œç›´åˆ°æ¯æ¬¡åˆ’åˆ†çš„ç»“æœä¿æŒä¸å˜ã€‚ K-Means èšç±»çš„æ­¥éª¤ â‘  Ask user how many clusters theyâ€™d like. â‘¡ Randomly guess k cluster Center locations â‘¢ Each datapoint finds out which Center itâ€™s closest to. â‘£ Each Center finds the centroid of the points it owns â‘¤ Jumps to â‘¢ï¼ŒRepeat until terminated! K-Means èšç±»çš„ç›®æ ‡å‡½æ•° $$Encode(x_i)$$ å¯ä»¥ç†è§£ä¸ºæŠŠæ•°æ®ç‚¹ $$x_i$$ å½’åˆ°ç¬¬å‡ ä¸ªèšç±»ï¼Œ$$Decode[j]$$ å¯ä»¥ç†è§£ä¸ºæŠŠç¬¬ j ä¸ªèšç±»çš„ä¸­å¿ƒ $$c_j$$ã€‚ è¦æœ€å°åŒ– Distortionã€‚â‘  è¿™å°±è¦æ±‚ $$x_i$$ å¿…é¡»è¢«å½’åˆ°ç¦»ä»–æœ€è¿‘çš„èšç±»ã€‚â‘¡ åŒæ—¶ï¼Œè¿˜è¦æ±‚å¯¹ $$c_j$$ å¯¹ Distortion çš„åå¾®åˆ†éƒ½ä¸º 0ï¼š æ»¡è¶³ minimum çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯æ»¡è¶³ $$c_j$$ æ˜¯è¯¥èšç±»ä¸­çš„ç‚¹çš„å‡å€¼çš„æƒ…å†µã€‚ â‘  å’Œ â‘¡ è¿ç»­æ“ä½œæ²¡æ„ä¹‰ï¼Œä½†æ˜¯äº¤æ›¿æ“ä½œå°±å¾ˆæœ‰æ„ä¹‰ï¼Œè¿™å³æ˜¯ K-meansã€‚ä¸ºä»€ä¹ˆå¯ä»¥æ”¶æ•›å‘¢ï¼Ÿ æœ‰é™ä¸ªç‚¹åˆ†åˆ°æœ‰é™ä¸ªèšç±»é‡Œï¼Œè¿™æ ·é…ç½®/èšç±»çš„å¯èƒ½æƒ…å†µæ˜¯æœ‰é™çš„ã€‚åŒæ—¶ï¼Œå½“é…ç½®æ”¹å˜ï¼Œæ„å‘³ç€å¾—åˆ°äº†æ›´å¥½çš„ Distortionã€‚æ¯æ¬¡æ”¹å˜éƒ½æ˜¯æ›´å¥½çš„é…ç½®ï¼Œå¦‚æœä¸€ç›´æ”¹å˜ï¼Œè¿Ÿæ—©ä¼šç”¨å…‰æ‰€æœ‰çš„é…ç½®ã€‚ ä¸ä¸€å®šèƒ½å…¨å±€æœ€ä¼˜ã€‚å› æ­¤ï¼Œè°¨è®°ï¼šé€‰å¥½åˆå§‹å€¼ï¼Œæˆ–è€…è·‘å¤šæ¬¡ä¸ä¸€æ ·çš„k-meansã€‚ å¯¹é€‰å¥½åˆå§‹å€¼çš„ä¸€ç§å¯è¡Œæ–¹æ¡ˆï¼šé¦–å…ˆéšä¾¿é€‰ä¸ªæ•°æ®ç‚¹åšèšç±»ä¸­å¿ƒï¼Œä¹‹åé€‰çš„èšç±»ä¸­å¿ƒå°½å¯èƒ½é€‰ç¦»æ‰€æœ‰å·²é€‰èšç±»ä¸­å¿ƒè¿œçš„æ•°æ®ç‚¹ã€‚ K-Means èšç±»çš„ K çš„é€‰å– å¸¸è§„æ–¹æ³•ï¼šæœ€å°åŒ– Schwarz Criterion (also related to the BIC, schwarzâ€™s bayesian criterion (bic)) 8. EM ç®—æ³•èƒŒæ™¯â€”â€”æ¬²è§£å†³çš„é—®é¢˜ E æ­¥ + M æ­¥ ç†è®ºæ¨å¯¼ï¼š å…ˆé‡æ–°è¡¨è¾¾æ‰€è¦ä¼˜åŒ–çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š å¼ºçƒˆå»ºè®®ç»“åˆæµ™å¤§çš„è¯¾ç¨‹ä¸€èµ·å¤ä¹ ï¼ EM ç®—æ³•ä¸€èˆ¬å½¢å¼ â‘  éšæœºé€‰å– $$\\theta_0$$ â‘¡ E-step $$Q_i(z_i) = P(z_i|x_i, \\theta_k) = \\frac{P(z_i,x_i|\\theta_k)}{P(x_i|\\theta_k)}=\\frac{P(z_i,x_i|\\theta_k)}{\\sum_{z_i} P(z_i, x_i|\\theta_k)}$$ â‘¢ M-step $$\\theta_{k+1}=argmax_{\\theta} \\sum_{i=1}^{N} \\sum_{z_i}Q_i(z_i) log\\frac{P(z_i,x_i|\\theta_k)}{Q_i(z_i)}$$ â‘£ å›åˆ° â‘¡ï¼Œç›´è‡³æ”¶æ•›ã€‚ é«˜æ–¯æ··åˆèšç±»ç®—æ³•çš„æ€æƒ³å’Œæ­¥éª¤ ä¸€ç§ soft(fuzzy) çš„èšç±» å®ç°æ€æƒ³ï¼šæ ¹æ® EM ç®—æ³•ï¼Œé’ˆå¯¹æ¯ä¸ªæ•°æ®ç‚¹ï¼Œä¸ºä¹‹åˆ†é…å±äºæ¯ä¸ªèšç±»çš„æ¦‚ç‡ é«˜æ–¯åˆ†å¸ƒ é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ä¸æ–¹å·®ï¼š å¼€å§‹æå¤§ä¼¼ç„¶ä¼°è®¡ï¼š è½¬ä¸ºå¯¹æ•°ä¼¼ç„¶ä¼°è®¡ï¼š E æ­¥ â€”â€” æ±‚å‡ºæ•°æ®ç‚¹å±äºæ¯ä¸ªèšç±»çš„æ¯”é‡ï¼š M æ­¥ â€”â€” æ›´æ–°é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼š https://zhuanlan.zhihu.com/p/85338773 9. æ¨èç³»ç»Ÿ æ‰“åˆ†çŸ©é˜µLåˆ†è§£æˆç”¨æˆ·çŸ©é˜µUå’ŒitemçŸ©é˜µIï¼Œç„¶åå¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™æ±‚ï¼Œç›®æ ‡å‡½æ•°æ€ä¹ˆå®šä¹‰ï¼ŸU*Içš„ç»“æœå°½å¯èƒ½æ¥è¿‘Lã€‚åŸºäºç”¨æˆ·ï¼šå¾—åˆ°æ‰“åˆ†çŸ©é˜µï¼Œè®¡ç®—ç›¸ä¼¼åº¦é‡å…¬å¼ï¼Œè®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼åº¦ï¼Œæ‰¾å‡ºkä¸ªæœ€åƒçš„ç”¨æˆ·ï¼Œè®¡ç®—æ‰“åˆ†ã€‚åŸºäºå•†å“ï¼šæœ‰æ—¶å€™ç”¨æˆ·å¾ˆå¤šï¼Œä½†å•†å“æ•°é‡æœ‰é™ã€‚å¾—åˆ°æ‰“åˆ†çŸ©é˜µï¼Œç¡®å®šä¸€ä¸ªå•†å“ä¹‹é—´ç›¸ä¼¼åº¦çš„åº¦é‡å…¬å¼ã€‚åŸºäºå†…å®¹ï¼šè€ƒå¯Ÿå•†å“ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä¸ä»…è€ƒè™‘æ‰“åˆ†ï¼Œè¿˜è€ƒè™‘å•†å“çš„æè¿°å†…å®¹ã€‚å†·å¯åŠ¨ï¼šæ¦‚å¿µï¼Œæ–°ç”¨æˆ·è¿›æ¥å¾ˆéš¾å¯¹å…¶è¿›è¡Œæ¨èï¼Œæ–°å•†å“è¿›æ¥ä¸çŸ¥é“è·Ÿå“ªäº›å•†å“ç›¸ä¼¼ï¼Œéš¾ä»¥æ¨èæ–°å•†å“ã€‚æ•°æ®ç¨€ç–çš„é—®é¢˜ï¼šæ‰“åˆ†çŸ©é˜µçš„æ•°æ®æ˜¯å¾ˆç¨€ç–çš„ã€‚ https://zhuanlan.zhihu.com/p/28577447 SVD åˆ†è§£ åŸºäºçŸ©é˜µåˆ†è§£çš„æ¨èç³»ç»Ÿ æ‰“åˆ†çŸ©é˜µ L åˆ†è§£æˆç”¨æˆ·çŸ©é˜µ U å’Œå•†å“çŸ©é˜µ Iï¼Œç„¶åå¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™æ±‚ï¼Œç›®æ ‡å‡½æ•°æ€ä¹ˆå®šä¹‰ï¼ŸU * I çš„ç»“æœå°½å¯èƒ½æ¥è¿‘ Lã€‚ åŸºäºç”¨æˆ·çš„ååŒæ¨è æ ¹æ®æ‰“åˆ†çŸ©é˜µï¼Œè®¡ç®—ç›¸ä¼¼åº¦é‡å…¬å¼ è§‚å¯Ÿ sim(a, b)ï¼Œå…¶å®å°±æ˜¯ç›¸å…³ç³»æ•°ï¼ˆPearson correlationï¼‰çš„è®¡ç®—ã€‚ é—®é¢˜ï¼šå¯èƒ½ä¼šå¯¼è‡´åªç»™å‡ºä¸€äº›ç‰¹å®šçš„ itemsã€‚ è§£å†³ï¼šå¯¹å·®å¼‚è¾ƒå¤§çš„é¡¹ç›®ç»™äºˆæ›´å¤šæƒé‡ï¼›significance weightingï¼›Case amplificationã€‚ æ€»ç»“ï¼šmemory-basedï¼Œä¸é€‚ç”¨ç°å®åœºæ™¯ï¼Œç°å®ä¸­è¿™ä¸ªçŸ©é˜µå¤ªå¤§ã€‚ åŸºäºå•†å“çš„ååŒæ¨è åŸºäºå†…å®¹çš„ååŒæ¨è åŸºæœ¬æ€æƒ³ï¼šæ ¹æ®æ¨èç‰©å“æˆ–å†…å®¹çš„å…ƒæ•°æ®ï¼Œå‘ç°ç‰©å“æˆ–è€…å†…å®¹çš„ç›¸å…³æ€§ï¼Œç„¶ååŸºäºç”¨æˆ·ä»¥å¾€çš„å–œå¥½è®°å½•ï¼Œæ¨èç»™ç”¨æˆ·ç›¸ä¼¼çš„ç‰©å“ã€‚å³è€ƒå¯Ÿå•†å“ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä¸ä»…è€ƒè™‘æ‰“åˆ†ï¼Œè¿˜è€ƒè™‘å•†å“çš„æè¿°å†…å®¹ã€‚ åº”ç”¨ï¼šç”µå½± A å’Œ C çš„ç±»å‹éƒ½æ˜¯çˆ±æƒ…å’Œæµªæ¼«ï¼Œé‚£ä¹ˆå°±ä¼šç»™çœ‹è¿‡ç”µå½± A çš„äººæ¨èç”µå½± Cã€‚ å†·å¯åŠ¨é—®é¢˜ æ•°æ®ç¨€ç–çš„é—®é¢˜","link":"/2022/07/06/machine-learning/2022-07-06-review-machine-learning-courses/"},{"title":"","text":"ï¿½ï¿½ï¿½Ê·ï¿½ï¿½à·¨ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â£ºï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½à£¬omega_1 ï¿½ï¿½ omega_2ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½Ä³ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Xï¿½ï¿½ÒªÃ´ï¿½ï¿½ X in omega_1ï¿½ï¿½ÒªÃ´ï¿½ï¿½ X in omega_2ï¿½ï¿½ ï¿½ï¿½ P(omega_1 |X) ï¿½ï¿½ P(omega_2 |X)ï¿½ï¿½P(omega_1 |X) + P(omega_2 |X) = 1ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â£ºP(omega_1 |X) &gt; P(omega_2 |X) ï¿½ï¿½ï¿½ï¿½ X in omega_1ï¿½ï¿½ ï¿½ï¿½ï¿½İ±ï¿½Ò¶Ë¹ï¿½ï¿½Ê½ï¿½ï¿½ P(omega_1 |X) = Pï¿½ï¿½X, omega_1) / P(X) = Pï¿½ï¿½X|omega_1) P(omega_1)/ P(X) P(omega_2 |X) = Pï¿½ï¿½X, omega_2) / P(X) = Pï¿½ï¿½X|omega_2) P(omega_2)/ P(X) Òªï¿½È½ï¿½P(omega_1 |X) &gt; P(omega_2 |X)ï¿½ï¿½Ö»ï¿½ï¿½Òªï¿½È½ï¿½ï¿½ï¿½Ê½ï¿½Ä·ï¿½ï¿½Ó¡ï¿½ ï¿½ï¿½ï¿½Ğ£ï¿½P(omega_1) ï¿½ï¿½ P(omega_2) ï¿½ï¿½ï¿½ï¿½ omega ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¡ï¿½Pï¿½ï¿½X|omega_1) ï¿½ï¿½ Pï¿½ï¿½X|omega_2) ï¿½ï¿½ï¿½ï¿½ X ï¿½ï¿½ omega ï¿½Ïµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê£ï¿½P(omega_1 |X) ï¿½ï¿½ P(omega_2 |X) ï¿½ï¿½ï¿½ï¿½ X ï¿½ï¿½ W ï¿½ÏµÄºï¿½ï¿½ï¿½ï¿½ï¿½Ê¡ï¿½ ï¿½Ë¹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ P(omega_1 |X) ï¿½ï¿½ P(omega_2 |X)ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ë£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ô±ï¿½ï¿½ï¿½Òªï¿½Ç³ï¿½ï¿½ï¿½×¢ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¡ï¿½ï¿½ï¿½ï¿½ï¿½Ñµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä£ï¿½Í£ï¿½Ñµï¿½ï¿½ï¿½ï¿½Ê±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¿ªï¿½ï¿½ï¿½ï¿½ï¿½Ç²ï¿½ï¿½Ôµï¿½Ê±ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½Í»ï¿½ï¿½ï¿½ÖºÜ´ï¿½ï¿½ï¿½ï¿½ï¿½â¡£Ò²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Òªï¿½Ú²ï¿½ï¿½Ôºï¿½Ñµï¿½ï¿½ï¿½ï¿½Ê±ï¿½ï¿½Ö¤ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ç²î²»ï¿½ï¿½Ä¡ï¿½Êµï¿½ï¿½Ê±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÒµÄ²ï¿½ï¿½è£¬ï¿½ï¿½Ô­ï¿½ï¿½Ò²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¡£ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Øµã¡£ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ó£ï¿½ï¿½ï¿½ï¿½ï¿½Öªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½Ú´ï¿½ï¿½ï¿½ï¿½ï¿½Â£ï¿½ï¿½ï¿½ï¿½ï¿½×¼ï¿½ï¿½ ï¿½ï¿½ Pï¿½ï¿½X|omega_1) &lt; Pï¿½ï¿½X|omega_2) ï¿½ï¿½ X in omega_2ï¿½ï¿½ï¿½ï¿½Ö® X in omega_1 ï¿½ï¿½Î¹ï¿½ï¿½ï¿½ Pï¿½ï¿½X|omega) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ëµï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ X_i in omegaï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Pï¿½ï¿½X|omega) ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü¶È¹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â¡£","link":"/2023/04/09/machine-learning/lec2_%E6%A6%82%E7%8E%87%E5%88%86%E7%B1%BB%E6%B3%95/"},{"title":"","text":"EMï¿½ï¿½Expectation-Maximizationï¿½ï¿½ï¿½ã·¨1. ï¿½ï¿½ï¿½ï¿½ï¿½Ö²ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½ã·¨ï¿½ï¿½Ö»ï¿½ï¿½Ä³Ò»ï¿½ï¿½Ö²ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½ï¿½É½â¡£ ï¿½Åµã£ºï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½Òªï¿½ï¿½ï¿½ÎºÎ²ï¿½ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½Ì¼ï¿½ ï¿½ï¿½ï¿½â£ºï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öªï¿½ï¿½Ã¿Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½ï¿½Ë¹ï¿½Ö²ï¿½ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½ï¿½Ü¹ï¿½ï¿½ï¿½ï¿½×µØ¹ï¿½ï¿½ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½Ë¹ï¿½Ö²ï¿½ï¿½Ä¾ï¿½Öµï¿½Í·ï¿½ï¿½î¡£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ç²ï¿½Öªï¿½ï¿½Ã¿Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½ï¿½Ë¹ï¿½Ö²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Æ£ï¿½EMï¿½ã·¨ï¿½ï¿½ 2. GMM ï¿½Ğµï¿½ EMï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½è£ºÒªÃ´ a. ï¿½ï¿½ï¿½ï¿½ï¿½Ã¿Ò»ï¿½ï¿½ï¿½ï¿½Ä·Ö²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÒªÃ´ b. ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ë¹ï¿½Ö²ï¿½ï¿½Ä²ï¿½ï¿½ï¿½ ï¿½ï¿½ b. Îªï¿½ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¹ï¿½ï¿½ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ë¹ï¿½Ö²ï¿½ï¿½Ä²ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ E-stepï¿½ï¿½ ï¿½ï¿½ M-stepï¿½ï¿½ ï¿½ï¿½ ï¿½Øµï¿½ ï¿½Ú£ï¿½ï¿½ï¿½ï¿½ï¿½Ñ­ï¿½ï¿½ï¿½ï¿½Ö±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ 3. K-Means ï¿½Ğµï¿½ EMï¿½Ù¿ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ EM ï¿½ã·¨ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ K-meansï¿½ï¿½ ï¿½Ş¼à¶½Ñ§Ï°ï¿½ï¿½Ò»ï¿½Ö¡ï¿½ ï¿½ï¿½ï¿½â£ºï¿½ï¿½ï¿½ï¿½ N ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ {X_i}_{i=1-N}ï¿½ï¿½ï¿½ï¿½ï¿½ N ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ {Z_i}_{i=1-N}ï¿½ï¿½ Ö¤ï¿½ï¿½ k-means ï¿½ã·¨ï¿½ï¿½ ï¿½ï¿½ï¿½È¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½Ä¿ï¿½êº¯ï¿½ï¿½ï¿½ï¿½ È»ï¿½ó¿´µï¿½ ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¹ï¿½ï¿½ E ï¿½ï¿½Ğ¡ï¿½ï¿½ ï¿½Ù¿ï¿½ï¿½Çµï¿½ ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½Ú´ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½Ë£ï¿½ï¿½ï¿½ ï¿½ï¿½ ï¿½ï¿½ï¿½Ä¾ï¿½Öµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò²ï¿½ï¿½ï¿½ï¿½ E ï¿½ï¿½Ğ¡ï¿½ï¿½ï¿½ï¿½ï¿½Ï£ï¿½ï¿½ï¿½ E ï¿½Â½ï¿½ 0ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ Ê¹ï¿½ï¿½ E ï¿½ï¿½ï¿½ï¿½ï¿½Â½ï¿½ï¿½ï¿½ï¿½ï¿½ E Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ 4. EM ï¿½ã·¨Ò»ï¿½ï¿½ï¿½ï¿½Ê½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ó£ï¿½ï¿½Ã³ï¿½ EM ï¿½ã·¨ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½Ê½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öªï¿½ï¿½ï¿½ï¿½ï¿½Ï·Ö²ï¿½ï¿½ï¿½$$p(x,z;\\theta)$$ï¿½ï¿½ï¿½Ğ£ï¿½x ï¿½Ç¹Û²ìµ½ï¿½Ä±ï¿½ï¿½ï¿½ï¿½ï¿½z ï¿½ï¿½Ç±ï¿½Ú±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Òªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÂµÄ¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½Æ£ï¿½$$\\theta = argmax_{\\theta}logp(x;\\theta)\\p(x;\\theta) = \\sum_{z}p(x,z;\\theta)$$ï¿½ï¿½Ë¹ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ï¿½Ğµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä³ï¿½ï¿½ï¿½ï¿½Ë¹ï¿½Ö²ï¿½ï¿½Ä¸ï¿½ï¿½ï¿½ K-Means ï¿½Ğµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½Ç·ï¿½ï¿½ï¿½ï¿½ï¿½Ä³ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Í¬ï¿½ï¿½Í¬ï¿½ï¿½ï¿½È¼ï¿½ ï¿½ï¿½ï¿½ï¿½ Jensen ï¿½ï¿½ï¿½ï¿½Ê½ï¿½Æµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï£¬f(x) = logxï¿½ï¿½E(x) = log[] ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÚµÄ¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ã´ X ï¿½ï¿½ï¿½ï¿½ï¿½Ç¸ï¿½ï¿½ï¿½Ê½ï¿½ï¿½ ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Îªï¿½ï¿½ï¿½ï¿½ï¿½Â½ï¿½È¼ï¿½ï¿½ï¿½ E(theta)ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ëµï¿½Ê½ï¿½ï¿½ï¿½Æµï¿½ï¿½ï¿½Ò²ï¿½ï¿½ï¿½ï¿½Ëµï¿½ï¿½ï¿½ÚµÈ¼Ûµï¿½ï¿½ï¿½ï¿½ï¿½Â£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ó»¯¶ï¿½ï¿½ï¿½ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½Ë¡ï¿½ ï¿½ï¿½ï¿½Ò»ï¿½Ğµï¿½ï¿½Æµï¿½ï¿½ï¿½ï¿½Â£ï¿½ Í¨ï¿½ï¿½ E ï¿½ï¿½ï¿½ï¿½ï¿½Òµï¿½ï¿½ï¿½Ê¹ï¿½ÃµÈºÅ³ï¿½ï¿½ï¿½ï¿½ï¿½ $Q_i(z^{(i)})$ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ôºï¿½ï¿½ï¿½ï¿½Ç¾Í¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ E(f(x)) ï¿½Ë£ï¿½Ò²ï¿½ï¿½ï¿½ÇµÈ¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ f(E(x))ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Æµï¿½ï¿½ï¿½ï¿½Ãµï¿½ EM ï¿½ã·¨ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½Ê½ï¿½ï¿½ Ö®ï¿½ï¿½ï¿½ï¿½Ö¤ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ EM ï¿½ã·¨ï¿½ï¿½ kmeans ï¿½ã·¨ï¿½Ä¹ï¿½ï¿½ï¿½ï¿½ï¿½ z_i ï¿½Ä¶ï¿½ï¿½å£ºï¿½ï¿½ i ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½ï¿½ï¿½à¡£ ÎªÊ²Ã´ p ï¿½ï¿½Ã´ï¿½ï¿½ï¿½å£¿ ï¿½ï¿½ï¿½Ò»ï¿½Ğµï¿½Ê½ï¿½ï¿½ï¿½ï¿½ Ö®ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Î¢ï¿½Ö£ï¿½ ï¿½Ü½ï¿½ï¿½Øµã£ºï¿½ï¿½ÖµÑ¡ï¿½ñ²»ºÃ»áµ¼ï¿½Â²ï¿½ï¿½ÃµÄ½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ö²ï¿½ï¿½ï¿½Öµï¿½ï¿½ ï¿½Î¿ï¿½ï¿½ï¿½ï¿½Ï£ï¿½ https://blog.csdn.net/Matrix_cc/article/details/105266141","link":"/2023/04/09/machine-learning/lec4_EM%E7%AE%97%E6%B3%95/"},{"title":"","text":"ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½É·ï¿½Ä£ï¿½Í£ï¿½Hidden Markov Modelsï¿½ï¿½HMMï¿½ï¿½ Ò»ï¿½ï¿½Ó¦ï¿½Ãµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¶ï¿½ğ¡£¶ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Çµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ç£ï¿½ï¿½ï¿½Öªï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Î£ï¿½ï¿½ï¿½Öªï¿½ï¿½Ã¿ï¿½ï¿½×´Ì¬ï¿½ï¿½Ê±ï¿½ï¿½ï¿½Ğ¶à³¤ï¿½ï¿½ï¿½ï¿½Ò²ï¿½ï¿½Öªï¿½ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Î¶ï¿½Ó¦ï¿½ï¿½ï¿½ï¿½ï¿½Ö¡ï¿½ ï¿½ï¿½ï¿½ï¿½Ç°ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â£¬Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ÜµÄ·ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ kmeans ï¿½ï¿½ï¿½ï¿½ï¿½à£¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ğµï¿½ï¿½ï¿½Ö®ï¿½ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ï¿½Ø´ï¿½ï¿½Ä´ï¿½ï¿½Ú£ï¿½ï¿½ï¿½Êµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½Êµï¿½ï¿½ï¿½Ğ£ï¿½ï¿½ï¿½ï¿½ï¿½ ni shi shuiï¿½ï¿½Ò»ï¿½ã²»ï¿½Ç·Ö³ï¿½ ni ï¿½ï¿½ shi ï¿½ï¿½ shuiï¿½ï¿½ï¿½á»®ï¿½ÖµØ¸ï¿½Ï¸ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½É·ï¿½Ä£ï¿½Í£ï¿½ï¿½àµ±ï¿½ï¿½Ëµï¿½ï¿½ï¿½Ê±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ñ­ï¿½ï¿½ï¿½ï¿½Ëµï¿½Çµï¿½Ê±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ñ­ï¿½ï¿½â€¦ Ò»ï¿½ï¿½ HMM ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½É£ï¿½lambda = {A, B, pi} Îªï¿½Ë½ï¿½Ä£ï¿½ï¿½ï¿½ã£¬ï¿½ï¿½Ò»ï¿½ï¿½Ê±ï¿½ï¿½×´Ì¬Ö»ï¿½ï¿½Ç°Ò»ï¿½ï¿½Ê±ï¿½ï¿½×´Ì¬ï¿½Ğ¹Ø£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Æ·ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ç°ï¿½ï¿½ï¿½×´Ì¬ï¿½ï¿½ Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½Ê·Ö²ï¿½Ò»ï¿½ï¿½ï¿½ï¿½Ğ²ï¿½Í¬ï¿½ï¿½GMMÖ¸ï¿½ï¿½Ë¹ï¿½ï¿½ï¿½Ä£ï¿½Í¡ï¿½b_j(O) ï¿½ï¿½Ê¾ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ O ï¿½ï¿½ï¿½ï¿½ S_j ï¿½Ä¸ï¿½ï¿½Ê¡ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å£ºï¿½ï¿½ï¿½ï¿½Ö»Öªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Oï¿½ï¿½ï¿½ï¿½ï¿½Ç²ï¿½Öªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½×´Ì¬ Qï¿½ï¿½Q ï¿½Ç±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ O ï¿½ï¿½Ä£ï¿½ï¿½ï¿½Òªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¡ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â¡£ ï¿½ï¿½Ò»ï¿½ï¿½Ê¶ï¿½ï¿½ï¿½ï¿½ï¿½â£¨Evaluationï¿½ï¿½ï¿½ï¿½ï¿½Ù¸ï¿½ï¿½ï¿½ï¿½Ó£ï¿½ï¿½ï¿½ï¿½ï¿½1-10ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê¶ï¿½ğ£¬½ï¿½ï¿½ï¿½10ï¿½ï¿½Ä£ï¿½Í£ï¿½ï¿½ï¿½ï¿½ï¿½Ã¿ï¿½ï¿½Ä£ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½Pï¿½ï¿½Ë­ï¿½ï¿½Pï¿½ó£¬¾ï¿½Ëµï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½ï¿½ï¿½Ö¡ï¿½ ï¿½ï¿½Ğ©ï¿½ï¿½ï¿½ï¿½ÎªÊ²Ã´ï¿½ï¿½Òªï¿½ï¿½ b ï¿½î£¿ï¿½ï¿½ï¿½ï¿½ pi ï¿½î£¬ï¿½ï¿½ï¿½ï¿½ O1 ï¿½ï¿½×´Ì¬ï¿½ï¿½ q1ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½Í¨ï¿½ï¿½ b ï¿½ï¿½ï¿½ï¿½ï¿½ O1 ï¿½ï¿½ï¿½ï¿½ q1 ï¿½Ä¸ï¿½ï¿½Ê¡ï¿½ï¿½ï¿½ï¿½ÇµØ¼ï¿½ï¿½ï¿½Ò»ï¿½ã£¬ï¿½ï¿½ï¿½ï¿½ b ï¿½ï¿½ï¿½ï¿½ï¿½È·ï¿½ĞµØ·Ö±ï¿½ O1 ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ó¦ï¿½ï¿½×´Ì¬ q1ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ 1ï¿½ï¿½ï¿½Ç¶ï¿½Ó¦ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ 0ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ q1 ×´Ì¬ï¿½ï¿½Ê¼ï¿½Ä¿ï¿½ï¿½ï¿½ï¿½ï¿½ pi ï¿½ï¿½Ã»ï¿½ï¿½ï¿½ï¿½ï¿½å£¬ï¿½Ê¸ï¿½ï¿½ï¿½ï¿½ pi ï¿½ï¿½Ò»ï¿½ï¿½ 0ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ëµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü±ï¿½ï¿½ï¿½ï¿½Ï³ï¿½Ä³Ò»ï¿½ï¿½ï¿½ï¿½Ò»Ğ©ï¿½Ø¶ï¿½ï¿½Ä´Ê¡ï¿½ ï¿½ï¿½ï¿½Çµï¿½Ò»ï¿½ï¿½ b ï¿½î£¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ O1 ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ÏµÄ¸ï¿½ï¿½Ê·Ö²ï¿½ï¿½ï¿½Ò²ï¿½ï¿½ï¿½ï¿½ O1 ï¿½ï¿½ï¿½Ú¸ï¿½ï¿½ï¿½×´Ì¬ï¿½Ä¸ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ O1 ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ p1 ï¿½ï¿½ï¿½ï¿½ s1ï¿½ï¿½ï¿½ï¿½Ã´ï¿½Úµï¿½Ç°ï¿½ï¿½ï¿½ï¿½ O1 ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ s1 ×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½Ê¾ï¿½ï¿½Çµï¿½ï¿½ï¿½×´Ì¬ s1 ï¿½Ä¸ï¿½ï¿½Ê³ï¿½ï¿½ï¿½p1ï¿½ï¿½Í¬ï¿½ï¿½ï¿½Ä£ï¿½ï¿½ï¿½ï¿½ÇµÚ¶ï¿½ï¿½ï¿½ b ï¿½î£¬ï¿½ï¿½ï¿½ï¿½ O2 ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ p2 ï¿½ï¿½ï¿½ï¿½ s2ï¿½ï¿½ï¿½ï¿½Ã´ï¿½Úµï¿½Ç°ï¿½ï¿½ï¿½ï¿½ O2 ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ s2 ×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½Ê¾ï¿½ï¿½Çµï¿½ï¿½ï¿½×´Ì¬ s2 ï¿½Ä¸ï¿½ï¿½Ê³ï¿½ï¿½ï¿½ p2ï¿½ï¿½ Ò²ï¿½ï¿½ï¿½Ç¶ï¿½ï¿½ï¿½Ä³ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ Oï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ O ï¿½ï¿½ï¿½ï¿½Ä³ï¿½ï¿½×´Ì¬ï¿½Ä¸ï¿½ï¿½Ê£ï¿½ï¿½ï¿½ O ï¿½ï¿½ï¿½ï¿½Ä³ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½È¨ï¿½Ø£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ëµ½ï¿½ï¿½ï¿½ï¿½ï¿½×´Ì¬ï¿½Ä¸ï¿½ï¿½Ê¡ï¿½ Ò»ï¿½ï¿½Ê¼Ã»ï¿½ëµ½ b ï¿½ï¿½ï¿½Ô­ï¿½ò£º°ï¿½ï¿½ï¿½ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öªï¿½Ë¡ï¿½ï¿½ï¿½Öªï¿½ï¿½ï¿½ï¿½ï¿½È·ÊµÃ»ï¿½ï¿½ b ï¿½î£¬ï¿½ï¿½Îªï¿½È¼ï¿½ï¿½ï¿½ 1ï¿½ï¿½Í¬Ê±Ò²Ã»ï¿½ï¿½ sum ï¿½î¡£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Î´Öªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â£ï¿½ï¿½ï¿½Òªï¿½ï¿½ï¿½ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¿ï¿½ï¿½ï¿½ï¿½Ô£ï¿½ï¿½Í»ï¿½ï¿½Ğ¸ï¿½ï¿½Ê·Ö²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ 1ï¿½ï¿½0ï¿½ï¿½0ï¿½ï¿½0 ï¿½Ä¸ï¿½ï¿½Ê·Ö²ï¿½ï¿½ï¿½ ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â£¬ï¿½ï¿½Ê½ï¿½Ó»ï¿½ï¿½ï¿½Ì«ï¿½ï¿½ï¿½ï¿½ï¿½Ë£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½â¡ªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ó·¨¡ï¿½ alpha_t(i) ï¿½ï¿½ï¿½ï¿½Îªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Û»ï¿½ï¿½ï¿½ t Ê±ï¿½ï¿½Ê±ï¿½ï¿½ï¿½Ñ¸ï¿½Ê±ï¿½Ìµï¿½ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ s_i ï¿½ï¿½ï¿½ï¿½ï¿½Ä¸ï¿½ï¿½Ê¡ï¿½ b_i(O_1) = P(O_1|q_t=s_i, lambda) ï¿½ï¿½ï¿½ï¿½Îªï¿½ï¿½O1 ï¿½ï¿½ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ s_i ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½È¨ï¿½Ø¡ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Decodingï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½Ò»ï¿½Ç¸ï¿½ï¿½ï¿½Ä£ï¿½Íºï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Úµï¿½Ç°Ä£ï¿½Íµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Æ¥ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä³Ì¶È£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ç¸ï¿½ï¿½ï¿½Ä£ï¿½Íºï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Æ¥ï¿½ï¿½ï¿½ï¿½ï¿½×´Ì¬ï¿½ï¿½ï¿½Ğ¡ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Î¬ï¿½Ø±ï¿½ï¿½ã·¨ï¿½ï¿½ Ã¿ï¿½ï¿½Ê±ï¿½ä¶¼ï¿½ï¿½ï¿½ï¿½Ñ¡ p ï¿½ï¿½×´Ì¬ï¿½Ğµï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½àµ±ï¿½ï¿½ï¿½ï¿½Í¼ï¿½ï¿½ï¿½ï¿½Ã¿ï¿½ï¿½Ê±ï¿½ï¿½ï¿½Ñ¡Ò»ï¿½ï¿½×´Ì¬ï¿½ï¿½È»ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½Â·ï¿½ï¿½ï¿½ï¿½Ñ¡ï¿½ï¿½ï¿½Ó¦×´Ì¬ï¿½ó£¬¼ï¿½ï¿½ï¿½ï¿½Ó¦×´Ì¬ï¿½Ä¼ï¿½Öµï¿½ï¿½ Ã¿ï¿½ï¿½Ê±ï¿½ï¿½Î£ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»Ê±ï¿½ï¿½Îµï¿½ï¿½ï¿½ï¿½Ğ½Úµï¿½ï¿½ï¿½ï¿½ß£ï¿½ï¿½ï¿½ï¿½ï¿½Öµï¿½ï¿½ï¿½Úµï¿½Ç°ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Öµï¿½Ô¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÖµÊ±Ç°Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ô»ï¿½ï¿½İµÃµï¿½Ò»ï¿½ï¿½ï¿½ï¿½Ãµï¿½Â·ï¿½ß£ï¿½Ò²ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ E(Q)ï¿½ï¿½ Î¬ï¿½Ø±ï¿½ï¿½ã·¨ï¿½ï¿½ï¿½Ì£ï¿½ ï¿½ï¿½ï¿½ÏµÃµï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ E(Q)ï¿½ï¿½ï¿½ï¿½ï¿½àµ±ï¿½Ú¶ï¿½ï¿½Ú¸ï¿½Ã¿ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ O ï¿½ï¿½ï¿½ï¿½Ò»ï¿½ï¿½ï¿½ï¿½Ç©ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ÎªÒ»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ HMM Ä£ï¿½Í´ï¿½ï¿½Ç©ï¿½Ä²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ñ§Ï°ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ã´ï¿½ï¿½ï¿½ï¿½ï¿½Ä±ï¿½Ç©ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Èµï¿½ï¿½ï¿½ï¿½ç£¬ï¿½Ô¶ï¿½Í¨ï¿½ï¿½ O Ñ§Ï°ï¿½ï¿½ï¿½ï¿½ï¿½Ç©ï¿½ï¿½ï¿½Ó¶ï¿½ï¿½æ»»ï¿½ï¿½ï¿½Ğ¹Û²ï¿½ï¿½ b ï¿½î¡£ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ñµï¿½ï¿½ï¿½ï¿½ï¿½â£¨Learningï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½Í¹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Å»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ë¼ï¿½ï¿½ã£º b ï¿½ï¿½ï¿½ó·¨£ï¿½","link":"/2023/04/09/machine-learning/lec5_%E9%9A%90%E5%90%AB%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B/"},{"title":"","text":"MAVROS æ•™ç¨‹ â€”â€” Offboard æ¨¡å¼ä¸‹è‡ªä¸»é£è¡Œ AMOV è§†é¢‘æ•™ç¨‹ 1.1 å·¥å…·é“¾å®‰è£…MAVROS æ“ä½œæ— äººæœºçš„è½¯ç¡¬ä»¶æ¶æ„ Mavros å·¥å…·åŒ…å¯ä»¥æŠŠæ¥æ”¶åˆ°çš„ Mavlink æ¶ˆæ¯ï¼ˆçŠ¶æ€æ•°æ®ï¼‰è½¬æ¢æˆ ROS æ¶ˆæ¯å‘é€ç»™ ROS ç³»ç»Ÿï¼Œäº¦å¯ä»¥æŠŠ ROS ç³»ç»Ÿå‘é€çš„ ROS æ¶ˆæ¯ï¼ˆæ§åˆ¶æ¶ˆæ¯ï¼‰è½¬æ¢æˆ Mavlink æ¶ˆæ¯å‘é€ç»™é£æ§ã€‚ å·¥å…·é“¾ï¼šVMware è™šæ‹Ÿæœº + 18.04 Ubuntu + ROS Melodic + mavros åŒ… + gazebo ä»¿çœŸå·¥å…· ROS å®‰è£… æ¢æºï¼Œå¦‚ä¸­ç§‘å¤§ã€é˜¿é‡Œã€æ¸…åã€‚vim(gedit) /etc/apt/source.listã€‚ sudo apt-get updateã€‚sudo apt-get update å®‰è£…ã€‚æœ€åä¸¤è¡Œä»£ç å®¹æ˜“å¤±è´¥ï¼Œå»ºè®®ç§‘å­¦ä¸Šç½‘æˆ–è€…å¤šè¯•å‡ æ¬¡ã€‚ æ£€éªŒå®‰è£…ï¼šroscore Mavros å®‰è£… äºŒè¿›åˆ¶å®‰è£…ï¼šå·²ç»ç¼–è¯‘å¥½çš„å·¥å…· æºç å®‰è£…[æ¨è]ï¼šå®‰è£…ã€‚éƒ½æ˜¯åŸå§‹ä»£ç ï¼Œå¿…é¡»ç¼–è¯‘æˆå¯ä»¥æ‰§è¡Œçš„äºŒè¿›åˆ¶æ–‡ä»¶æ‰å¯ä»¥æ‰§è¡Œï¼Œå¯ä»¥ä¿®æ”¹ä»£ç ï¼Œè¿›è¡Œå¼€å‘ç­‰ç­‰ã€‚æ³¨ï¼šæ•™ç¨‹å¤„ç”¨çš„æ˜¯ kinetic ç‰ˆæœ¬ï¼Œå®é™…ä¸­è®°å¾—æ¢æˆ melodicã€‚ æ£€éªŒå®‰è£…ï¼šroslaunch mavros px4.launch 1.2 ROS åˆ›å»ºèŠ‚ç‚¹ä¸ç¼–è¯‘ROS çš„é€šä¿¡æ–¹å¼ï¼š server ç‚¹å¯¹ç‚¹ï¼Œå“åº”å¿« topic å¤šå¯¹å¤š ROS æ–‡ä»¶ç³»ç»Ÿç»„ç»‡ ç¼–è¯‘åŸºäº catkinï¼ŒCMakeList.txt ç”¨äºåç»­çš„ç¼–è¯‘ã€‚ å¸¸ç”¨å‘½ä»¤ rospack è·å–æœ‰å…³åŒ…çš„ä¿¡æ¯ï¼Œæœ¬æ•™ç¨‹ä»…ä»¥ find ä¸ºä¾‹ï¼Œè¿”å›åŒ…çš„è·¯å¾„ã€‚ rospack find [pacakge name] roscd å°†ç›®å½•æ”¹ä¸ºåŒ…æˆ–å †æ ˆï¼Œæˆ–è€…å…¶å­ç›®å½• roscd &lt;package-or-stack&gt;[/subdir] rosls ç›´æ¥æŸ¥çœ‹åŒ…ä¸­æ–‡ä»¶ï¼Œæˆ–è€…å…¶å­ç›®å½• rosls &lt;package-or-stack&gt;[/subdir] èŠ‚ç‚¹åˆ›å»ºä¸ç¼–è¯‘ åˆ›å»ºå·¥ä½œç©ºé—´å¹¶è¿›å…¥ srcã€‚mkdir -p catkin_ws/srcï¼Œcd catkin_ws/src åˆ›å»ºåŠŸèƒ½åŒ…ã€‚crakin_create_pkg [package-name] roscpp std_msgs roscppï¼šç”¨ cpp ç¼–è¯‘ std_msgsï¼šç”¨å·²æœ‰çš„æ•°æ®ç»“æ„ è¿›å…¥åŠŸèƒ½åŒ…çš„ src å¹¶åˆ›å»ºæºæ–‡ä»¶ã€‚cd package-name/srcã€‚ å›åˆ°ä¸Šçº§ç›®å½•ï¼Œä¿®æ”¹ CMakeLists.txtã€‚ ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ä¸ºç”Ÿæˆçš„å¯ä»¥æ‰§è¡Œæ–‡ä»¶å®šä¹‰ä¸€ä¸ªåå­—ï¼Œç¬¬äºŒä¸ªæ˜¯é»˜è®¤çš„æºä»£ç ç›®å½•ï¼Œéœ€è¦ä¿®æ”¹ã€‚ ç¬¬ä¸€ä¸ªå‚æ•°éœ€è¦å’Œå‰è€…å¯¹åº”ã€‚ å›åˆ°å·¥ä½œç©ºé—´ç›®å½•ï¼Œç¼–è¯‘ã€‚catkin buildã€‚ä¼šäº§ç”Ÿ buildã€devel æ–‡ä»¶å¤¹ã€‚ ç¼–è¯‘æˆåŠŸåï¼Œroscoreï¼Œsource ~/catkin_ws/devel/setup.shã€‚ä¹‹åä¾¿å¯ rosrun [ç»“ç‚¹å]ã€‚ 1.3 ROS ç¼–ç¨‹åŸºç¡€ä¾‹ç¨‹ï¼šç®€å•çš„å‘å¸ƒå’Œè®¢é˜… [ä»£ç è®²è§£] è¿è¡Œæ–¹å¼ï¼ˆæ³¨æ„å„ä¸ªå‘½ä»¤ç”¨ç‹¬ç«‹çš„ç»ˆç«¯ï¼‰ roscore rosrun minimal_nodes[åŒ…å] minimal_publisher[èŠ‚ç‚¹å] rosrun minimal_nodes[åŒ…å] minimal_subscriber[èŠ‚ç‚¹å] rostopic listï¼Œrostopic info topic1[è¯é¢˜å]ï¼Œrostopic hz topic1[è¯é¢˜å]ã€‚ ä¾‹ç¨‹ï¼šç®€å•çš„æ§åˆ¶å™¨å’Œä»¿çœŸå™¨ [ä»£ç è®²è§£] è¿è¡Œæ–¹å¼ roscore rosrun minimal_nodes[åŒ…å] minimal_simulator[èŠ‚ç‚¹å] rosrun minimal_nodes[åŒ…å] minimal_controller[èŠ‚ç‚¹å] å‘é€é¢„å®šé€Ÿåº¦ï¼šrostopic pub -r 10[hz] vel_cmd[è¯é¢˜å] std_msgs/Float64[æ•°æ®ç±»å‹] 1.0 C++ ç±»çš„ä½¿ç”¨ ROSä»£ç å¦‚æœè®¢é˜…å¾ˆå¤šä¸ªæ¶ˆæ¯ï¼Œå‘å¸ƒå¤šä¸ªæ¶ˆæ¯çš„è¯ï¼Œå¾ˆå¿«ä¼šå˜å¾—è¿‡äºå†—é•¿ï¼Œè‹¥è¦æé«˜ä»£ç æ•ˆç‡å’Œä»£ç å¤ç”¨ï¼Œæœ€å¥½ä½¿ç”¨ç±»ã€‚ åœ¨å¤´æ–‡ä»¶ä¸­å®šä¹‰ç±»: å®šä¹‰æ‰€æœ‰æˆå‘˜å‡½æ•°çš„åŸå‹ å®šä¹‰ç§æœ‰å’Œå…¬å…±æ•°æ®æˆå‘˜ å®šä¹‰æ„é€ å‡½æ•°çš„åŸå‹ ç¼–å†™ä¸€ä¸ªå•ç‹¬çš„å®ç°æ–‡ä»¶ åŒ…å«ä¸Šé¢çš„å¤´æ–‡ä»¶ åŒ…å«å·²ç»å£°æ˜æˆå‘˜å‡½æ•°çš„å·¥ä½œä»£ç  åŒ…å«åœ¨æ„é€ å‡½æ•°ä¸­å°è£…çš„å¿…è¦çš„åˆå§‹åŒ–çš„ä»£ç  æ„å»ºæ–‡ä»¶ç³»ç»Ÿ åœ¨åŠŸèƒ½åŒ…ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªinlcude/minimal_controller_class [ç»“ç‚¹å]çš„æ–‡ä»¶å¤¹ å¹¶åœ¨è¯¥æ–‡ä»¶å¤¹ä¸‹åˆ›å»ºä¸€ä¸ªminimal_controller_class.hçš„æ–‡ä»¶ åœ¨srcç›®å½•ä¸‹åˆ›å»ºminimal_controller_class.cppæ–‡ä»¶ ä¿®æ”¹CMakeLists.txtï¼Œä½¿å¾—rosç»“ç‚¹åŒ…å«è¿›includeæ–‡ä»¶å¤¹æ‰€åŒ…å«çš„å¤´æ–‡ä»¶ æ²¡çœ‹å®Œï¼Œå…ˆè·³è¿‡ã€‚ 1.4 Mavros æ¶ˆæ¯çš„è®¢é˜…ä¸å‘å¸ƒ1.4.1 åº”ç”¨mavrosæ§åˆ¶æ— äººæœºçš„æ¶ˆæ¯æµ å¦‚ä½•å»æŸ¥é˜…mavrosçš„æ¶ˆæ¯ä¸mavlinkåè®®ä¹‹é—´çš„å…³ç³» å¦‚ä½•å»æ‰¾åˆ°mavlinkåè®®ä¸uorbæ¶ˆæ¯ä¹‹é—´çš„å¯¹åº”å…³ç³» 1.4.2 example offboardä¾‹ç¨‹çš„ä»¿çœŸä¸è§£æ ä½¿ç”¨gazeboè¿›è¡Œè½¯ä»¶åœ¨ç¯ä»¿çœŸ æ­è½½æœºè½½è®¡ç®—æœºçš„æ— äººæœºçš„å®é™…é£è¡Œæµ‹è¯• ENU åæ ‡ç³»ï¼Œz=2ï¼Œå‡é«˜ä¸¤ç±³ã€‚","link":"/2023/04/09/lab-experience/mavros-tutorials/MAVROS%20notes/"},{"title":"","text":"Mavros 1. mavros è„šæœ¬è¯­æ³•123456&lt;launch&gt; &lt;node pkg=&quot;åŠŸèƒ½åŒ…çš„åå­—&quot; type=&quot;åŠŸèƒ½åŒ…ä¸‹ä½ æƒ³å¯åŠ¨èŠ‚ç‚¹çš„åå­—&quot; name=&quot;å¯¹è¿™ä¸ªèŠ‚ç‚¹å†å‘½ä¸ªå&quot; output=&quot;&quot;&gt; output ç»“æœè¾“å‡ºåœ¨å±å¹•ä¸Šï¼Œæ²¡æœ‰è¿™ä¸ªå‚æ•°é»˜è®¤è®°å½•åœ¨logé‡Œ &lt;param name=&quot;&quot;&gt; ä¼ å‚:https://blog.csdn.net/taste_cyn/article/details/82737225 &lt;/node&gt;&lt;/launch&gt; 2. mavros æ•°æ®ä¼ è¾“å…³æ³¨ px4_pos_estimator.cppï¼Œå¯èƒ½æ˜¯å‘é£æ§ä¼ é£æœºçš„å§¿æ€æ•°æ®ã€‚ä»–ä»¬ä¼ æ•°æ®ï¼Œéƒ½æ˜¯ç”¨rosè®¢é˜…çš„æ–¹å¼ï¼Œé£æ§åˆæ˜¯åªçœ‹å¾—æ‡‚mavlinkåè®®é‡Œé¢çš„ä¸œè¥¿ã€‚æ‰€ä»¥é£æ§æ€ä¹ˆæ‹¿æ•°æ®å‘¢ï¼Ÿ mainï¼šå…ˆåœ¨ä»t265è®¢é˜…ï¼ˆsubscribeï¼‰çš„æ¶ˆæ¯ä¸­ï¼Œæ‹¿åˆ°é£æœºçš„å§¿æ€æ•°æ®ã€‚ mainï¼šå¼€è¾Ÿä¸€ä¸ªè¯é¢˜ï¼ˆadvertiseï¼‰ï¼Œç”¨ä»¥è¡¨ç¤ºæ— äººæœºçš„ä½ç½®å’Œå§¿æ€ã€‚ send_to_fcuï¼šåˆ©ç”¨ publish å°†æ¶ˆæ¯å‘å¸ƒã€‚ é—®ï¼šmavros é€šè¿‡è®¢é˜…å’Œå‘å¸ƒå®ç°æ¶ˆæ¯çš„ä¼ è¾“ï¼Œé£æ§åˆéµå¾ªçš„æ˜¯mavlinkåè®®ï¼Œæ‰€ä»¥é£æ§æ€ä¹ˆæ‹¿æ•°æ®å‘¢ï¼Ÿ æ€è·¯ï¼šåº”å­˜åœ¨æœ‰ä¸€éƒ¨åˆ†ä¼šå‘é€ mavlink æ¶ˆæ¯ï¼Œé‚£æ”¶åˆ° mavlink æ¶ˆæ¯å‰ï¼Œæœ‰éœ€è¦å…ˆæ”¶åˆ° send_to_fcu å‘é€çš„ mavros æ¶ˆæ¯ã€‚æ—¢ç„¶æœ‰ publishï¼Œé‚£å°±åº”è¯¥æœ‰ subscribeï¼Œé‚£æ€ä¹ˆæ‰¾åˆ°å“ªé‡Œæœ‰ subscribeï¼Ÿ 1grep -r &quot;/mavros/vision_pose/pose&quot; å…³æ³¨ vision_pose_esimate.cppï¼Œè¯¥æ–‡ä»¶è®¢é˜…äº†è¯¥æ¶ˆæ¯ï¼Œå¹¶å°†è¯¥æ¶ˆæ¯å°è£…æˆ mavlink æ¶ˆæ¯å‘ç»™é£æ§ã€‚ 3. PX4 &amp; Ardupilotpx4å’ŒardupilotåŸæœ¬æ˜¯ä¸¤å¥—ç‹¬ç«‹çš„å¼€æºé£æ§ï¼Œå„è‡ªæœ‰è½¯ä»¶å’Œç¡¬ä»¶ã€‚åæ¥ardupilotçœ‹ä¸­äº†px4çš„ç¡¬ä»¶ï¼Œå°±æŠŠä»£ç ç§»æ¤åˆ°px4ä¸Šäº†ã€‚æ‰€ä»¥ç›®å‰px4å’Œapmä¸»æµæ˜¯è¿è¡Œåœ¨ä¸€ç§ç¡¬ä»¶ä¸Šçš„ä¸¤ç§è½¯ä»¶ã€‚å„è‡ªéƒ½æ˜¯å®Œå¤‡çš„ç³»ç»Ÿã€‚ px4æ˜¯åŸºäºå®æ—¶æ“ä½œç³»ç»Ÿçš„ï¼Œä¼ æ„Ÿå™¨é‡‡é›†ã€å¯¼èˆªã€æ§åˆ¶ã€å­˜å‚¨ç­‰ç­‰éƒ½æ˜¯å•ç‹¬çš„åº”ç”¨ç¨‹åºï¼Œå› æ­¤apmçš„ä»£ç ä¹Ÿè¢«å°è£…æˆäº†ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œè·Ÿpx4çš„ä»£ç æ ˆåœ¨ä¸€èµ·ã€‚è€Œä¸”apmè¿˜ç”¨åˆ°äº†ä¸€éƒ¨åˆ†px4çš„åº•å±‚åº”ç”¨ã€‚ é£æ§æ§åˆ¶çš„æƒ³æ³•ï¼šrospy + pymavlinkã€‚ è™½ç„¶pymavlinkå¥½åƒæ˜¯arduå®¶çš„å®ç°ï¼Œä½†åº•å±‚å…¶å®æœ‰ç›´æ¥åšpx4å…¼å®¹æ˜ å°„çš„ã€‚ è¿™äº›æ ‡é¢˜ä¸‹çš„ä¾‹ç¨‹ï¼Œä¼˜å…ˆè¯•è¯•ã€‚è¯•ä»£ç çš„æ—¶å€™è®°å¾—ä¸è¦æ— è„‘è¯•ï¼Œè¦éªŒè¯ mavlink èƒ½ä¸èƒ½é€šã€‚çœ‹è®¾è®¡ç—•è¿¹ï¼Œpymavlinkè¿˜æ˜¯æœ‰ç‚¹é’ˆå¯¹ardupilotçš„ã€‚ https://www.ardusub.com/developers/pymavlink.html","link":"/2023/04/09/lab-experience/mavros-tutorials/MAVROS%20topics/"},{"title":"","text":"MINIMAL_NODEShere are source examples for minimal nodes, as covered in the text Part 1, Chapter 1. This package ncludes a minimal publisher, minimal subscriber, minimal simulator andminimal controller, as well as a launch file.","link":"/2023/04/09/lab-experience/mavros-tutorials/Amovlab%20MAVROS%20offboard/%E7%AC%AC%E4%B8%80%E7%AB%A0%20%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/1-3minimal_nodes/1-3minimal_nodes/minimal_nodes/README/"}],"tags":[],"categories":[{"name":"algorithm","slug":"algorithm","link":"/categories/algorithm/"},{"name":"others","slug":"others","link":"/categories/others/"},{"name":"courses","slug":"courses","link":"/categories/courses/"},{"name":"machine-learning","slug":"machine-learning","link":"/categories/machine-learning/"}]}