<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Yourname"><title>Hexo</title><meta name="description" content="A simple and beautiful blog"><meta name="keywords" content="Blog,博客,Hexo"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/insight.css"><link rel="stylesheet" href="/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li> <a href="/">Home</a></li><li> <a href="/archives">Archives</a></li><li> <a href="/tags">Tags</a></li><li> <a href="/about">About</a></li><li> <a href="/links">Links</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)" style="display:none;"> </a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/images/logo.webp"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/images/logo@2x.webp" style="width:220px;" alt="favicon"><h3 title=""><a href="/">Hexo</a></h3><div class="description"><p>A simple and beautiful blog</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/Lhcfl"><i class="fa fa-github"></i></a></li><li><a href="mailto:yourname@example.com"><i class="fa fa-envelope"></i></a></li><li><a target="_blank" rel="noopener" href="https://zhihu.com/people/jin-xin-4-68"><i class="fa fa-mortar-board"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> 全站CC-BY-SA-3.0 </span><i class="fa fa-star"></i><span> Yourname</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2023/04/09/machine-learning/lec3_%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1/"></a></h3></div><div class="post-content"><div class="card"><p><p>���ر�Ҷ˹��������Naive Bayesian Classifier��</p>
<p>������������ ���� X ��ÿ��ά�ȶ�����ɢ��</p>
<p>�� X ��ÿ��ά�ȶ��Ƕ����ģ�������أ�</p>
<p>�����и�Ӧ�ý������ʼ����࣬��һ���ļ���ֻ�����ࣨ�Ƿ��������ʼ�����</p>
<p>���룺һ���ʼ� d</p>
<p>�����d in c_1 �� d in c_2</p>
<p>ѵ������ {(d_i, y_I)}_{i&#x3D;1-N}��d&#x3D;{w1, w2, …, wn} ��ÿ���ʼ���������</p>
<p>ѧϰĿ�꣺P(d|c_1) �� P(d|c_2)</p>
<p>P(d|C) &#x3D; P({w1, w2, …, wn} | C)</p>
<p>������������������������������ �٣�w �����ﱻ����Ϊ���ʣ�������Ȼ�ܶ࣬��������Ŀ�����޵ģ���˿��Ա���ɢ��ʾ�������������� �ڣ���Ȼ���Ƕ����ģ���Ϊ�����뵥��֮����������ϵ�������������ʼ�������һ�򵥵���������Լ��� �ڳ�������һЩ��Ϊ���ӵı�������ʶ�𣬱㲻����ô����</p>
<p>P(d|C) &#x3D; P({w1, w2, …, wp} | C) &#x3D; [�۳� i in n]P(w_i|C)</p>
<p>P(w_i|C_j) &#x3D; count(w_i, c_j) &#x2F; [�ۼ�w in V]count(w, c_j)������ j&#x3D;1-2��</p>
<p>P(C_i) &#x3D; count(C_i) &#x2F; count(C)</p>
<p> ��P(d|c_1)P(c_1) &gt; P(d|c_2)P(c_2) �� d in c_1��</p>
<p>�����ܴ����������������һ������δ��ѵ�����г��ֹ�����ô P(d|c) [����cȡ�ĸ�] ���� 0��Ϊ��ֹ����������Ľ����㹫ʽ���£�</p>
<p>P(w_i|C_j) &#x3D; count(w_i, c_j) + 1&#x2F; [�ۼ�w in V]count(w, c_j) + |V|������ j&#x3D;1-2��</p>
<p>��˹�ܶȺ���</p>
<p>���� {x_i}_{i&#x3D;1-n} in C��X_i ��һά�����</p>
<p>$P(X|C) &#x3D; \frac{1}{\sqrt{2\pi \sigma}}e ^ {- \frac{(x-\mu)^2}{2\sigma^2}}$ </p>
<p>$\mu &#x3D; \frac{1}{N} \sum^{N}_{i&#x3D;1}X_i$</p>
<p>$\sigma^2&#x3D;\frac{1}{N-1}\sum^{N}_{i&#x3D;1}(X_i-\mu)^2$ [��ƫ����]</p>
<p>�����һά�����������֤����ά�������</p>
<p>$P(X|C)&#x3D;\frac{1}{\sqrt{(2\pi)^d |\sum|}}exp[-\frac{1}{2}(x-\mu)^T\sum^{-1}(x-\mu)]$</p>
<p>������� $\sum $ �� $\mu$�����ü�����Ȼ��������Ŀ�꺯����</p>
<p>$E(\mu, \sum)&#x3D;\sum^{N}_{i&#x3D;1}lnP(x_i|C)$</p>
<p>���ڼ��裺�� ���� {X_i}_{i&#x3D;1-N}  ����ͬ�ֲ�</p>
<p>�� �趨 $\mu$ ��$\sum$ ʹ���� {x_i} �ĸ������</p>
<p>���򣬾����֤���κ�ȥ�˽⡣</p>
<img src="https://s2.loli.net/2022/06/04/OLDuRB6bo7gFwHi.png" alt="image-20220604170701333" style="zoom:50%;" />

<p>������Ҫǿ�����㣬�����ʷ��෨Ҫ����ļ��㣺</p>
<p>�� ���� X �ĸ��ʷֲ��ľ�����ʽ��Ҳ������ P(X|C)�������������ʽ���У���һЩ���������������˹���ʷֲ���Ϊ $\mu, \sum$��</p>
<p>�� �ü��������Ȼ�������Ż�Ŀ�꺯����</p>
<p>�� �� �� �е��Ż����⣬��ô��������</p>
<p>��Ȼ�����ڸ�˹�����Ǹ�͹�ĺ���������ֵ����ȫ�����ֵ�������ڿ���ֱ����΢������������ںܶ���������㲻�����ģ�����ô���أ������ݶ��½��ȵȡ�</p>
<p>��˹���ģ��</p>
<p>��󣬾�������һ���㲻��������ֵ�����⡣Ҳ����ϸ�˹ģ�ͣ�Gaussian Mixture Model����</p>
<p><img src="https://s2.loli.net/2022/06/04/wR7JIZ2tYvSeybK.png" alt="image-20220604171707303"></p>
<p><img src="https://s2.loli.net/2022/06/04/1KW7LlMsoDGmIVY.png" alt="image-20220604172023016"></p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2023-04-09</span><span class="leancloud_visitors"></span><span>About 1252 words, 4 min 10 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2023/04/09/machine-learning/lec2_%E6%A6%82%E7%8E%87%E5%88%86%E7%B1%BB%E6%B3%95/"></a></h3></div><div class="post-content"><div class="card"><p><p>���ʷ��෨</p>
<p>�������⣺�� �����������࣬omega_1 �� omega_2���� ����ĳ�������� X��Ҫô�� X in omega_1��Ҫô�� X in omega_2��</p>
<p>�� P(omega_1 |X) �� P(omega_2 |X)��P(omega_1 |X) + P(omega_2 |X) &#x3D; 1��</p>
<p>�������⣺P(omega_1 |X) &gt; P(omega_2 |X) ���� X in omega_1��</p>
<p>���ݱ�Ҷ˹��ʽ��</p>
<p>P(omega_1 |X) &#x3D; P��X, omega_1) &#x2F; P(X) &#x3D; P��X|omega_1) P(omega_1)&#x2F; P(X) </p>
<p>P(omega_2 |X) &#x3D; P��X, omega_2) &#x2F; P(X) &#x3D; P��X|omega_2) P(omega_2)&#x2F; P(X) </p>
<p>Ҫ�Ƚ�P(omega_1 |X) &gt; P(omega_2 |X)��ֻ��Ҫ�Ƚ���ʽ�ķ��ӡ�</p>
<p>���У�P(omega_1) �� P(omega_2) ���� omega ��������ʡ�P��X|omega_1) �� P��X|omega_2) ���� X �� omega �ϵ��������ʣ�P(omega_1 |X) �� P(omega_2 |X) ���� X �� W �ϵĺ�����ʡ�</p>
<p>�˹����������������ʣ�����������ģ�� P(omega_1 |X) �� P(omega_2 |X)��������ˣ������Ա���Ҫ�ǳ���ע������ʡ�����ѵ��������ģ�ͣ�ѵ����ʱ���������忪�����ǲ��Ե�ʱ���һ�����ͻ���ֺܴ�����⡣Ҳ��������Ҫ�ڲ��Ժ�ѵ����ʱ��֤������������ǲ��ġ�ʵ��ʱ������һ�������������ҵĲ��裬��ԭ��Ҳ���������</p>
<p>���������ص㡣��һ������������ӣ�����֪��������ʣ���<strong>���������������һ��</strong>���ڴ�����£�����׼��</p>
<p>�� P��X|omega_1) &lt; P��X|omega_2) �� X in omega_2����֮ X in omega_1</p>
<p>��ι���  P��X|omega) ������˵����һ�� X_i in omega������� P��X|omega) �����������������ܶȹ������⡣</p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2023-04-09</span><span class="leancloud_visitors"></span><span>About 695 words, 2 min 19 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2023/04/09/hello/hello-world/">Hello World</a></h3></div><div class="post-content"><div class="card"><p><p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2023-04-09</span><span class="leancloud_visitors"></span><span>About 75 words, 15 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2022/07/06/machine-learning/2022-07-06-review-machine-learning-courses/">[ml][rv] sysu-courses</a></h3></div><div class="post-content"><div class="card"><p><h4 id="1-线性回归-逻辑回归"><a href="#1-线性回归-逻辑回归" class="headerlink" title="1. 线性回归 + 逻辑回归"></a>1. 线性回归 + 逻辑回归</h4><blockquote>
<p>TIPS：什么是线性回归逻辑回归，损失函数有可能带正则项，为什么要加正则项因为要防止过拟合，损失函数要怎么定义，梯度下降好处有什么坏处有什么，最优参数表达式怎么写的</p>
</blockquote>
<p><strong>损失函数</strong></p>
<p><strong>最优参数表达式</strong></p>
<p>损失函数带正则项的原因（补）：防止过拟合。[防止过拟合的另一种方法：k-fold交叉验证]</p>
<p><strong>定义（补）：</strong></p>
<p>回归模型</p>
<img src="https://s2.loli.net/2022/06/16/7ptIHgE9TxmLqDY.png" alt="image-20220616211439417" style="zoom: 33%;" />

<p>线性模型：</p>
<img src="https://s2.loli.net/2022/06/16/iSARVj61pXs7uot.png" alt="image-20220616211840331" style="zoom:33%;" />

<p>对于上式，假设b&#x3D;0，则易得：</p>
<img src="https://s2.loli.net/2022/06/16/38sicRAGgWkaBQ9.png" alt="image-20220616211950067" style="zoom: 33%;" />

<p>矩阵形式可以写作为：</p>
<img src="https://s2.loli.net/2022/06/16/CmTt9DBIVc564PX.png" alt="image-20220616212339948" style="zoom:33%;" />

<p>显然，我们的目的就是求位置参数 theta，如何求解？构造最大似然估计（maximum likelihood estimator，MLE），找到 theta 使得似然概率最大。</p>
<p>最大似然估计的合理性在于这样一个假设：既然能出现这样一个数据分布，那么可以假设在当前的 theta 情况下，出现该数据分布的概率是很大的。因此可以进行最大似然估计。</p>
<p>最大似然的求解可以有两种：分析法，即令微分&#x3D;0；迭代法，即（随机）梯度下降。</p>
<p>基于独立同分布的假设，n 个数据点的概率可以表示为：</p>
<img src="https://s2.loli.net/2022/06/16/YGK2RtiLNy7ZVqW.png" alt="image-20220616212845691" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/25/SHtiPL5NZFBVDQJ.png" alt="image-20220616213531856" style="zoom:50%;" />

<p>问：为什么这里的 p(x_i) 可以表示成1？</p>
<p>问题转化为：</p>
<img src="https://s2.loli.net/2022/06/16/XCvn2zl1wBic5Iq.png" alt="image-20220616213559809" style="zoom:33%;" />

<p>为简便计算，一般求对数 MLE：</p>
<img src="https://s2.loli.net/2022/06/16/mEqR7yvndSDTxCU.png" alt="image-20220616213842804" style="zoom:33%;" />

<p>第一项对于 theta 而言是常数项，省去，故最终优化目标为：</p>
<img src="https://s2.loli.net/2022/06/16/ml7RKP58VQDMBTU.png" alt="image-20220616213936228" style="zoom:33%;" />

<p>等价于：</p>
<img src="https://s2.loli.net/2022/06/16/3ckBP5XQ2s8oZvI.png" alt="image-20220616223835964" style="zoom:33%;" />

<p><strong>如何通过梯度下降求解参数：</strong></p>
<img src="https://s2.loli.net/2022/06/16/kU1puR4iNY7TjKa.png" alt="image-20220616224131196" style="zoom:33%;" />

<img src="https://s2.loli.net/2022/06/16/k6xDJTvgwRCQU57.png" alt="image-20220616224144007" style="zoom:33%;" />

<p>为保证对数似然是凸的，求二阶导（Hessian）矩阵：</p>
<img src="https://s2.loli.net/2022/06/16/XkuaKYjnhz95xpR.png" alt="image-20220616224258646" style="zoom:33%;" />

<p>如果 X 是满秩的，那么 XX 就是正定的，因此 theta_{MLE} &#x3D; minimum。用正则化处理退化情况</p>
<p>令梯度为 0，解得：</p>
<img src="https://s2.loli.net/2022/06/16/N6bi98ATIqmByjK.png" alt="image-20220616224419634" style="zoom:33%;" />

<p>据此可以利用一些矩阵方式求解，方法有 Cholesky Factorization 等。</p>
<p>抑或是梯度下降求解 theta_{MLE}（rho 是学习率）：</p>
<img src="https://s2.loli.net/2022/06/16/KgdqV8P1OoG6j4X.png" alt="image-20220616225107915" style="zoom:33%;" />

<p>其中，对数似然求微分得到的系数 2 被并入 rho。</p>
<p>更好的办法——随机梯度下降：</p>
<img src="https://s2.loli.net/2022/06/16/QxsKiuEzZS548WM.png" alt="image-20220616225520614" style="zoom:33%;" />

<p>在非线性的情况，可以采用非线性变换，如 splines, radial basis functions 等。</p>
<h5 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h5><img src="https://s2.loli.net/2022/06/19/pZSXLig1uB8HQTe.png" alt="image-20220619150432337" style="zoom:33%;" />



<img src="https://s2.loli.net/2022/06/19/fUJOoXMxzVbYiGQ.png" alt="image-20220619150625491" style="zoom:33%;" />

<p>要知道的就是 w，对于 w 的取值，我们可以令：</p>
<p>$$<br>\omega &#x3D; argmax_{\omega} \prod_{l} P(y^l|x^l,w)<br>$$</p>
<p>其中，$$y^l$$ 和 $$x^l$$ 取之于训练集。上式写作 log-likelihood：</p>
<img src="https://s2.loli.net/2022/06/19/fYuy1vN9mRKJl82.png" alt="image-20220619151102221" style="zoom:33%;" />

<p>根据 y 只能取 0 或 1 的性质，把 argmax 右边的 sum 写作下式：</p>
<img src="https://s2.loli.net/2022/06/19/yBqYNAuV8wDoXUc.png" alt="image-20220619151331602" style="zoom: 33%;" />

<p>写出 loss 方程，直接开导！</p>
<img src="https://s2.loli.net/2022/06/19/5XeWJgpL3DmnFUS.png" alt="image-20220619151806127" style="zoom:33%;" />

<p>梯度下降：</p>
<img src="https://s2.loli.net/2022/06/19/PXnCHxJT5Li9kFV.png" alt="image-20220619152345177" style="zoom:33%;" />

<p>加入正则化，防止过拟合的版本：</p>
<img src="https://s2.loli.net/2022/06/19/gMUjNX45zOZL2Af.png" alt="image-20220619152530114" style="zoom:33%;" />



<h4 id="2-过拟合"><a href="#2-过拟合" class="headerlink" title="2. 过拟合"></a>2. 过拟合</h4><p><strong>什么是过拟合</strong></p>
<p>Low training error does not imply good expected performance</p>
<p><strong>降低过拟合的方法</strong></p>
<p>Reduce number of features + Keep all the features, but reduce values of parameters</p>
<p>① 损失函数加入正则项</p>
<p>② k-fold交叉验证</p>
<h4 id="3-训练方法"><a href="#3-训练方法" class="headerlink" title="3. 训练方法"></a>3. 训练方法</h4><blockquote>
<p>什么是过拟合、欠拟合，过拟合：训练集损失函数误差小，测试集大。怎么避免过拟合？加入正则项，使他训练集没那么好，增加模型的延展性；k-折交叉验证的k什么意思，分数据集怎么分，可以随机也可以不随机</p>
</blockquote>
<p>一个衡量模型好坏的指标：</p>
<img src="https://s2.loli.net/2022/06/19/FlpzMatZY5qsQbC.png" alt="image-20220619203215062" style="zoom: 50%;" />



<p><strong>训练集-矫正集-测试集</strong></p>
<img src="https://s2.loli.net/2022/06/19/2uViFwWhag4DAm7.png" alt="image-20220619204433308" style="zoom:33%;" />

<p>使用验证集是为了快速调参，(网络层数，网络节点数，迭代次数，学习率）。另外用验证集还可以监控模型是否异常（过拟合），然后决定是不是要提前停止训练。</p>
<p><strong>留出法（Hold-out method）</strong></p>
<p>把数据集分此训练集(2&#x2F;3)和测试集(1&#x2F;3)，经常使用的情况：有几千个示例，每个类有几百个实例。</p>
<img src="https://s2.loli.net/2022/06/19/e5OIa72Dv4HUfkE.png" alt="image-20220619203443206" style="zoom: 50%;" />



<p>更大的测试集可以得到更精确的错误率估计。</p>
<p>有时有些类的实例很少，此时就要用 Stratified (分层) sample，确保每个类在训练测试集中的比例大致相等，这可以减少模型方差。</p>
<p><strong>Repeated hold-out method</strong> </p>
<p>在每次迭代中，随机选择一定比例数据进行训练（可能分层）。对不同迭代的错误率进行平均，以得出总体错误率。</p>
<p>仍不是最佳：不同的测试集重叠，但我们希望每个数据都被至少测试一次。</p>
<p><strong>k-fold cross validation</strong></p>
<p>① 数据分成 k 等分个子集。② 每次选 k 份中未选择过的一份当测试集，其他训练集。</p>
<p>每个子集在交叉验证就分层过了。总 estimate 就是各次 estimate 的平均。</p>
<p><strong>k-fold cross validation with validation and test sets</strong></p>
<p>这是个稍微不那么精细的方法</p>
<p>① 数据分成 k 等分个子集。② 每次选 k 份中未选择过的一份当测试集，剩余的选个当验证集，其他就是训练集。</p>
<p>最优的 k：10，实验证明可以得到最精确的 estimate。</p>
<p><strong>Bootstrap method</strong></p>
<img src="https://s2.loli.net/2022/06/25/oTNsXG7bHMu6UY3.png" alt="image-20220620102258752" style="zoom: 50%;" />

<p>我们随机地从数据集中抽取出 n 个数据组成一个新的数据集（允许重复）。</p>
<img src="https://s2.loli.net/2022/06/20/v9ZPYdwJLx37Bib.png" alt="image-20220620102505143" style="zoom: 50%;" />

<p>由于只在 63% 的数据集上训练，因此测试集上的 error estimate 不太好，故联合训练集上的 error：</p>
<img src="https://s2.loli.net/2022/06/25/VroIE9T8L3dwCPu.png" alt="image-20220620103213161" style="zoom: 50%;" />

<p>重复以上过程多次，平均结果。</p>
<p>总结：</p>
<p>hold-out method：large data</p>
<p>cross-validation method： middle-sized data</p>
<p>leave-one-out and bootstrap method：small data</p>
<h4 id="4-决策树"><a href="#4-决策树" class="headerlink" title="4. 决策树"></a>4. 决策树</h4><p><img src="https://s2.loli.net/2022/06/25/8XbqAC2ezLvjJYV.png" alt="image-20220620103458461"></p>
<blockquote>
<p>决策树做分类的监督学习算法，熵的定义</p>
</blockquote>
<p><strong>熵的求解</strong></p>
<img src="https://s2.loli.net/2022/06/20/9C2TJaINsQSevrw.png" alt="image-20220620104114188" style="zoom: 50%;" />

<p>$$log(p_i)$$ 定义为信息量。</p>
<h5 id="条件熵的求解"><a href="#条件熵的求解" class="headerlink" title="条件熵的求解"></a>条件熵的求解</h5><p><img src="https://pic1.zhimg.com/80/v2-f925bd0dba2f4584ebd78efea6c9864c_720w.png" alt="img"></p>
<img src="https://s2.loli.net/2022/06/20/NkF7ymxfM2tQYpI.png" alt="image-20220620111606275" style="zoom:50%;" />

<p><strong>求解对应属性的信息增益</strong></p>
<img src="https://s2.loli.net/2022/06/20/LeoA34iYJxOC9Rr.png" alt="image-20220620111639812" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/20/KrRZDhVyWu39jfz.png" alt="image-20220620111705567" style="zoom:50%;" />



<p><strong>决策树的构建</strong></p>
<p>预剪枝，后剪枝</p>
<img src="https://s2.loli.net/2022/06/20/pLagxXGmhu2FeqU.png" alt="image-20220620111819108" style="zoom: 67%;" />



<h4 id="5-SVM"><a href="#5-SVM" class="headerlink" title="5. SVM"></a>5. SVM</h4><p><img src="https://s2.loli.net/2022/06/20/92VxBYKZTsEnmQo.png" alt="image-20220620111901955"></p>
<blockquote>
<p>标准的SVM是个线性的分类器，基本思想：找出一个分界面，让分界面离正负样本的距离最大，不需要背答对了大概意思就行，损失函数怎么定义，不需要会求解，为什么引入核函数，有什么功能</p>
</blockquote>
<p><strong>SVM 的基本思想</strong></p>
<p>找出一个分界面，让分界面（margin）离正负样本（support vector）的距离最大</p>
<p>点到直线的距离：</p>
<img src="https://s2.loli.net/2022/06/20/wSNbjhR3mc1EprZ.png" alt="image-20220620112504919" style="zoom:50%;" />



<p><strong>SVM 的损失函数</strong></p>
<p>Hinge 损失函数</p>
<p>$$<br>L(y, f(x)) &#x3D; [1-yf(x)]<em>+ \<br>z</em>+&#x3D;<br>\begin{cases}<br>z,z \ge 0 \<br>0,z \le 0<br>\end{cases}<br>$$</p>
<img src="https://www.freesion.com/images/712/08b2261140aa01b193bf2546c55926a0.png" alt="在这里插入图片描述" style="zoom: 67%;" />

<p>SVM 的优化目标</p>
<p>$$<br>最小化：\frac{1}{2}||w||^2 + C\sum^{N}_{i&#x3D;1}\delta_i\ \<br>限制条件： (1)\ \delta_i&gt;&#x3D;0,(i&#x3D;1-N)\<br>(2)\ y_i(w^TX_i+b) &gt;&#x3D; 1-\delta_i,(i&#x3D;1-N)<br>$$</p>
<p>SVM 的损失函数</p>
<p>$$<br>\frac{1}{2}||w||^2+C\sum^{N}_{i&#x3D;1}max(0, 1-y_i(wx_i+b))<br>$$</p>
<p>提出公因子 C，等价于</p>
<p>$$<br>\frac{1}{2C}||w||^2+\sum^{N}_{i&#x3D;1}max(0, 1-y_i(wx_i+b))<br>$$</p>
<p>参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/guofei_fly/article/details/102750900">https://blog.csdn.net/guofei_fly/article/details/102750900</a></p>
<p><strong>SVM 中的核函数</strong></p>
<img src="https://s2.loli.net/2022/06/25/6LHme9akUO2ixu1.png" alt="image-20220620113232679" style="zoom:50%;" />

<p>高维非线性计算资源消耗大，故映射到线性低维。</p>
<p>根据对 SVM 优化问题的观察，可以得知数据点只以点积的形式出现：</p>
<img src="https://s2.loli.net/2022/06/20/BCe9FviQfEswd61.png" alt="image-20220620113548007" style="zoom:50%;" />

<p>因此，无需考虑具体的映射 phi 函数的形式，只需要考虑核函数：</p>
<img src="https://s2.loli.net/2022/06/20/ztsNlJa7D8wkEyi.png" alt="image-20220620113646068" style="zoom:50%;" />

<p>举例而言：</p>
<img src="https://s2.loli.net/2022/06/25/lsecmURo8HkL6Vi.png" alt="image-20220620113739303" style="zoom:50%;" />

<p>要求核函数满足 Mercer function，即要求正定（对于nxn的矩阵，entry[i,j]&#x3D;K(xi,xj)）。</p>
<p>基本的核函数：</p>
<img src="https://s2.loli.net/2022/06/20/CyiWNYSKzEPBArJ.png" alt="image-20220620114131555" style="zoom:50%;" />



<h4 id="6-PCA"><a href="#6-PCA" class="headerlink" title="6. PCA"></a>6. PCA</h4><p><img src="https://s2.loli.net/2022/06/20/bIlwEBOWS9N2Hzu.png" alt="image-20220620114523211"></p>
<blockquote>
<p>PCA基本思想：降维，把最关键的维度找出来。PCA无监督的。</p>
<p>PCA三种理解的角度：通过重构误差最小推出PCA的定义公式；通过方差最大的思想推出PCA；通过奇异值分解的方法推出PCA。</p>
<p>PCA有进行一些假设约束，如两两方向之间正交。推导过程要知道，比如PCA重构误差的推导。PCA有什么缺点：要求方向正交，而这不一定是合理的。</p>
</blockquote>
<p><strong>PCA 的基本思想</strong></p>
<p>降维，把最关键的维度找出来，以代表大部分的信息。</p>
<p><strong>PCA 的三种理解角度</strong>：最小重构误差</p>
<p>正交的概念：</p>
<img src="https://s2.loli.net/2022/06/25/q67d8aQrOHNEWu4.png" alt="image-20220620164104895" style="zoom:50%;" />

<p>正交定理（举个例子就能理解，$$\alpha_{i}$$ 类似投影长度）：</p>
<img src="https://s2.loli.net/2022/06/20/JY8tlMweoGU1CAW.png" alt="image-20220620164120492" style="zoom: 50%;" />

<img src="https://s2.loli.net/2022/06/20/f3mq5YuFBtTV6SA.png" alt="image-20220620164410215" style="zoom:50%;" />

<p>当前的目标，就是找到这几个正交向量，以最好  地表示原数据。</p>
<p>PCA(主成分分析)所对应的数学理论是 SVD。而奇异值分解本身是完全不需要对矩阵中的元素做标准化或者去中心化的。但是对于机器学习，我们通常会对矩阵（也就是数据）的每一列先进行标准化。</p>
<img src="https://s2.loli.net/2022/06/20/Dq8LxuJfKAXYrNb.png" alt="image-20220620200743365" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/20/WZyETCcNzKkUD54.png" alt="image-20220620200758681" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/20/q83lrapPHICT5Vx.png" alt="image-20220620200813328" style="zoom:50%;" />

<p>Frobenius norm</p>
<p>$$<br>||X||<em>{F} &#x3D; \sqrt{\sum</em>{i} \sum_j X_{i,j}^2}<br>$$</p>
<img src="https://s2.loli.net/2022/06/20/SBcbvxlTGajD281.png" alt="image-20220620200824009" style="zoom:50%;" />



<img src="https://s2.loli.net/2022/06/20/IwqFd2GLfZNYUEo.png" alt="image-20220620200848625" style="zoom:50%;" />



<img src="https://s2.loli.net/2022/06/20/EAeJ5HyxTLpagX8.png" alt="image-20220620201027218" style="zoom:50%;" />



<p><strong>PCA 的三种理解角度</strong>：最大化方差</p>
<p><img src="https://pic3.zhimg.com/80/v2-0c361ad3dbb56d96e0ed85fbb6701a06_720w.jpg" alt="img"></p>
<p>最大化方差等价于尽可能多地保留原始数据的信息。</p>
<p>以其中一个投影坐标方向 $$u_1$$ 为例，求其方差表达式：</p>
<img src="https://s2.loli.net/2022/06/20/EiQzg76lsfRMBah.png" alt="image-20220620201121960" style="zoom: 50%;" />

<p>类似前文所述，要使的 var 最大，等价于让 $$u_1$$ 是 S 的那个最大特征值的特征向量。</p>
<p><strong>PCA 的三种理解角度</strong>：SVD 分解</p>
<img src="https://s2.loli.net/2022/06/20/q9BjcKtP6ICi5rp.png" alt="image-20220620201616504" style="zoom: 50%;" />

<img src="https://s2.loli.net/2022/06/25/my1vuTYa5Wz8JGp.png" alt="image-20220620201650161" style="zoom:50%;" />



<h4 id="7-聚类"><a href="#7-聚类" class="headerlink" title="7.  聚类"></a>7.  聚类</h4><p><img src="https://s2.loli.net/2022/06/25/UYWsd43SkaAEblO.png" alt="image-20220620201752216"></p>
<blockquote>
<p>k是什么？k个聚类。初始选取的k个点可以是随机的也可以是自己定义的。kmeans为什么可以收敛？可以通过实验的方法来了解k的选取。不同的初始状态会导致不同的结果。</p>
</blockquote>
<p><strong>K-Means 聚类的思想</strong></p>
<p>在数据集中根据一定策略选择K个点作为每个簇的初始中心，然后将数据划分到距离这K个点最近的簇中，但形成的新簇并不一定是最好的划分，因此生成的新簇中，重新计算每个簇的中心点，然后在重新进行划分，直到每次划分的结果保持不变。</p>
<p><strong>K-Means 聚类的步骤</strong></p>
<p>① Ask user how many clusters they’d like.</p>
<p>② Randomly guess k cluster Center locations</p>
<p>③ Each datapoint finds out which Center it’s closest to.</p>
<p>④ Each Center finds the centroid of the points it owns</p>
<p>⑤ Jumps to ③，Repeat until terminated!</p>
<p><strong>K-Means 聚类的目标函数</strong></p>
<img src="https://s2.loli.net/2022/06/21/1jMsx9iXITu3gLA.png" alt="image-20220621195837743" style="zoom:50%;" />

<p>$$Encode(x_i)$$ 可以理解为把数据点 $$x_i$$ 归到第几个聚类，$$Decode[j]$$ 可以理解为把第 j 个聚类的中心 $$c_j$$。</p>
<p>要最小化 Distortion。① 这就要求 $$x_i$$ 必须被归到离他最近的聚类。② 同时，还要求对 $$c_j$$ 对 Distortion 的偏微分都为 0：</p>
<img src="https://s2.loli.net/2022/06/21/SM9Nbs16FlmLtHB.png" alt="image-20220621200517118" style="zoom:50%;" />

<p>满足 minimum 的情况，也就是满足 $$c_j$$ 是该聚类中的点的均值的情况。</p>
<p>① 和 ② 连续操作没意义，但是交替操作就很有意义，这即是 K-means。为什么可以收敛呢？</p>
<p>有限个点分到有限个聚类里，这样配置&#x2F;聚类的可能情况是有限的。同时，当配置改变，意味着得到了更好的 Distortion。每次改变都是更好的配置，如果一直改变，迟早会用光所有的配置。</p>
<p>不一定能全局最优。因此，谨记：选好初始值，或者跑多次不一样的k-means。</p>
<p>对选好初始值的一种可行方案：首先随便选个数据点做聚类中心，之后选的聚类中心尽可能选离所有已选聚类中心远的数据点。</p>
<p><strong>K-Means 聚类的 K 的选取</strong></p>
<p>常规方法：最小化 Schwarz Criterion (also related to the BIC, schwarz’s bayesian criterion (bic))</p>
<img src="https://s2.loli.net/2022/06/21/Nr6iYRcZe8BKOnh.png" alt="image-20220621201736841" style="zoom: 50%;" />





<h4 id="8-EM-算法"><a href="#8-EM-算法" class="headerlink" title="8. EM 算法"></a>8. EM 算法</h4><p>背景——欲解决的问题</p>
<img src="https://s2.loli.net/2022/06/21/8smHPfpizQuCMGd.png" alt="image-20220621202550971" style="zoom:50%;" />

<p><strong>E 步</strong> + <strong>M 步</strong></p>
<img src="https://s2.loli.net/2022/06/21/fItr2GPplesRZyV.png" alt="image-20220621211812481" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/21/E6PnbiGUND3I8aS.png" alt="image-20220621211829792" style="zoom:50%;" />

<p>理论推导：</p>
<p>先重新表达所要优化的对数似然函数：</p>
<img src="https://s2.loli.net/2022/06/25/J47MrBzUauFkNV8.png" alt="image-20220621203424720" style="zoom:50%;" />



<img src="https://s2.loli.net/2022/06/21/pFKkdUzD7rxcEGS.png" alt="image-20220621212332088" style="zoom:50%;" />



<img src="https://s2.loli.net/2022/06/21/XLMBO2mAv9Z6jtY.png" alt="image-20220621212346646" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/25/RHqwNm8ICAYnyc1.png" alt="image-20220621212358971" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/21/KSPc1XvpboqmU9e.png" alt="image-20220621212426612" style="zoom:50%;" />

<p>强烈建议结合浙大的课程一起复习！</p>
<p><strong>EM 算法一般形式</strong></p>
<p>① 随机选取 $$\theta_0$$</p>
<p>② E-step</p>
<p>$$<br>Q_i(z_i) &#x3D; P(z_i|x_i, \theta_k) &#x3D; \frac{P(z_i,x_i|\theta_k)}{P(x_i|\theta_k)}&#x3D;\frac{P(z_i,x_i|\theta_k)}{\sum_{z_i} P(z_i, x_i|\theta_k)}<br>$$</p>
<p>③ M-step</p>
<p>$$<br>\theta_{k+1}&#x3D;argmax_{\theta} \sum_{i&#x3D;1}^{N} \sum_{z_i}Q_i(z_i) log\frac{P(z_i,x_i|\theta_k)}{Q_i(z_i)}<br>$$</p>
<p>④ 回到 ②，直至收敛。</p>
<p><strong>高斯混合聚类算法的思想和步骤</strong></p>
<p>一种 soft(fuzzy) 的聚类</p>
<p>实现思想：根据 EM 算法，针对每个数据点，为之分配属于每个聚类的概率</p>
<p>高斯分布</p>
<img src="https://s2.loli.net/2022/06/22/CqPZydVhtUkpaj6.png" alt="image-20220622150629542" style="zoom:50%;" />

<p>高斯分布的均值与方差：</p>
<img src="https://s2.loli.net/2022/06/22/q1pVILjWGrEba4h.png" alt="image-20220622150851026" style="zoom:50%;" />

<p>开始极大似然估计：</p>
<img src="https://s2.loli.net/2022/06/22/1RAtDoiS8hKf3F6.png" alt="image-20220622150709006" style="zoom:50%;" />

<p>转为对数似然估计：</p>
<img src="https://s2.loli.net/2022/06/22/Ox84ADUYJquFtQs.png" alt="image-20220622150728816" style="zoom:50%;" />

<p>E 步 —— 求出数据点属于每个聚类的比重：</p>
<img src="https://s2.loli.net/2022/06/22/hIHJOAWxZKsqv6C.png" alt="image-20220622151427673" style="zoom:50%;" />

<p>M 步 —— 更新高斯分布的参数：</p>
<img src="https://s2.loli.net/2022/06/25/YGpvCBXmrwZWxAJ.png" alt="image-20220622151501063" style="zoom:50%;" />

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/85338773">https://zhuanlan.zhihu.com/p/85338773</a></p>
<h4 id="9-推荐系统"><a href="#9-推荐系统" class="headerlink" title="9. 推荐系统"></a>9. 推荐系统</h4><p><img src="https://s2.loli.net/2022/06/22/a2qrV1MUFRLeo5v.png" alt="image-20220622160643079"></p>
<blockquote>
<p>打分矩阵L分解成用户矩阵U和item矩阵I，然后可以用梯度下降求，目标函数怎么定义？U*I的结果尽可能接近L。<br>基于用户：得到打分矩阵，计算相似度量公式，计算两两相似度，找出k个最像的用户，计算打分。<br>基于商品：有时候用户很多，但商品数量有限。得到打分矩阵，确定一个商品之间相似度的度量公式。<br>基于内容：考察商品之间的相似度，不仅考虑打分，还考虑商品的描述内容。<br>冷启动：概念，新用户进来很难对其进行推荐，新商品进来不知道跟哪些商品相似，难以推荐新商品。<br>数据稀疏的问题：打分矩阵的数据是很稀疏的。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28577447">https://zhuanlan.zhihu.com/p/28577447</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_58535145/article/details/122651843">SVD 分解</a></p>
<p><strong>基于矩阵分解的推荐系统</strong> </p>
<p>打分矩阵 L 分解成用户矩阵 U 和商品矩阵 I，然后可以用梯度下降求，目标函数怎么定义？U * I 的结果尽可能接近 L。</p>
<img src="https://s2.loli.net/2022/06/29/1eIBCKohqjzwUGQ.png" alt="image-20220629102319437" style="zoom:50%;" />



<p><strong>基于用户的协同推荐</strong></p>
<p><img src="https://s2.loli.net/2022/06/29/15cNKrYSz67Tte8.png" alt="image-20220629094502874"></p>
<p>根据打分矩阵，计算相似度量公式</p>
<img src="https://s2.loli.net/2022/06/22/UImglxuAvd8YGoq.png" alt="image-20220622182448962" style="zoom:50%;" />

<p>观察 sim(a, b)，其实就是相关系数（Pearson correlation）的计算。</p>
<img src="https://s2.loli.net/2022/06/25/m9vDk6iMAcpF8OQ.png" alt="image-20220622185202056" style="zoom:50%;" />

<p>问题：可能会导致只给出一些特定的 items。</p>
<p>解决：对差异较大的项目给予更多权重；significance weighting；Case amplification。</p>
<p>总结：memory-based，不适用现实场景，现实中这个矩阵太大。</p>
<p><strong>基于商品的协同推荐</strong></p>
<p><img src="https://s2.loli.net/2022/06/29/G6u4xBhybcMfo9r.png" alt="image-20220629094512656"></p>
<img src="https://s2.loli.net/2022/06/25/IA8ZXt6OnjYUkhq.png" alt="image-20220622185916132" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/25/Ayaqb8OCjeBhSxn.png" alt="image-20220622191033984" style="zoom:50%;" />



<p><strong>基于内容的协同推荐</strong></p>
<p>基本思想：根据推荐物品或内容的元数据，发现物品或者内容的相关性，然后基于用户以往的喜好记录，推荐给用户相似的物品。即考察商品之间的相似度，不仅考虑打分，还考虑商品的描述内容。</p>
<p>应用：电影 A 和 C 的类型都是爱情和浪漫，那么就会给看过电影 A 的人推荐电影 C。</p>
<p><strong>冷启动问题</strong></p>
<img src="https://s2.loli.net/2022/06/25/3r2tRfuQJYW1967.png" alt="image-20220622190514423" style="zoom:50%;" />



<p><strong>数据稀疏的问题</strong></p>
<img src="https://s2.loli.net/2022/06/25/unjKe5YSromxyRG.png" alt="image-20220622190602455" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/06/25/8TADf4nGsN1Vemo.png" alt="image-20220622190618711" style="zoom:50%;" /></p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><a class="tag" href="/categories/courses/" title="courses">courses </a><span class="leancloud_visitors"></span><span>About 3836 words, 12 min 47 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2022/07/06/machine-learning/2022-07-06-review-pattern-recognition-courses/">[ml][rv] pattern recognition</a></h3></div><div class="post-content"><div class="card"><p><h3 id="1-总览"><a href="#1-总览" class="headerlink" title="1. 总览"></a>1. 总览</h3><img src="https://s2.loli.net/2022/06/25/NcpDeYXjQLCB7wb.png" alt="image-20220625120156682" style="zoom: 67%;" />

<p><strong>考核形式</strong></p>
<p>主要考对概念的一些理解，例如说偏置方差分解和过拟合欠拟合之间的关系</p>
<p>计算有但不是太多</p>
<p>在理解的基础上对算法进行记忆，比如 PCA &amp; LDA，他们的目标函数优化这些都是要知道的</p>
<h3 id="2-提取特征"><a href="#2-提取特征" class="headerlink" title="2. 提取特征"></a>2. 提取特征</h3><blockquote>
<p>提取特征：Normalization(Chap. 9), PCA(Chap. 5), FLD(Chap. 6), Sparse(Chap. 11), …<br>PCA 无监督，FLD 有监督地利用标签去提取特征的方法<br>Sparse 没有详细地去讲</p>
</blockquote>
<h4 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h4><img src="https://s2.loli.net/2022/06/25/Vu6rQ4LS8Rylxvb.png" alt="image-20220625122340062" style="zoom: 67%;" />

<img src="https://s2.loli.net/2022/06/25/OfLYdTHaN3JwQX8.png" alt="image-20220625122352658" style="zoom:67%;" />

<p>可以把范围从 [0, 1] 拉伸至任意范围。</p>
<p>如果某一维度的最大值等于最小值，这个维度的数据可以丢掉。</p>
<p>如果 0 值在原始数据中代表 “空”，那么应该把它规范成0。</p>
<p>如果测试样例的数据范围大于 0 或 大于 1，有时候算法必须要求 [0, 1]，那么可以把小于 0 的值设为 0，大于 1 同理，如果算法不要求其实也可以这么做。</p>
<p>如果能看出某维数据符合高斯分布，那么也可以化为标准高斯分布：</p>
<img src="https://s2.loli.net/2022/06/25/5P1Z49mjxLMqrBH.png" alt="image-20220625122726742" style="zoom: 67%;" />

<p>L-1 规范化：如果值非负，规范化后样例各维之和为 1</p>
<img src="https://s2.loli.net/2022/06/25/cNhxoSBs9TGaEyZ.png" alt="image-20220625122931565" style="zoom:67%;" />

<p>L-2 规范化：把数据规范化为单位向量</p>
<img src="https://s2.loli.net/2022/06/25/G9Fc2trETn1ZvoU.png" alt="image-20220625122925127" style="zoom:67%;" />

<h4 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h4><p>首先要会做 SVD 分解。</p>
<img src="https://s2.loli.net/2022/06/25/Hn4AO2M1Ze8hL9v.png" alt="image-20220625155915036" style="zoom: 67%;" />

<p><img src="https://s2.loli.net/2022/06/25/3rj7boJ9OiTKktw.png" alt="image-20220625155923920"></p>
<h4 id="FLD"><a href="#FLD" class="headerlink" title="FLD"></a>FLD</h4><p>思想：把数据点进行投影，使得不同类别之间的数据距离尽可能大。</p>
<p> <img src="https://s2.loli.net/2022/06/25/oudrltBzY3psvSE.png" alt="image-20220625160821944" style="zoom: 50%;" />     <img src="https://s2.loli.net/2022/06/25/v5VHwi7oY9ELePM.png" alt="image-20220625162319955" style="zoom: 50%;" /></p>
<p>可分性的绝对要素：两个均值之间的距离 + 两个标准差。要实现分类，就需要最大化这二者的比例。</p>
<p>注：PCA 和 FLD 中的 X 的尺寸都是 (dim x 1) 。因而，$$a^Ta$$ 的结果是一个值，$$aa^T$$ 的结果是一个矩阵。</p>
<p>二分类的 FLD：</p>
<img src="https://s2.loli.net/2022/06/25/1UghbLr4SEZizaY.png" alt="image-20220625165356810" style="zoom: 50%;" />

<p>$$w$$：投影方向</p>
<p>$$m_i$$ ：集合 i 的均值</p>
<p>$$C_i$$ ：集合 i 的协方差矩阵</p>
<p>$$<br>C_i &#x3D; \frac{1}{N_i} \sum_{x \in X_i} (x-m_i)(x-m_i)^T<br>$$</p>
<p>传统 FLD 用散度矩阵而不是用协方差矩阵，散度矩阵 $$S_i &#x3D; N_iC_i$$</p>
<p>类间散度矩阵 &amp; 类内散度矩阵：</p>
<p>$$<br>S_B&#x3D;(m_1-m_2)(m_1-m_2)^T \<br>S_W &#x3D; S_1+S_2<br>$$</p>
<p>目标函数（第一行的 m 是投影后的均值，第二行的 m 是向量）：</p>
<p>$$<br>J &#x3D; \frac{(m_1-m_2)^2}{\sigma_1^2+\sigma_2^2} \<br>&#x3D; \frac{(m_1^T w-m_2^Tw) ^ 2}{\sigma_1^2+\sigma_2^2} \<br>&#x3D; \frac{w^T(m_1-m_2)(m_1-m_2)^Tw}{w^T(C_1+C_2)w} \<br>&#x3D; \frac{w^TS_Bw}{w^TS_Ww} \<br>$$</p>
<p>如果一个均值向量扮演了所属类别的所有样本的代理，那么就可以用均值向量集合的散度矩阵代替 $$S_B$$</p>
<p>$$<br>\sum^{2}_{i&#x3D;1}(m_i - \overline{m})(m_i - \overline{m}) ^T \<br>\overline{m} &#x3D; \frac{m_1+m_2}{2}<br>$$</p>
<p>之后就可以计算以及规范化了。</p>
<p>考虑至多类别呢？</p>
<p>类内散度矩阵 </p>
<p>$$<br>S_W &#x3D; \sum ^{K}<em>{k&#x3D;1} S_k &#x3D; \sum ^{K}</em>{k&#x3D;1}N_kC_k &#x3D; \sum ^{K}<em>{k&#x3D;1} \sum</em>{x \ in X_k}(x-m_i)(x-m_i)^T<br>$$</p>
<p>总散度矩阵</p>
<p>$$<br>S_T &#x3D; \sum ^{N}<em>{i&#x3D;1}(x_i-m)(x_i-m)^T \<br>m &#x3D; \frac{1}{N} \sum^{N}</em>{i&#x3D;1}x_i<br>$$</p>
<p>类间散度矩阵</p>
<p>$$<br>S_B &#x3D;\sum ^{K}_{k&#x3D;1}N_k(m_k-m)(m_k-m)^T<br>$$</p>
<p>规律：总散度矩阵 &#x3D;  类内散度矩阵 + 类间散度矩阵。</p>
<p>多分类问题中，类间散度矩阵不再是秩为 1 的矩阵，算法 6.1 不可用，故求解如下广义特征值问题来找最佳投影方向：</p>
<p>$$<br>S_B w &#x3D; \lambda S_W w<br>$$</p>
<p>当 $S_W$ 可逆，广义特征值问题等价于：</p>
<p>$$<br>S_W ^ {-1} S_B w &#x3D; \lambda  w<br>$$</p>
<p>那么如何找更多投影方向（降低更多维度）呢？类似 PCA，只要使用与前 K-1 个最大广义特征值对应的广义特征向量即可</p>
<h4 id="Sparse"><a href="#Sparse" class="headerlink" title="Sparse"></a>Sparse</h4><p>含义：最小化 $$l_0$$$ norm（向量 x 的非零元素个数）</p>
<p>$$<br>minimize\  ||x||_0 \<br>subject\ to\ Ax&#x3D;y<br>$$</p>
<h3 id="3-分类器"><a href="#3-分类器" class="headerlink" title="3. 分类器"></a>3. 分类器</h3><blockquote>
<p>分类器：kNN, SVM, Decision Tree, Ensemble, Regression, NN, CNN<br>kNN, SVM 前两个重要，后面都是简单提一下<br>CNN 也可以看作是个特征提取的方法</p>
</blockquote>
<h4 id="kNN（机器学习）"><a href="#kNN（机器学习）" class="headerlink" title="kNN（机器学习）"></a>kNN（机器学习）</h4><p>理解且会用</p>
<p>缺陷以及解决办法</p>
<ol>
<li><p>出现平局：可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。</p>
</li>
<li><p>离群点</p>
</li>
</ol>
<p>复杂度 O(nd) [d是计算距离的代价]</p>
<h4 id="SVM（机器学习）"><a href="#SVM（机器学习）" class="headerlink" title="SVM（机器学习）"></a>SVM（机器学习）</h4><h4 id="Decision-Tree-Regression（机器学习）"><a href="#Decision-Tree-Regression（机器学习）" class="headerlink" title="Decision Tree + Regression（机器学习）"></a>Decision Tree + Regression（机器学习）</h4><h4 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h4><h4 id="NN"><a href="#NN" class="headerlink" title="NN"></a>NN</h4><h4 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h4><h3 id="4-概率模型"><a href="#4-概率模型" class="headerlink" title="4. 概率模型"></a>4. 概率模型</h3><blockquote>
<p>概率模型 (Chap. 8)：参数估计，非参，HMM，GMM<br>参数估计：点估计，贝叶斯估计，HMM<br>非参数估计：KDE<br>要知道 HMM 的隐马尔可夫性质 + 要知道 GMM 的概念</p>
</blockquote>
<p>概率模型：计算变量的概率或者概率分布的模型。</p>
<p>参数估计：假设 PDF 服从某种函数形式，当指定其所有参数值之后，PDF 就完全确定，估计 PDF 就是估计参数。</p>
<p>非参数估计：非参数不代表无参数（允许无限），用训练数据直接估计空间中任意点的密度 p(x|D)。</p>
<p>生成模型：估计 p(x|y&#x3D;i) 和 p(y&#x3D;i)，根据贝叶斯定理求 p(y&#x3D;i|x)</p>
<p>判别模型：直接估计 p(y&#x3D;i|x)</p>
<p>这些模型都有两个步骤：推理和决策，分别是估计各种密度函数，根据估计得到的PDF对任意的？给出输出。</p>
<h4 id="点估计（参）"><a href="#点估计（参）" class="headerlink" title="点估计（参）"></a>点估计（参）</h4><p>点估计（point estimation）是用样本统计量来估计总体参数，典型的如 MLE 和 MAP，把 $$\theta$$ 视作固定参数，目的是找这个最佳参数。</p>
<p>p(D|theta) 不是 PDF，但 p(x|theta) 是。</p>
<p>likelihood function of MLE：</p>
<p>$$<br>l(\theta) &#x3D; p(D|\theta) &#x3D; \prod_{i}p(x_i|\theta)<br>$$</p>
<p>高斯分布的最大似然估计，可以通过对 $ll(\theta)$ 求偏微分得到结果：</p>
<p>$$<br>\mu &#x3D; \frac{1}{n} \sum^{n}<em>{i&#x3D;1}x_i \<br>\sigma^2 &#x3D; \frac{1}{n} \sum^{n}</em>{i&#x3D;1}(x_i-\mu)(x_i-\mu)^T<br>$$</p>
<p>最大后验估计（MAP）：把参数 theta 自身的取值可能性考虑进来。如果一无所知就等价于 MLE。</p>
<p>$$<br>\theta &#x3D; argmax_{\theta} l(\theta)p(\theta)<br>$$</p>
<p>渐进性质（asymptotic property），如一致性（consistency）：随样本容量增大收敛到参数真值的估计量</p>
<p>其他性质，无偏估计（unbiased estimate）：指估计量的期望和被估计量的真值相等</p>
<p>完成 inference 后，如何决策？根据参数得到后验概率 p(y|x;theta) 得出结果，在 0-1 风险时，选择概率大的就行。</p>
<img src="https://s2.loli.net/2022/06/29/rTozyVmcjG6n1RC.png" alt="image-20220625193547900" style="zoom: 33%;" />

<h4 id="贝叶斯估计（参）"><a href="#贝叶斯估计（参）" class="headerlink" title="贝叶斯估计（参）"></a>贝叶斯估计（参）</h4><p>点估计是把 $\theta$ 看成固定参数，而贝叶斯估计 p(theta|D) 是估计一个 $$\theta$$ 的分布，而不是一个值（点）！</p>
<p>高斯分布参数的贝叶斯估计：设参数 theta 的先验分布 p(theta)，数据 X &#x3D; {x1, … , xn}，估计 p(theta|D)。这里假设单变量，只估计 p(theta|D) 的高斯分布的均值 mu，方差 sigma^2 已知：</p>
<ol>
<li><p>根据已知的先验高斯分布 P(theta) &#x3D; N(mu0, sigma0^2)</p>
</li>
<li><p>根据贝叶斯定理和独立性，可以得 p(theta|D) &#x3D;</p>
</li>
</ol>
<img src="https://s2.loli.net/2022/06/25/9nU37YI5kqDdj8A.png" alt="image-20220625191741658" style="zoom:50%;" />

<p>估计均值 &amp; 方差为：</p>
<img src="https://s2.loli.net/2022/06/29/mwhWvl2gLouRy8a.png" alt="image-20220625192656515" style="zoom:50%;" />

<p>共轭先验conjugate prior：若 p(x|theta) ，存在先验 p(theta)，使得 p(x|theta) 和 p(theta) 有相同的函数形式，从而简化推导和计算。如高斯分布的共轭先验分布仍然是高斯分布。</p>
<p>完成 inference 后，如何决策？输出一个分布，结果通常根据期望决定。</p>
<h4 id="KDE（非参）"><a href="#KDE（非参）" class="headerlink" title="KDE（非参）"></a>KDE（非参）</h4><p>常用的参数形式基本都是单模的，不足以描述复杂的数据分布。因此应该直接以训练数据自身来估计分布。</p>
<p>例：直方图。每维 n 个bin，那么 n 维应该保存多少个bin的参数？$$n^d$$。太大了，且不光滑！</p>
<p>给定一组提取于未知分布 p(x) 的数据 $x_1,x_2,…,x_n$ ，任一点 x 处的核密度估计定义为：</p>
<p>$$<br>\hat{p}(x) &#x3D; \frac{1}{nh} \sum^{n}_{i&#x3D;1}K(\frac{x-x_i}{h})<br>$$</p>
<p>$$<br>K(x) \ge0, \int K(x)dx&#x3D;1<br>$$</p>
<p>KDE 核函数与 SVM 的不同：在概率估计中被用于估计目标点周围的概率密度。而在SVM中，被用于计算两点间的核空间距离。</p>
<img src="https://s2.loli.net/2022/06/25/OzKfk6DU5dah1Ng.png" alt="image-20220625193832796" style="zoom: 33%;" />

<p>连续的。</p>
<p>窗宽确定：使得估计的积分均方误差 (mean integral square error,MISE) 达到最小，如下式</p>
<p>$$<br>MISE{\hat{p}<em>h(x)}&#x3D;E[\int^{\inf}</em>{-\inf}{\hat{p}_h(x)-p(x)}dx]<br>$$</p>
<h4 id="HMM（机器学习）"><a href="#HMM（机器学习）" class="headerlink" title="HMM（机器学习）"></a>HMM（机器学习）</h4><p><strong>隐马尔可夫性质</strong></p>
<p>$$P(X_t|X_{1:t-1})&#x3D;P(X_t|X_{t-1})$$ ，无记忆性，当前状态的只跟上一个状态有关系。</p>
<p><strong>随机过程（stochastic process）</strong></p>
<p>$${X(t), t\in T}$$ 是一系列随机变量的集合，用于描述一些过程的时间进化，目的是希望过去对现在有帮助。也就是说，对于每个 $$t \in T$$, $$X(t)$$ 是一个随机变量。索引 t 通常被解释为时间，因此把 $$X(t)$$ 作为 t 时流程的状态。</p>
<p>B：emission probability 发出观察值的概率。$$b_j(k)&#x3D;Pr(O_t&#x3D;V_k|Q_t&#x3D;S_j)$$。当未知状态为 $$S_j$$ 时观察到为 $$V_k$$ 的概率。</p>
<p><strong>Problem 1. Evaluation</strong></p>
<p>概念：给定已知 $$\lambda &#x3D; (A,B,\pi)$$ 的 HMM 模型，以及一个完整的输出序列 $$o&#x3D;o_{1:T}$$，求该模型观察到该输出序列的概率 $$P(O|\lambda)$$。</p>
<p>作用：看出此模型对该观察序列的成绩，从而在多个模型中选择最适合的模型。</p>
<p>算法</p>
<ol>
<li>Naive</li>
</ol>
<p>假设隐状态序列 $q_{1:T}$ 已知：</p>
<p>$$<br>Pr(o_{1:T}|\lambda, q_{ 1:T}) &#x3D; \prod^{T}<em>{t&#x3D;1}Pr(o_t|q_t, \lambda) &#x3D; \prod^{T}</em>{t&#x3D;1}b_{q_i}(o_i)<br>$$</p>
<p>则必有</p>
<p>$$<br>Pr(o_{1:T}|\lambda) &#x3D; Pr(o_{1:T}, q_{1:T}|\lambda) &#x3D;\sum_{all\ Q}Pr(o_{1:T}|\lambda, q_{ 1:T})Pr(q_{1:T}|\lambda)<br>$$</p>
<p>时间复杂度 $$O(TN^T)$$</p>
<ol start="2">
<li>对 Naive 的观察与优化——提取 $$b_i(o_i)$$</li>
</ol>
<p>$$<br>Pr(o_{1:T}|\lambda)&#x3D;\sum_{i&#x3D;1}^{N}Pr(o_{1:T},Q_T&#x3D;S_i|\lambda)\<br>&#x3D;\sum_{i&#x3D;1}^{N}Pr(o_{1:T-1},Q_T&#x3D;S_i|\lambda)Pr(O_T&#x3D;V_k|Q_T&#x3D;S_i,\lambda)\<br>&#x3D;\sum_{i&#x3D;1}^{N}Pr(o_{1:T-1},Q_T&#x3D;S_i|\lambda)b_i(o_T)<br>$$</p>
<ol start="3">
<li>对 Naive 的观察与优化——提取 $$A_{ji}$$</li>
</ol>
<p>$$<br>Pr(o_{1:T-1},Q_T&#x3D;S_i|\lambda) &#x3D; \sum_{j&#x3D;1}^{N}Pr(o_{1:T-1},Q_{T-1}&#x3D;S_j|\lambda)A_{ji}<br>$$</p>
<p>根据 2. 和 3. 的提取优化，可得</p>
<p>$$<br>Pr(o_{1:T}|\lambda)&#x3D;\sum_{i&#x3D;1}^{N}Pr(o_{1:T},Q_T&#x3D;S_i|\lambda)\<br>&#x3D;\sum_{i&#x3D;1}^{N}Pr(o_{1:T-1},Q_T&#x3D;S_i|\lambda)b_i(o_T)\<br>&#x3D;\sum_{i&#x3D;1}^{N}(b_i(o_T)\sum_{j&#x3D;1}^{N}Pr(o_{1:T-1},Q_{T-1}&#x3D;S_j|\lambda)A_{ji}) \<br>$$</p>
<ol start="4">
<li>前向算法 forward</li>
</ol>
<p>定义 $$\alpha_{t}(i)&#x3D;Pr(o_{1:t},Q_t&#x3D;S_i|\lambda)$$。含义：对于已知参数 $$\lambda$$ 的模型，获得观测序列 $$o_{1:T}$$ 且 t 时刻隐状态为 $$S_i$$ 的概率。</p>
<p>初始化：$$\alpha_1(i)&#x3D;Pr(o_{1},Q_1&#x3D;S_i|\lambda) &#x3D; Pr(Q_1&#x3D;S_i|\lambda)Pr(o_{1}|Q_1&#x3D;S_i,\lambda) &#x3D; Pr(Q_1&#x3D;S_i|\lambda)b_i(o_1)$$</p>
<p>前向递推：</p>
<p>$$<br>\alpha_{t+1}(i)&#x3D;[\sum^{N}<em>{j&#x3D;1} Pr(o</em>{1:t},Q_t&#x3D;S_j|\lambda)A_{ji}]b_i(o_{t+1})\<br>&#x3D;[\sum^{N}<em>{j&#x3D;1} a</em>{t}(j)A_{ji}]b_i(o_{t+1})<br>$$</p>
<p>结果：$$Pr(o_{1:T}|\lambda)&#x3D;\sum^{N}<em>{i&#x3D;1}Pr(o</em>{1:T},Q_T&#x3D;S_i|\lambda)&#x3D;\sum^{N}_{i&#x3D;1} \alpha_T(i) $$</p>
<p>复杂度：$$O(TN^2)$$</p>
<p>⑤ 后向算法 backward</p>
<p>定义 $$\beta_t(i) &#x3D; Pr(o_{t+1:T}|Q_t&#x3D;S_i, \lambda)$$。含义：对于已知参数 $$\lambda$$ 的模型，已知 t 时刻状态为 $$S_i$$，未来观测到 $$o_{t+1:T}$$ 的概率。</p>
<p>初始化：$$\beta_T(i) &#x3D; 1$$。</p>
<p>反向更新：</p>
<p>$$<br>\beta_t(i) &#x3D; \sum^{N}<em>{j&#x3D;1}A</em>{ij}b_j(o_{t+1})\beta_{t+1}(j)<br>$$</p>
<p>输出：$$Pr(o_{1:T}|\lambda)&#x3D;\sum^{N}<em>{i&#x3D;1}\pi</em>{i}b_i(o_{1})\beta_{1}(i)$$</p>
<p><strong>Problem 2：Decoding</strong></p>
<p>概念：给定已知 $$\lambda &#x3D; (A,B,\pi)$$ 的 HMM 模型，以及一个完整的输出序列 $$o&#x3D;o_{1:T}$$，求一个完全指定的隐变量序列 $$q_{1:T}$$ 的值。</p>
<p>作用：语音识别中状态可能有实际意义（各音节），可以用来观察模型结构，优化模型。</p>
<p>算法：</p>
<img src="https://s2.loli.net/2022/06/29/LWcKyRP9Zk8xB4Y.png" alt="image-20220629185728038" style="zoom: 50%;" />

<p><strong>Problem 3：Learning</strong></p>
<p>概念：发现 $$\lambda &#x3D; (A,B,\pi)$$，使得对于固定的 N，T，和观察值 O，似然概率 $$P(O|\lambda)$$ 最大。</p>
<p>作用：最重要的问题</p>
<p>目前无法发现全局最优解，常用 Baum-Welch 算法。</p>
<h3 id="5-优化方法"><a href="#5-优化方法" class="headerlink" title="5. 优化方法"></a>5. 优化方法</h3><blockquote>
<p>优化方法：极值条件，对偶，KKT，GD，SGD，EM，<br>要知道凸优化和非凸优化，要知道凸优化的话，极值就是最优点，那么找最优点就是导数等于0<br>要直到 SVM 里面的对偶问题，SVM 没有显式最优解，因此可以用 GD，Regression 有显式最优解<br>在神经网络里面一般用 SGD，SGD 要有一个概念，为什么我们要用 SGD 和 GD？要知道二者区别，还得知道 SGD 优点<br>要对概率模型的参数进行估计的话，可以考虑用 EM 进行参数估计，比如 HMM</p>
</blockquote>
<p>凸优化定义：</p>
<p>$$<br>minimize \ f_0(x)  \<br>subject \ to \ f_i(x)&lt;&#x3D;b_i,\ \ i&#x3D;1,…,m<br>$$</p>
<p>其中，目标函数和约束函数都是凸函数，即</p>
<p>$$<br>f_i(\alpha x+\beta y) &lt;&#x3D; \alpha f_i(x) + \beta f_i(y) \<br>\alpha + \beta &#x3D; 1,\  \alpha &gt;&#x3D;0, \ \beta&gt;&#x3D;0<br>$$</p>
<h4 id="SVM-中的对偶-amp-KKT（机器学习）"><a href="#SVM-中的对偶-amp-KKT（机器学习）" class="headerlink" title="[SVM 中的对偶 &amp; KKT（机器学习）"></a>[SVM 中的对偶 &amp; KKT（机器学习）</h4><h4 id="GD-amp-SGD"><a href="#GD-amp-SGD" class="headerlink" title="GD &amp; SGD"></a>GD &amp; SGD</h4><p>随机梯度下降每次只用一个样本，对于最优化凸问题，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。但是相比于批量梯度，这样的方法更快，更快收敛。</p>
<p>批量梯度下降每次更新时用所有样本。对于最优化凸问题，可以达到一个全局最优。如果样本不多的情况下，当然是这样收敛的速度会更快。但是很多时候，样本很多，更新一次要很久。</p>
<h4 id="EM-amp-GMM（机器学习）"><a href="#EM-amp-GMM（机器学习）" class="headerlink" title="EM &amp; GMM（机器学习）"></a>EM &amp; GMM（机器学习）</h4><p>浙大</p>
<h3 id="6-距离度量"><a href="#6-距离度量" class="headerlink" title="6. 距离度量"></a>6. 距离度量</h3><blockquote>
<p>（样本之间的）距离度量：l-p 范数, DTW, …<br>要知道如何度量两个不同时间序列的样本之间的距离<br>DTW 动态时间规整</p>
</blockquote>
<p>$$l_0$$ 范数：向量 x 的非零元素的个数</p>
<img src="https://s2.loli.net/2022/06/29/QEPADFUZL5hbsfv.png" alt="image-20220625200150788" style="zoom:50%;" />

<p>DTW（Dynamic Time Warping）：动态时间规整</p>
<p>性质：1. 匹配是顺序的 2. 每个 $$x_i$$ 或 $$y_i$$ 都要有对应的匹配 3. 一个 $$x_i$$ 可以和多个 $$y_j$$ 匹配，反之亦然</p>
<img src="https://s2.loli.net/2022/06/29/UdA6mkPbKY1phcR.png" alt="image-20220625202602917" style="zoom:50%;" />

<p>递推公式：</p>
<img src="https://s2.loli.net/2022/06/29/OeASiJYFf952cZh.png" alt="image-20220625202654161" style="zoom:50%;" />

<h4 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h4><p>单变量</p>
<p>$$<br>H&#x3D;-\sum^{m}_{i&#x3D;1}p_ilog_2p_i<br>$$</p>
<p>$$<br>h&#x3D;-\int p(x)ln(p(x))dx<br>$$</p>
<p>双变量</p>
<p>$$<br>H(x,y)&#x3D;-\sum_{x}\sum_{y}P(x,y)log_2P(x,y)<br>$$</p>
<p>$$<br>h&#x3D;-\int p(x,y)ln(p(x,y))dxdy<br>$$</p>
<p>$$<br>H(X|Y) &#x3D; \sum_{y}P(y)H(X|Y&#x3D;y) &#x3D;<br>-\sum_{y}P(y)\sum_{x}P(X&#x3D;x|Y&#x3D;y)log_2P(X&#x3D;x|Y&#x3D;y) \<br>&#x3D; -\sum_{x,y}P(x,y)log_2 \frac{P(x,y)}{p(y)}<br>$$</p>
<p>$$<br>h(x,y) &#x3D; -\int p(x,y)ln\frac{p(x,y)}{p(y)}dxdy<br>$$</p>
<p>熵之间的关系</p>
<p>H(X,Y)&#x3D;H(X)+H(Y|X)&#x3D;H(Y)+H(X|Y)</p>
<p>H(X|Y)&lt;H(X)</p>
<p>H(Y|X)&lt;H(Y)</p>
<p>互信息</p>
<p>$$<br>I(X;Y)&#x3D;H(X)-H(X|Y) &#x3D; \sum_{x,y}P(x,y)log_2 \frac{P(x,y)}{P(x)P(y)}<br>$$</p>
<p>KL 散度</p>
<p>$$<br>KL(P||Q)&#x3D;\sum_{i} P_ilog_2\frac{P_i}{Q_i}<br>$$</p>
<p>$$KL(P||Q) \ge 0$$，等号成立条件：$$P_i&#x3D;Q_i$$。不对称。</p>
<p>交叉熵</p>
<p>$$<br>CE(P,Q)&#x3D;-\sum_{i}P_ilog_2Q_i \<br>CE(P,Q)&#x3D;H(p)+KL(P||Q)&#x3D;-\sum_{i}P_ilog_2P_i+\sum_{i} P_ilog_2\frac{P_i}{Q_i}<br>$$</p>
<h3 id="7-损失函数"><a href="#7-损失函数" class="headerlink" title="7. 损失函数"></a>7. 损失函数</h3><blockquote>
<p>损失函数：square, hinge, exponential, logistic, cross entropy, …<br>线性回归：square<br>SVM：hinge<br>Adaboost：exp<br>逻辑回归：logistic<br>神经网络：cross entropy</p>
</blockquote>
<h4 id="Square（机器学习）"><a href="#Square（机器学习）" class="headerlink" title="Square（机器学习）"></a>Square（机器学习）</h4><p>形式：</p>
<p>$$<br>L(f,y)&#x3D;(f-y)^2<br>$$</p>
<p>线性回归中的 Square：</p>
<p>$$<br>L&#x3D;\sum^{N}_{i&#x3D;1}(y_i-\theta^Tx_i)<br>$$</p>
<h4 id="Hinge"><a href="#Hinge" class="headerlink" title="Hinge"></a>Hinge</h4><p>译为铰链损失。</p>
<p>形式：</p>
<p>$$<br>L(y,f(x)) &#x3D; max(0,1-yf(x)),<br>$$</p>
<p>SVM 中的 Hinge：</p>
<p>$$<br>L &#x3D; \frac{1}{2C}||w||^2+\sum^{N}_{i&#x3D;1}max(0, 1-y_i(\theta^Tx_i+b))<br>$$</p>
<h4 id="Exp"><a href="#Exp" class="headerlink" title="Exp"></a>Exp</h4><p>译为指数损失。</p>
<p>形式：</p>
<p>$$<br>L(y, f(x)) &#x3D; exp[-yf(x)]<br>$$</p>
<p>Adaboost 中的 Exp：</p>
<p>$$<br>L(y, f(x)) &#x3D; \frac{1}{n} \sum^{n}_{i&#x3D;1} exp[-y_if(x_i)]<br>$$</p>
<h4 id="Logistic（机器学习）"><a href="#Logistic（机器学习）" class="headerlink" title="Logistic（机器学习）"></a>Logistic（机器学习）</h4><p>形式：</p>
<p>$$<br>L(y,f(x))&#x3D;\sum_{l}y^l ln P(y^l&#x3D;1|x^l,w)+(1-y^l)ln P(y^l&#x3D;0|x^l,w) \<br>&#x3D;\sum_{l}y^l(w_0+\sum^{n}<em>{i&#x3D;1}w_ix_i^l)-ln(1+exp(w_0+\sum^{n}</em>{i&#x3D;1}w_ix_i^l))<br>$$</p>
<h4 id="Cross-entropy"><a href="#Cross-entropy" class="headerlink" title="Cross entropy"></a>Cross entropy</h4><p>形式：</p>
<p>$$<br>L(y,f(x)) &#x3D; -\sum^{n}_{i&#x3D;1}y_i logf(x_i)<br>$$</p>
<h3 id="8-评价准则"><a href="#8-评价准则" class="headerlink" title="8. 评价准则"></a>8. 评价准则</h3><blockquote>
<p>评价准则：Acc, ROC, AP, Recall (TPR, true position rate), Precision, Bayes error, Bias-variance<br>概念掌握<br>Bayes error：取一个后验概率最大的去作为模型预测的输出<br>Bias-variance：把模型的误差做一个偏执方差分解，需要直到模型的偏置和方差，以及是由什么决定的</p>
</blockquote>
<p>PPT 3-4</p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><a class="tag" href="/categories/courses/" title="courses">courses </a><span class="leancloud_visitors"></span><span>About 4526 words, 15 min 5 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2022/07/06/machine-learning/2022-07-06-review-reinforcement-learning/">[rv] reinforcement learning</a></h3></div><div class="post-content"><div class="card"><p><h1 id="Reinforcement-Learning-P1-：Basics"><a href="#Reinforcement-Learning-P1-：Basics" class="headerlink" title="Reinforcement Learning P1 ：Basics"></a>Reinforcement Learning P1 ：Basics</h1><h2 id="Supervised-Learning→RL"><a href="#Supervised-Learning→RL" class="headerlink" title="Supervised Learning→RL"></a>Supervised Learning→RL</h2><p>Supervised Learning：给定 label</p>
<p>Self Supervised Learning：自动生成 label</p>
<p>Unsupervised Learning(Auto-encoder)：没用到人类的 label，但事实上仍然还有 label 只不过不需要用人力生成</p>
<p>RL：机器当我们给它一个输入的时候，我们不知道最佳的输出（label）应该是什么。如下棋。</p>
<h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><img src="https://s2.loli.net/2022/07/02/47o2ubILgfhtE6w.png" alt="image-20220702145935497" style="zoom:50%;" />

<h2 id="Machine-Learning-≈-Looking-for-a-Function"><a href="#Machine-Learning-≈-Looking-for-a-Function" class="headerlink" title="Machine Learning ≈ Looking for a Function"></a>Machine Learning ≈ Looking for a Function</h2><p>机器学习就是找一个 Function，Reinforcement Learning 也是，这个 Function 即 Actor 本身，要做的就是最大化 reward 之总和。</p>
<p>例：Atari Space Invador。Actor：操作对象。环境：游戏场景。Observation：游戏画面。</p>
<p>例：围棋。稀疏 Reward，只有游戏结束（输、赢）才能够拿到 Reward。</p>
<h2 id="Machine-Learning-is-so-simple-……"><a href="#Machine-Learning-is-so-simple-……" class="headerlink" title="Machine Learning is so simple ……"></a>Machine Learning is so simple ……</h2><p>Machine Learning 三个步骤：</p>
<ol>
<li>定义含待求未知数的 Function</li>
<li>定义 Loss Function</li>
<li>Optimization，minimize loss</li>
</ol>
<p>而 RL 其实也是一模一样的三个步骤</p>
<h3 id="Step-1-Function-with-Unknown"><a href="#Step-1-Function-with-Unknown" class="headerlink" title="Step 1: Function with Unknown"></a>Step 1: Function with Unknown</h3><p>Function (in RL) &#x3D; Actor, RL 中的 Actor 即神经网络，通称 Policy 的 Network。</p>
<p>神经网络输入：the observation of machine represented as a vector or a matrix。</p>
<p>神经网络输出：each action corresponds to a neuron in output layer。</p>
<p><img src="https://s2.loli.net/2022/07/03/nj8qFcTSyQ1RCBM.png" alt="image-20220702151119061"></p>
<p>为什么输出结果是概率分布？引入随机性。</p>
<h3 id="Step-2-Define-“Loss”"><a href="#Step-2-Define-“Loss”" class="headerlink" title="Step 2: Define “Loss”"></a>Step 2: Define “Loss”</h3><p>从游戏开始到结束的这整个过程被称之为一个 &#x3D;&#x3D;Episode&#x3D;&#x3D;,</p>
<p>将整个游戏的过程中 Actor 採取非常多的行为得到的 Reward 通通集合起来便是 &#x3D;&#x3D;Total Reward (Return)&#x3D;&#x3D;。$R &#x3D; \sum^{T}_{t&#x3D;1}r_t$ 。</p>
<p>Return 是最大化的对象，我们要最小化 loss，可以定义 loss &#x3D; -R。</p>
<h3 id="Step-3-Optimization"><a href="#Step-3-Optimization" class="headerlink" title="Step 3: Optimization"></a>Step 3: Optimization</h3><p>将整个游戏的过程中 s 跟 a 所形成的这个 Sequence 叫做 Trajectory。符号表示为 $\tau &#x3D; {s_1, a_1,s_2,a_2,…}$。</p>
<p>通常说，Reward Function 在定义的时候和 Action 与 Observation 都有关联。即 $r_i$ 和 $s_i$  和 $a_i$ 有关系。优化 Return 就行。</p>
<p>但是 RL 困难之处在于它不是一个一般的 Optimization 的问题。</p>
<p>第一个问题是，Actor 的输出是有随机性的。 Network 裡面的某一个 Layer 每次产生出来结果是不一样的。第二，Environment 只是一个黑盒，且包含随机性。</p>
<p>与 GAN 的对比。</p>
<p>相同：GAN 中 调整 Generator 的参数让 Discriminator 的输出越大越好。RL 中调整 ACtor 的参数让 Environment 的 Reward 越大越好。</p>
<p>不同：Discriminator 是 Network，但 Environment 只是个黑盒。不能用 GD 调整 Environment。</p>
<h1 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h1><h3 id="How-to-control-your-actor"><a href="#How-to-control-your-actor" class="headerlink" title="How to control your actor"></a>How to control your actor</h3><img src="https://s2.loli.net/2022/07/02/v7TwXC5UEJWoGdL.png" alt="image-20220702152953732" style="zoom:50%;" />

<p>可以把它想成一个分类的问题。即 s 是 Actor 的输入, $\hat{a}$(Ground Truth) 就是 Label。</p>
<p>计算 Actor 的输出跟 Ground Truth 之间的 Cross-entropy，那接下来就可以定义一个 Loss。提示：根据交叉熵的定义，预测分布和真实分布有相同的分布时交叉熵最小。Loss 越小，就等价于预测值越接近真实值。</p>
<img src="https://s2.loli.net/2022/07/02/Zb6yw2HEv38tVJM.png" alt="image-20220702153405916" style="zoom:50%;" />

<p>模型训练</p>
<img src="https://s2.loli.net/2022/07/02/T3mxPShAgQp6ZKY.png" alt="image-20220702153533859" style="zoom:50%;" />

<p>用数值 A 表示代替 +1&#x2F;-1，就可以实现表示动作的好坏程度。Loss 改写为：<br>$$<br>L&#x3D;\sum A_ne_n<br>$$</p>
<h2 id="Value-Function"><a href="#Value-Function" class="headerlink" title="Value Function"></a>Value Function</h2><h2 id="Version-0"><a href="#Version-0" class="headerlink" title="Version 0"></a>Version 0</h2><p>用随机的  Actor 去跟环境做互动收集训练资料获得 ${s_i, a_i}$。再根据情况好坏为之赋予 $r_i$。</p>
<p>最简单的但不正确的版本。短视近利。事实上，每一个行为都会影响到接下来发生的事情。例：Space Invador 中，由于只有开火才能得到正 Reward，故他会一直开火。</p>
<p>Reward Delay：牺牲短期的利益,以换取更长程的目标。</p>
<h2 id="Version-1"><a href="#Version-1" class="headerlink" title="Version 1"></a>Version 1</h2><p>&#x3D;&#x3D;Cumulated Reward&#x3D;&#x3D;：把当下与未来所有的 Reward 加起来评估一个 Action 的好坏。<br>$$<br>G_t &#x3D; \sum^{N}_{n&#x3D;t} r_n<br>$$<br>用 $G_i$ 表示每个 ${s_i, a_i}$ 对应的 reward。</p>
<p>问题在于：未来发生的影响中，有些影响大有些影响小。</p>
<h2 id="Version-2"><a href="#Version-2" class="headerlink" title="Version 2"></a>Version 2</h2><p>加上递减权重 $\gamma$。未来的 reward 中，离当下近的表示影响更大。<br>$$<br>G’<em>t &#x3D; \sum^{N}</em>{n&#x3D;t} \gamma^{n-t}r_n<br>$$</p>
<h2 id="Version-3"><a href="#Version-3" class="headerlink" title="Version 3"></a>Version 3</h2><p>做标准化，因为好或坏是相对的。</p>
<p>一个最简单的方法就是：把所有的 G’ 都减掉一个 b，即&#x3D;&#x3D;Baseline&#x3D;&#x3D;。</p>
<h2 id="Policy-Gradient-1"><a href="#Policy-Gradient-1" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h2><img src="https://s2.loli.net/2022/07/03/GJB31Hvkh4InrgR.png" alt="image-20220702155759971" style="zoom:50%;" />

<p>其中，$L &#x3D; \sum A_n e_n$。$A_n$ 就是 Reward，$e_n$ 就是交叉熵。</p>
<p>一般的 Training，Data Collection 都是在 For 循环之外。但在 RL 裡面收集资料是在 For 循环裡面。这意味着更新一次参数以后，就要重新收集资料，因此 RL 的训练过程非常花时间。</p>
<p>为什么不把 Data Collection 放在 For 循环之外？彼之砒霜，吾之蜜糖。因为由 $θ_{i-1}$ 所收集出来的资料不一定适合拿来 Update $θ_{i}$ 的参数。</p>
<p>故同一个 Action 同一个行为，对于不同的 Actor 而言，它的好是不一样的。更新后的 Actor，可能 Trajectory 就会跟之前出现区别。</p>
<h3 id="On-policy-v-s-Off-policy"><a href="#On-policy-v-s-Off-policy" class="headerlink" title="On-policy v.s. Off-policy"></a>On-policy v.s. Off-policy</h3><p>被训练的 Actor 与跟环境互动的 Actor 是同一个叫做 &#x3D;&#x3D;On-policy  Learning&#x3D;&#x3D;。</p>
<p>反之，为 &#x3D;&#x3D;Off-policy Learning&#x3D;&#x3D;。</p>
<p>Off-policy 的好处：不用一直收集资料。可以收一次资料，就 Update 参数很多次。</p>
<p>显然上文所述为 On-policy Learning。</p>
<h3 id="Off-policy-→-Proximal-Policy-Optimization-PPO"><a href="#Off-policy-→-Proximal-Policy-Optimization-PPO" class="headerlink" title="Off-policy → Proximal Policy Optimization(PPO)"></a>Off-policy → Proximal Policy Optimization(PPO)</h3><p>Off-policy 的经典算法： Proximal Policy Optimization。</p>
<p>Off-policy 的重点：在训练的那个 Network，要知道自己跟别人之间的差距，它要有意识到它跟环境互动的那个 Actor 是不一样的。</p>
<p>例子：东施效颦，别瞎模仿。</p>
<h3 id="Collection-Training-Data-Exploration"><a href="#Collection-Training-Data-Exploration" class="headerlink" title="Collection Training Data: Exploration"></a>Collection Training Data: Exploration</h3><p>Exploration：Actor 在採取行为的时候有随机性的。随机性大一点意味着能够收集到比较丰富的资料。实现方法：增大 Actor 的 Output（Distribution）的 Entropy；在 Actor 参数上加 Noise。</p>
<h2 id="Critic"><a href="#Critic" class="headerlink" title="Critic"></a>Critic</h2><p>Critic 用以评估一个 Actor 的好坏。Given actor 𝜃, how good it is when observing 𝑠 (and taking action 𝑎)。</p>
<p>本课程中 Critic 叫做 &#x3D;&#x3D;Value Function&#x3D;&#x3D;，用 $V^θ(s)$ 来表示。输出一个 scalar（Discounted Cumulated Reward）。</p>
<p>故 Value Function 的作用就是：对某一个参数为 $\theta$ 的 Actor 来说，如果它已经看到某一个游戏画面 s，那接下来会得到的 Discounted Cumulated Reward 应该是多少。</p>
<p>DCR 需要未来的 Reward 来计算。但当下怎么知道未来的 Reward 呢？Value Function 的能力就是要未卜先知。</p>
<h2 id="How-to-estimate-V-θ-s"><a href="#How-to-estimate-V-θ-s" class="headerlink" title="How to estimate $ V^θ(s) $"></a>How to estimate $ V^θ(s) $</h2><h3 id="Monte-Carlo-MC-based-approach"><a href="#Monte-Carlo-MC-based-approach" class="headerlink" title="Monte-Carlo (MC) based approach"></a>Monte-Carlo (MC) based approach</h3><p>MC：把 Actor 拿去跟环境互动很多轮，可以得到每轮的 DCR。</p>
<p>那么 Value Function 就得到一笔训练资料，训练目标是：如果看到 $s_a$ 作为输入，那它的输出 $ V^θ(s_a) $ 应该要跟 G’a 越接近越好。</p>
<img src="https://s2.loli.net/2022/07/02/jz5FaG1xdcvsWI7.png" alt="image-20220702161849346" style="zoom: 50%;" />



<h3 id="Temporal-difference-TD-approach"><a href="#Temporal-difference-TD-approach" class="headerlink" title="Temporal-difference (TD) approach"></a>Temporal-difference (TD) approach</h3><p>一轮互动可能无法终止或者很长。</p>
<p>TD：不用玩完整场游戏，才能得到训练 Value 的资料。虽然我们不知道，$ V^θ(s_t)$ 和 $ V^θ(s_{t+1})$ 应该是什么，但是我们可以让 $ V^θ(s_t)$  与 $ \gamma V^θ(s_{t+1})$ 的差值逼近已知的 $r_t$。</p>
<img src="https://s2.loli.net/2022/07/02/lazNsUr4dnBRx1k.png" alt="image-20220702162248677" style="zoom:50%;" />

<h3 id="MC-v-s-TD"><a href="#MC-v-s-TD" class="headerlink" title="MC v.s. TD"></a>MC v.s. TD</h3><img src="https://s2.loli.net/2022/07/03/SrMDN6TPgmFfh7v.png" alt="image-20220702162905728" style="zoom:50%;" />



<h2 id="Version-3-5"><a href="#Version-3-5" class="headerlink" title="Version 3.5"></a>Version 3.5</h2><p>把 baseline 设成 $V^θ(S)$。把 ${s_t,a_t}$ 对应的 Value 定义为：<br>$$<br>A_t &#x3D; G’_t-V^θ(s_t)<br>$$<br>为什么这样可以？我们知道 $ V^θ(s_t)$是看到某一个画面 $s_t$ 以后，接下来会得到的 (加权) Reward。它其实是一个期望，因为有随机性，即每次的 $a_t$ 可能不同，故每次可能会得到不一样的 Reward。</p>
<img src="https://s2.loli.net/2022/07/02/krBqTm6nCYiFKMG.png" alt="image-20220702163444448" style="zoom:50%;" />

<p>图中 Gt’ 是 sample 某一个 trajectory 的结果，而$ V^θ(s_t)$ 是很多条路径平均以后的结果。</p>
<p>问题在于：把一个 sample 去减掉平均，这样会准吗？也许这个sample 特别好或特别坏。为什麽不是拿平均去减掉平均？</p>
<h2 id="Version-4"><a href="#Version-4" class="headerlink" title="Version 4"></a>Version 4</h2><p>最后一个版本：平均去减掉平均。这就是 &#x3D;&#x3D;Advantage Actor-Critic&#x3D;&#x3D;。</p>
<p>把 ${s_t,a_t}$ 对应的 Value 定义为：<br>$$<br>A_t &#x3D; r_t+V^θ(s_{t+1})-V^θ(s_t)<br>$$<br><img src="https://s2.loli.net/2022/07/03/M72tBQOvFV5lpsX.png" alt="image-20220702163949638" style="zoom:50%;" /></p>
<h2 id="Tip-of-Actor-Critic"><a href="#Tip-of-Actor-Critic" class="headerlink" title="Tip of Actor-Critic"></a>Tip of Actor-Critic</h2><p>Actor 和 Critic 都是 Network，他们的输入可以公用 CNN。</p>
<h2 id="Sparse-Reward"><a href="#Sparse-Reward" class="headerlink" title="Sparse Reward"></a>Sparse Reward</h2><p>Sparse Reward：$r_t$ &#x3D; 0 in most cases。例如拧螺丝。</p>
<p>解决办法：reward shaping。</p>
<h2 id="Imitation-Learning"><a href="#Imitation-Learning" class="headerlink" title="Imitation Learning"></a>Imitation Learning</h2><p>Actor 可以与环境互动，但 reward function 不知道怎么定义。</p>
<p>解决办法：根据专家的演示 ${\hat{\tau_1}, \hat{\tau_2}, …}$ 进行模仿学习。</p>
<p>例子：自动驾驶，机械臂抓举。</p>
<p>问题：专家们只对有限的观察进行抽样。</p>
<h2 id="Inverse-Reinforcement-Learning"><a href="#Inverse-Reinforcement-Learning" class="headerlink" title="Inverse Reinforcement Learning"></a>Inverse Reinforcement Learning</h2><p>使用 reward function 找到最佳 actor。</p>
<p>原则：The teacher is always the best。</p>
<p>方法论：</p>
<img src="https://s2.loli.net/2022/07/02/YR12xlTz8PwE7sG.png" alt="image-20220702164853222" style="zoom:50%;" />

<img src="https://s2.loli.net/2022/07/02/FDgLe1CdnYfmhoU.png" alt="image-20220702165029388" style="zoom:50%;" />

<p>和 GAN 的类比理解</p>
<p>GAN 中 Generator 的优化目标是产生跟 Ground Truth 的很像的结果，IRL 中 Actor 的优化目标是产生跟 Expert 的很像的结果。</p>
<p>GAN 中 Discriminator 的优化目标是产生分辨 Ground Truth 和 Generator 的输出值，给 Ground Truth 打高分，IRL 中 Reward 则是给 Expert 打高分。</p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><a class="tag" href="/categories/courses/" title="courses">courses </a><span class="leancloud_visitors"></span><span>About 2401 words, 8 min 0 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2022/07/06/machine-learning/2022-07-06-review-domain-adaptation/">[ml][rv] domain adaptation</a></h3></div><div class="post-content"><div class="card"><p><h1 id="27-Domain-Adaptation"><a href="#27-Domain-Adaptation" class="headerlink" title="27 Domain Adaptation"></a>27 Domain Adaptation</h1><p>训练资料跟测试资料的分布是不一样的，叫做 &#x3D;&#x3D;Domain Shift&#x3D;&#x3D;。</p>
<p>解决办法是 &#x3D;&#x3D;Domain Adaptation&#x3D;&#x3D;，它也可以看做是 &#x3D;&#x3D;Transfer Learning&#x3D;&#x3D; 的一种。</p>
<p>Transfer Learning ：在 A 任务上学到的技能可以被用在 B 任务上</p>
<p>Domain Adaptation：你的训练资料是一个 Domain，你的测试资料是另外一个 Domain，你在训练资料上面学到的资讯可以要把它用到另外一个 Domain 上。</p>
<h2 id="Domain-Shift"><a href="#Domain-Shift" class="headerlink" title="Domain Shift"></a>Domain Shift</h2><p>两者可能情况。一，输入资料即训练集和测试集的分布不同。二，输入跟输出虽然分布相同的，但它们之间的关係变了，比如训练集叫做 0 的东西在测试集里叫做 1。</p>
<p>今天只考虑前者。记测试集为 &#x3D;&#x3D;Target Domain&#x3D;&#x3D;，训练集为 &#x3D;&#x3D;Source Domain&#x3D;&#x3D;。</p>
<h2 id="Domain-Adaptation"><a href="#Domain-Adaptation" class="headerlink" title="Domain Adaptation"></a>Domain Adaptation</h2><p>分三种情况考虑：</p>
<p>其一，在 Target Domain 上有一大堆的资料且配有 Label，那就直接拿 Target Domain 的资料来训练。</p>
<p>其二，在 Target Domain 上有一点点的资料且配有 Label，那就拿他们来微调，即不要在 Target Domain 上的资料上跑太多的 Iteration。</p>
<p>其三，在 Target Domain 上有一大堆的资料但没有 Label。找个 Feature Extractor，它会把 Source 和 Target 不一样的部分拿掉，只抽取出它们共同的部分。</p>
<p>其四，在 Target Domain 上有一点点的资料且没有 Label。有一个方法叫做 &#x3D;&#x3D;Testing Time Training&#x3D;&#x3D;,它的缩写是 TTT。</p>
<img src="https://s2.loli.net/2022/07/02/YkL3rCt54DKV1hd.png" alt="image-20220702171146183" style="zoom:50%;" />



<h3 id="Domain-Adversarial-Training"><a href="#Domain-Adversarial-Training" class="headerlink" title="Domain Adversarial Training"></a>Domain Adversarial Training</h3><p>怎麼找出这样的一个 Feature Extractor 呢？那其实我们可以把一个一般的 Classifier 分成 Feature Extractor 跟 Label Predictor 。</p>
<img src="https://s2.loli.net/2022/07/02/KRqyn5MD2SxmYE3.png" alt="image-20220702172724450" style="zoom:50%;" />

<p>Domain Adaptation 的一种方法 &#x3D;&#x3D;Domain Adversarial Training&#x3D;&#x3D;</p>
<p>训练 Feature Extractor：让 Source Domain 的图片得到的 Feature，跟 Target Domain 的分不出差异。</p>
<p>训练 Domain Classifier：二元分类器，区分这个 feature 是来自於 Source Domain,还是来自於 Target Domain。</p>
<p>Domain Adversarial Training 很像是 GAN。可以把 Feature Extractor 想成是 Generator，把 Domain Classifier 想成是 Discriminator。</p>
<p>Generator 好像优势太大了，它只要都输出 0 不就无法区分了吗？不行，都输出 0 虽然 Domain Classifier 无法区分，但 Label Predictor 也无法区分！</p>
<p>接下来考虑参数优化。Label Predictor 要做的事情就是让这个 Source Domain 的 Image 分类越正确越好，即最小化 Loss（交叉熵，分类问题有交叉熵）。Domain Classifier 要做的事情就是让 Domain 的分类越正确越好，也是最小化交叉熵。</p>
<p>Feature Extractor 要做的事情是，它又要保证能让 Label Predictor 有个好结果，又要骗过 Domain Classifier，故把 loss 设为 $L-L_d$。</p>
<h4 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h4><p>刚才这整套想法有一个小小的问题</p>
<img src="https://s2.loli.net/2022/07/02/Hrnl2S15keas3fT.png" alt="image-20220702173655699" style="zoom:50%;" />

<p>直觉上讲右边更好，所以我们是不是应该要让右边的状况发生呢？怎么做呢？也许一个可能的想法：我们既然知道分界点在哪裡，那我们应该要让这些方形远离这一个分界点。</p>
<h4 id="Considering-Decision-Boundary"><a href="#Considering-Decision-Boundary" class="headerlink" title="Considering Decision Boundary"></a>Considering Decision Boundary</h4><p>什麼叫做离 Boundary 越远越好呢？如果今天输出的结果非常地集中，即 Entropy 小，叫做离 Boundary 远。反之则近。</p>
<p>到目前為止都假设说，Source Domain 跟 Target Domain，它的类别都要是一模一样。但是真的一定会这样吗？</p>
<img src="https://s2.loli.net/2022/07/02/wjvbz6ytZYGfS7H.png" alt="image-20220702174451574" style="zoom:50%;" />



<p>实线的圈圈代表，Source Domain 裡面有的东西，这个虚实线的圈圈代表 Target Domain 裡面有的东西。所以在这个前提之下，你说你要让 Source Domain 的 Data 跟 Target Domain 的 Data，它们的 Feature 完全 Match 在一起，那意味著说，你硬是要让老虎去变得跟狗像，到时候你就分不出老虎这个类别了。</p>
<h2 id="Domain-Generalization"><a href="#Domain-Generalization" class="headerlink" title="Domain Generalization"></a>Domain Generalization</h2><p>但其实还有一个更严峻的状况，如果我们对 Target Domain 一无所知的话怎麼办呢？这种情况通常就叫 &#x3D;&#x3D;Domain Generalization&#x3D;&#x3D;。</p>
<p>我们期待机器在 Testing 的时候，不管来什麼样的 Domain，它都可以处理。</p>
<p>Domain Generalization 又分成两种状况：其一，训练资料本来就包含了各式各样不同的 Domain 的数据；其二，训练资料只有一个 Domain，做 Data Augmentation。</p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><a class="tag" href="/categories/courses/" title="courses">courses </a><span class="leancloud_visitors"></span><span>About 1168 words, 3 min 53 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2022/07/06/machine-learning/2022-07-06-review-generative-adversarial-network.md/">[ml][rv] generative adversarial network</a></h3></div><div class="post-content"><div class="card"><p><h1 id="GAN-P1"><a href="#GAN-P1" class="headerlink" title="GAN_P1"></a>GAN_P1</h1><h1 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h1><h2 id="Network-as-Generator"><a href="#Network-as-Generator" class="headerlink" title="Network as Generator"></a>Network as Generator</h2><p>输入 x 和从一个distribution 裡面 sample 出来的 z，输出变成了一个复杂的 distribution。这种输出 distribution 的 network 称之为&#x3D;&#x3D;generator&#x3D;&#x3D;。</p>
<img src="https://s2.loli.net/2022/07/02/eDOx7rbhcL9BEZA.png" alt="image-20220702205648601" style="zoom:50%;" />

<h2 id="Why-distribution"><a href="#Why-distribution" class="headerlink" title="Why distribution"></a>Why distribution</h2><p>为什么要输出一个分布？有时候需要这样。</p>
<p>例子：video prediction，即给机器一段的影片，然后它要预测接下来会发生什麼事情。训练资料裡面同样的输入，有时候同样的转角有两种可能性。所以你的 network 学到的就是两面讨好。</p>
<p>什麼时候我们会特别需要这？我们的任务需要一点创造力的时候。通俗讲，们想要找一个function，但是同样的输入有多种可能的输出，他们都是对的。</p>
<h1 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network (GAN)"></a>Generative Adversarial Network (GAN)</h1><p>generative 的 model，其中一个非常知名的就是&#x3D;&#x3D;generative adversarial network&#x3D;&#x3D;。</p>
<h2 id="Anime-Face-Generation"><a href="#Anime-Face-Generation" class="headerlink" title="Anime Face Generation"></a>Anime Face Generation</h2><p>例子：让机器生成动画人物的,二次元人物的脸。</p>
<img src="https://s2.loli.net/2022/07/02/jlqBn7UevwaStmH.png" alt="image-20220702210030736" style="zoom: 50%;" />



<h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><p>在GAN裡面除了&#x3D;&#x3D;generator&#x3D;&#x3D;以外还有一个 &#x3D;&#x3D;discriminator&#x3D;&#x3D;。</p>
<p>discriminaton 也是个 network，它的作用是：拿一张图片作為输入，它的输出是一个数值。越大代表越像是真实的二次元图像。 </p>
<h2 id="Basic-Idea-of-GAN"><a href="#Basic-Idea-of-GAN" class="headerlink" title="Basic Idea of GAN"></a>Basic Idea of GAN</h2><p>物竞天择。对应到 GAN，枯叶蝶就是 generator，那它的天敌就是 discriminator。</p>
<p>generator 生成二次元图像。discriminator 分辨二次元图像。</p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><h4 id="Step-0：初始化-generator-和-discriminator-的参数。"><a href="#Step-0：初始化-generator-和-discriminator-的参数。" class="headerlink" title="Step 0：初始化 generator 和 discriminator 的参数。"></a>Step 0：初始化 generator 和 discriminator 的参数。</h4><h4 id="Step-1-Fix-generator-G-and-update-discriminator-D"><a href="#Step-1-Fix-generator-G-and-update-discriminator-D" class="headerlink" title="Step 1: Fix generator G, and update discriminator D"></a>Step 1: Fix generator G, and update discriminator D</h4><p>从这个 gaussian distribution 裡面去 sample 一堆 vector，把这些 vector 丢到 generator 裡面，它就吐出一些图片。</p>
<p>你会有一个 database，这个database裡面，有很多二次元人物的头像。</p>
<p>接下来就拿真正的二次元人物头像，跟 generator 產生出来的结果，去训练你的discriminator。discriminator 它训练的目标是要分辨，真正的二次元人物跟 generator 產生出来的二次元人物。</p>
<p>这对於 discriminator 来说是一个分类的问题。也可以说是 regression 的问题。</p>
<img src="https://s2.loli.net/2022/07/02/yVjMHO91l8wvBYd.png" alt="image-20220702211803640" style="zoom:50%;" />

<h4 id="Step-2-Fix-discriminator-D-and-update-generator-G"><a href="#Step-2-Fix-discriminator-D-and-update-generator-G" class="headerlink" title="Step 2: Fix discriminator D, and update generator G"></a>Step 2: Fix discriminator D, and update generator G</h4><p>我们把 generator 生成的图片丢到 Discriminator 裡面，Discriminator 会给这个图片一个分数，那 generator 是要 Discriminator 的输出值越大越好</p>
<p>举例来说 generator 如果是五层的 network，Discriminator 如果是五层的 network，把它们接起来我们就把它当作是一个十层的 network 来看待。这个十层的network裡面，其中某一隐藏层的输出就是代表一张图片。</p>
<p>我们要做的事情是,整个巨大的 network 啊,它会吃一个向量作為输入，然后他会输出一个分数,那我们希望调整这个 network，让输出的分数越大越好。&#x3D;&#x3D;gradient ascent&#x3D;&#x3D; 来优化。</p>
<img src="https://s2.loli.net/2022/07/02/pohEWjL1BzN692T.png" alt="image-20220702211815139" style="zoom:50%;" />





<h1 id="GAN-P2-Theory-behind-GAN"><a href="#GAN-P2-Theory-behind-GAN" class="headerlink" title="GAN_P2_Theory behind GAN"></a>GAN_P2_Theory behind GAN</h1><p>接下来讨论為什麼这个 Generator 跟 Discriminator 的互动，可以让我们的 Generator產生像是真正的人脸的图片。</p>
<p>那我们先来弄清楚训练的目标到底是什麼，我们想要 Minimize 的是让 Generator 产生的 Distribution 和 真正 Data 的 Distribution 越接近越好。</p>
<img src="https://s2.loli.net/2022/07/02/SrRm7qka3Gznywl.png" alt="image-20220702212331965" style="zoom:50%;" />

<p>Div &#x3D; Divergence。红色下划线的函数也就表示了我们的 Loss Function。</p>
<p>常见的 Divergence 计算方法：</p>
<img src="https://s2.loli.net/2022/07/02/NcdJfC34mDreIQa.png" alt="image-20220702212648534" style="zoom:50%;" />

<img src="C:%5CUsers%5Cysc%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220702212653606.png" alt="image-20220702212653606" style="zoom:50%;" />



<p>但是我们这边遇到一个困难的问题，这个 Divergence 很难算的。而&#x3D;&#x3D;GAN&#x3D;&#x3D;是一个很神奇的做法,它&#x3D;&#x3D;可以突破,我们不知道怎麼计算 Divergence 的限制&#x3D;&#x3D;。</p>
<p>我们不需要知道 PG 跟 Pdata 它们实际上的 Formulation （对应公式的 P(x) 和 Q(x)）长什麼样子，只要能从 PG 和 Pdata这两个 Distributions Sample 东西出来，就有办法算 Divergence。</p>
<h2 id="Discriminator-1"><a href="#Discriminator-1" class="headerlink" title="Discriminator"></a>Discriminator</h2><p>如何在只有做 Sample 的前提之下估测出 Divergence？那这个就是要靠 &#x3D;&#x3D;Discriminator&#x3D;&#x3D; 的力量。</p>
<p>Discriminator 优化的过程，你也可以把它写成式子：</p>
<img src="https://s2.loli.net/2022/07/02/r865BCpik9Ihtlc.png" alt="image-20220702213617546" style="zoom:50%;" />

<p>这个 Discriminator 可以去 Maximize某一个 Function,我们这边叫做 &#x3D;&#x3D;Objective Function&#x3D;&#x3D;（我们要 Maximize 的东西,我们会叫 Objective Function,如果 Minimize 我们就叫它 Loss Function）。</p>
<ul>
<li><p>$E_{y\sim P_{data}}[logD(y)]$ 我们有一堆 Y,它是从 Pdata 裡面 Sample 出来的,也就是它们是真正的 Image,而我们把这个真正的 Image 丢到 D 裡面,得到一个分数再取$logD(y)$</p>
</li>
<li><p>$E_{y\sim P_G}[log(1-D(y))]$ 那另外一方面,我们有一堆 Y,它是从 PG 从 Generato r 所產生出来的,把这些图片也丢到 Discriminator 裡面,得到一个分数,再取 $log(1 - D (y))$</p>
</li>
</ul>
<p>那这边最神奇的地方是这一个式子，这个红框框裡面的数值,它跟 JS Divergence 有关。假设 PG 跟 Pdata 的 Divergence 很小，所以这个 Objective 这个 V 的 Maximum 的值就比较小。所以小的 Divergence，对应到小的这个 Objective Function 的Maximum 的值。</p>
<img src="C:%5CUsers%5Cysc%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220702214350465.png" alt="image-20220702214350465" style="zoom:50%;" />



<h2 id="Tips-for-GAN"><a href="#Tips-for-GAN" class="headerlink" title="Tips for GAN"></a>Tips for GAN</h2><p>技巧之一： &#x3D;&#x3D;WGAN&#x3D;&#x3D;。</p>
<p>在此之前先讲 JS Divergence 有什麼样的问题。</p>
<h3 id="JS-divergence-is-not-suitable"><a href="#JS-divergence-is-not-suitable" class="headerlink" title="JS divergence is not suitable"></a>JS divergence is not suitable</h3><p>PG 跟 Pdata 有一个非常关键的特性是：它们重叠的部分往往非常少。</p>
<p>原因有二：其一，那图片其实是高维空间裡面的一个低维的 Manifold，二次元人物的头像它的分布在高维的空间中其实是非常狭窄的。其二，我们对 PG 跟 Pdata,它的分布的理解来自於 Sample，如果采样不全有重叠也发现不了。</p>
<p>JS Divergence 有个特性，是两个没有重叠的分布，JS Divergence 算出来,就永远都是 Log2。因此用 JS Divergence 的时候，你就假设你今天在 Train 一个 Binary 的 Classifier，你会发现实际上你通常 Train 完以后正确率几乎都是 100%。</p>
<p>因為你 Sample 的图片根本就没几张，它直接用硬背来分辨。所以这时候 accuracy 没啥用。</p>
<h3 id="Wasserstein-Distance"><a href="#Wasserstein-Distance" class="headerlink" title="Wasserstein Distance"></a>Wasserstein Distance</h3><p>假想你在开一台推土机,那你把分布 P 想成是一堆土，把分布 Q 想成是你要把土堆放的目的地，那这个推土机把 P 这边的土，挪到 Q 所移动的平均距离就是 Wasserstein Distance。</p>
<img src="https://s2.loli.net/2022/07/02/YbfdnjBgKyG7MiQ.png" alt="image-20220702215728448" style="zoom:50%;" />



<p>但是推土的办法有很多种。因此光只是要计算一个 Distance，居然还要解一个 Optimization 的问题，解出这个 Optimization 的问题，才能算 Wasserstein Distance。先讲 Wasserstein Distance 能给我们什么好处。</p>
<img src="https://s2.loli.net/2022/07/02/L2exJ7objlQV6RU.png" alt="image-20220702215942823" style="zoom:50%;" />



<p>由左向右的时候，Wasserstein Distance 是越来越小的，表明 Generator 在进步。JS Divergence 却不变。</p>
<h3 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h3><p>用 Wasserstein Distance 来取代 JS Divergence 的时候，这个 GAN 就叫做 WGAN。</p>
<p>接下来你会遇到的问题就是，Wasserstein Distance 是要怎麼算。</p>
<p>解下面这个 Opimilazion 的 Problem，解出来以后你得到的值就是 Wasserstein Distance。</p>
<img src="https://s2.loli.net/2022/07/02/BQdKpZU4hnojlkT.png" alt="image-20220702220447872" style="zoom:50%;" />

<p>即我们想要 Discriminator 对 Pdata 输出越大越好，对 PG 的 输出越小越好。 </p>
<p>限制：D 必须要是一个 1-Lipschitz 的 Function。</p>
<p>1-Lipschitz 不知道是什麼的话也没关係。可以想象成 D 必须要是一个足够平滑的 Function。</p>
<img src="https://s2.loli.net/2022/07/02/zW8YZsXSBRuwAIn.png" alt="image-20220702220721319" style="zoom:50%;" />

<p>否则，就会出现无限大的情况。这会导致要优化的目标越来越大，这下就又不能收敛力（悲。</p>
<p>接下来的问题就是怎麼做到 1-Lipschitz 的这个限制。</p>
<p>想法一：只需 Train Network 的时候，让 Training 的那个参数，要求它放得在 C 跟 -C 之间，如果参数更新后超过就设为 C 就设为 C，小于 -C 就设为 -C。但这样其实挺拉的。</p>
<p>想法二：Gradient Penalty。</p>
<img src="https://s2.loli.net/2022/07/02/5tfQYTE1ApIj9Zl.png" alt="image-20220702221255324" style="zoom:50%;" />

<p>想法三：Spectral Normalization。</p>
<h1 id="GAN-P3"><a href="#GAN-P3" class="headerlink" title="GAN_P3"></a>GAN_P3</h1><p>有了 WGAN 并不代表说 GAN 就一定特别好 Train。為什麼 GAN 很难被 Train 起来？</p>
<p>事实上 Generator 跟 Discriminator，它们是互相砥砺才能互相成长的，只要其中一者发生什麼问题停止训练，另外一者就会跟著停下训练。</p>
<h2 id="Conditional-Generation"><a href="#Conditional-Generation" class="headerlink" title="Conditional Generation"></a>Conditional Generation</h2><p>到目前為止我们讲的 Generator，它输入都是一个随机的分布而已，那这个不见得非常有用。</p>
<p>我们现在想要更进一步的是，我们可以操控 Generator 的输出，我们给它一个 Condition x，让它根据 x 跟 z 来產生 y，那这样的 Conditional Generation。</p>
<img src="https://s2.loli.net/2022/07/02/IRunVTbEJ5xdNUW.png" alt="image-20220702222211000" style="zoom:50%;" />

<p>普通的 &#x3D;&#x3D;GAN&#x3D;&#x3D; 不也是一个标量一个向量输入？</p>
<p>如果要做文字对图片的生成，它其实是一个 Supervised Learning 的问题。你需要一些 Label 的 Data，比如说红眼睛的人头像，才能够训练这种 Conditional 的 Generation。</p>
<p>所以在这样的任务裡面，我们的 x 就是一段文字。比如说输入 Red Eyes，然后机器就可以画一个红眼睛的角色，但每次画出来的角色都不一样。</p>
<p>也许你就可以去把 Generator 训练出来，但这样的方法是错误的。因为这样的 Generator 它只要產生清晰的图片，就可以骗过 Discriminator 了，它何必要去管 Input 文字叙述是什麼。</p>
<p>所以在 Conditional GAN 裡面， Discriminator 不是只吃图片 y，它还要吃 Condition x。</p>
<img src="C:%5CUsers%5Cysc%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220702222850921.png" alt="image-20220702222850921" style="zoom:50%;" />



<p>那怎麼样训练这样的 Discriminator ？那你需要文字跟影像成对的资料，所以 Conditional GAN 一般的训练需要的 Data 的，是需要有标註的资料的。</p>
<p>光是这样子的 Positive Sample 还不够，还有 Negative Sample，即產生好的图片文字叙述配不上的状况。</p>
<p>再考虑 Image To Image 的情形，只是从影像產生影像,把文字的部分用影像取代掉而已。文献上如果你要做到最好，往往就是 GAN 跟 Supervised Learning，同时使用。</p>
<p>此外，输入的 label 也可以是 multi-label 的。</p>
<h1 id="GAN-P4-Learning-from-Unpaired-Data"><a href="#GAN-P4-Learning-from-Unpaired-Data" class="headerlink" title="GAN_P4 Learning from Unpaired Data"></a>GAN_P4 Learning from Unpaired Data</h1><p>最后讲一个GAN的神奇应用，它把GAN用在&#x3D;&#x3D;unsupervised Learning&#x3D;&#x3D;。</p>
<p>我们可能会遇到一个状况：我们有一堆 X 我们有一堆 Y，但 X 跟 Y 是不成对的。这叫做&#x3D;&#x3D;unlabeled&#x3D;&#x3D;的资料。</p>
<img src="https://s2.loli.net/2022/07/02/YJeNnvA8OHcTklV.png" alt="image-20220702223725028" style="zoom:50%;" />



<p>我们这边举一个例子：影像风格转换。X domain 是真人的照片，Y domain的图是二次元人物的头像。这个例子没有任何的成对的资料。</p>
<p>解决办法：Unsupervised Conditional Generation。</p>
<img src="https://s2.loli.net/2022/07/02/txUk6CiOclPKSsZ.png" alt="image-20220702224026202" style="zoom:50%;" />

<p>输入是一个 Gaussian 的分佈，输出可能是一个复杂的分佈。现在我们在稍微转换一下我们的想法，输入说是 X domain 的图片的分佈，输出说是 Y domain 的图片的分佈。</p>
<p>把输入改成  X domain 很简单，不从高斯分布里采样就行。那怎麼让输出变成是Y domain 的 distribution 呢？</p>
<p>那就要两三个 discriminator，那这个 discriminator 给它看过很多 Y domain 的图，所以它能够分辨 Y domain 的图跟不是 Y domain 的图。</p>
<img src="https://s2.loli.net/2022/07/03/xPShuYeZ5q1Fg9y.png" alt="image-20210524140458705" style="zoom:50%;" />

<p>但这样不够，还得保证生成的二次元头像跟输入的真实的照片有关联。</p>
<img src="https://s2.loli.net/2022/07/03/GZDRuk1986sXVa3.png" alt="image-20210524141004712" style="zoom:50%;" />



<p>由于没有成对数据，因此无法直接套用 conditional GAN 的想法。因為在 conditional GAN 裡面，我们是有成对的资料来训练 discriminator 的。</p>
<h2 id="Cycle-GAN"><a href="#Cycle-GAN" class="headerlink" title="Cycle GAN"></a>Cycle GAN</h2><p>这边这个想法叫做&#x3D;&#x3D;Cycle GAN&#x3D;&#x3D;。在Cycle GAN裡面会 train 两个 generator。</p>
<img src="https://github.com/unclestrong/DeepLearning_LHY21_Notes/blob/master/Notes_pic/image-20210524141830620.png?raw=true" alt="image-20210524141830620" style="zoom:50%;" />

<p>在训练的时候增加了一个额外的目标：希望输入一张图片，从 X domain 转成 Y domain 以后，要从Y domain转回原来的。我们要让原图和还原的图越相近越好。这叫做 &#x3D;&#x3D;Cycle的consistency&#x3D;&#x3D;。</p>
<p>两张图片本质上就是两个向量，它们之间的距离越接近越好，就是要两张图片越像越好。</p>
<p>所以现在这边我们有三个Network：</p>
<ol>
<li>第一个generator,它的工作是把X转成Y</li>
<li>第二个generator,它的工作是要把Y还原回原来的X</li>
<li>那这个discriminator,它的工作仍然是要看,蓝色的这个generator它的输出,像不像是Y domain的图</li>
</ol>
<p>这时你可能会有的一个问题就是：你只能保证两个 domain 的图有关系，但这种关系真的有意义？比如两个 generator 学到的都是图片反转，同样也能保证 cycle consistency。这个问题实际上一般不出现。</p>
<p>Cycle GAN 可以是双向的。</p>
<img src="https://s2.loli.net/2022/07/02/pMnYJsVlE2v49yf.png" alt="image-20220702225831039" style="zoom:50%;" />



<p>一些其他的 GAN。Disco GAN、Dual GAN 跟 Cycle GAN 没什么不同。</p>
<p>相比只能在两种风格间转换的 Cycle GAN，StarGAN 可以做多风格影像风格转换。</p>
<p>一些其他应用：把长的文章变成简短的摘要；翻译；非督导式的语音辨识。</p>
<h2 id="Evaluation-of-Generation"><a href="#Evaluation-of-Generation" class="headerlink" title="Evaluation of Generation"></a>Evaluation of Generation</h2><p>要评估 Generator 的好坏完全用人来看显然有很多的问题。应该来点客观的方法。</p>
<p>比如跑一个影像的分类系统：把你的 GAN 產生出来的图片，丢到一个的影像的分类系统裡面，看它產生什麼样的结果。</p>
<img src="https://s2.loli.net/2022/07/02/Dl2ynLFCiBHk1c3.png" alt="image-20220702230658786" style="zoom:50%;" />



<p>如果四不像，那就是均匀分布力。</p>
<h3 id="Diversity-Mode-Collapse"><a href="#Diversity-Mode-Collapse" class="headerlink" title="Diversity - Mode Collapse"></a>Diversity - Mode Collapse</h3><p>但是光用这个评估的方法会被一个叫做 &#x3D;&#x3D;Mode Collapse&#x3D;&#x3D; 的问题骗过去。</p>
<img src="https://s2.loli.net/2022/07/02/oSnfjz1grKa6QA4.png" alt="image-20220702230818845" style="zoom:50%;" />



<p>这会导致 Generative Model 输出来的图片来来去去就是那几张可能单一的图片。</p>
<p>那為什麼会有 Mode Collapse 这种现象发生？直觉上理解，这个地方就是 Discriminator 的一个盲点，发现这个盲点后每次都整这一出。</p>
<h3 id="Diversity-Mode-Dropping"><a href="#Diversity-Mode-Dropping" class="headerlink" title="Diversity - Mode Dropping"></a>Diversity - Mode Dropping</h3><p>但是有另外一种更难被侦测到的问题叫做 &#x3D;&#x3D;Mode Dropping&#x3D;&#x3D;。</p>
<p>Mode Dropping 的意思是说，你的產生出来的资料，但看起来多样性好像也够。</p>
<p>这种问题难以侦测。一种可能的方法：</p>
<p>借助我们的 Image Classifier。比如把 Generator 產生 1000 张图片，把这 1000 张图片裡,都丢到 Image Classify 裡面，看输出是哪个 class。</p>
<p>每张图片，都会给我们一个 Distribution。把所有图片的 Distribution 加起来平均，如果很集中说明多样性不行。</p>
<p>Diversity 跟 Quality 好像是有点互斥？实则不然。二者评估范围不同。Quality 是只看一张图片的分布，而 Diversity 看的是一堆图片它分布的平均。</p>
<p>过去有一个非常常被使用的分数,叫做 &#x3D;&#x3D;Inception Score&#x3D;&#x3D;。如果 Quality 高，那个 Diversity 又大，那 Inception Score 就会比较大。</p>
<h3 id="Frechet-Inception-Distance-FID"><a href="#Frechet-Inception-Distance-FID" class="headerlink" title="Fréchet Inception Distance (FID)"></a>Fréchet Inception Distance (FID)</h3><p>还有一个 Evaluation 的 Measure,叫 &#x3D;&#x3D;Fréchet Inception Distance&#x3D;&#x3D;。</p>
<img src="C:%5CUsers%5Cysc%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20220702233919606.png" alt="image-20220702233919606" style="zoom:50%;" />

<p>你先把你產生出来的二次元的人物，丢到 Inception Net 裡面，那个 Inception Network 输出它的类别，那你得到的可能就是人脸，那每一张二次元的人物看起来都是人脸，那我们不要拿那个类别。</p>
<p>我们拿进入 Softmax 之前的 Hidden Layer 的输出。把这个向量拿出来代表这张图片。</p>
<p>我们拿出来的是一个向量，而不是最后的类别。那虽然最后分类的类别可能是一样的，但是在决定最后的类别之前，这个向量就算都是人脸，可能还是不一样的。</p>
<p>假设真实的图片跟產生出来的图片它们都是 Gaussians 的 Distribution，然后去**计算这两个 Gaussians Distribution 之间的&#x3D;&#x3D;Fréchet  Distance&#x3D;&#x3D;**。因為它是一个 Distance，所以这个值就是越小越好，代表这两组图片越接近。</p>
<p>但实际上图片不一定是 Gaussians Distribution，且要準确得到你的 Network 它的分布需要產生大量的 Sample 才能做到。</p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><a class="tag" href="/categories/courses/" title="courses">courses </a><span class="leancloud_visitors"></span><span>About 4152 words, 13 min 50 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2022/07/06/machine-learning/2022-07-06-support-vector-machine/">[ml][nt] support vector machine</a></h3></div><div class="post-content"><div class="card"><p><p>没有免费的午餐定理：在不考虑先验概率的情况下，所有算法的性能一样。即没有不存在适用于所有的问题的算法，不存在普适性的算法，任何两个算法，以及它们训练出来的模型，在所有的现实问题的集合面前是无优劣的，它们的性能的数学期望值是一样的。</p>
<p>尽管如此，适合大部分情况的算法依然是存在的。</p>
<p>线性可分（Linear Separable）：存在一条直线分开两类。线性不可分（Linear Unseparable）：反之。</p>
<p><img src="https://s2.loli.net/2022/05/31/w8QjIJaoXu4NWqL.png" alt="image-20220531150521269" style="zoom: 50%;" />                              <img src="https://s2.loli.net/2022/05/31/lhHLk8BOqdR6Kji.png" alt="image-20220531150559805" style="zoom:50%;" /></p>
<p>同样地，可以延伸至高维。用数学方式表示：</p>
<p><img src="https://s2.loli.net/2022/05/31/lNSTWmDonyPLdZr.png" alt="image-20220531150850968"></p>
<p>两侧正负号是人为定义的，将权重和偏置取反，两侧符号也便取反。</p>
<p>线性可分的严格定义：一个样本训练集 $${(X_i, y_i), …, (X_N,y_N)}$$ 在 i&#x3D;1-N 线性可分，是指存在 $$(w_1, w_2, b)$$ 使得对 i&#x3D;1-N，都有：</p>
<p>$$<br>(1)\ 若y_i&#x3D;+1, 则w_1x_{i1}+w_2x_{i2}+b&gt;0 \<br>(2)\ 若y_i&#x3D;-1, 则w_1x_{i1}+w_2x_{i2}+b&lt;0<br>$$</p>
<p>线性可分定义的简化形式：</p>
<p>如果 $$y_i$$ &#x3D; +1 或 -1，一个样本训练集 $${(X_i, y_i), …, (X_N,y_N)}$$ 在 i&#x3D;1-N 线性可分，是指存在 $$(w_1, w_2, b)$$ 使得对 i&#x3D;1-N，都有：</p>
<p>$$<br>y_i(w^TX_i+b)&gt;0<br>$$</p>
<p>课后思考：</p>
<p>① 你能否给出实际生活中训练样本集是线性可分和线性不可分的例子？大多数实际生活中的例子是线性可分还是线性不可分？</p>
<p>② 我们对于线性可分和线性不可分的定义只是局限于二分类间题，请对类别数大于 2 的情况，给出线性可分与线性不分严格的数学定义。</p>
<p>③ 请通过数学定义严格证明，在二分类情况下，如果一个数据集是线性可分的，那么一定存在无数多个超平面可以把这两个类别完全分开。</p>
<h3 id="线性可分的解法"><a href="#线性可分的解法" class="headerlink" title="线性可分的解法"></a>线性可分的解法</h3><p>支持向量机算法步骤：① 解决线性可分问题 ② 再将线性可分问题中获得的结论推广到线性不可分情况</p>
<p>例子：三种分割按照免费午餐定理应该都一样，为什么会觉得 2 比较好？因为建立在这样一个先验假设：训练样本的位置在特征空间上有测量误差，这样的话 2 会有更高的容错率。</p>
<img src="https://s2.loli.net/2022/05/31/1IF4TA2aVRfx8Ee.png" alt="image-20220531151537298" style="zoom:50%;" />

<p>那么如何画出2线？也就是SVM算法的步骤①。</p>
<p>把一条分割线平行地往两侧移动，直到擦到两边的样本。令平行线擦到的样本为支持向量（support vector），平行线的间隔称为间隔（margin），SVM就是要让间隔做最大的那一个分割线。</p>
<p>但该方法不唯一，与该线平行的线都是间隔最大的。为保证唯一性，应使这条线在两条平行线中央。</p>
<p>总结条件：① 该直线分开了两类 ② 该直线最大化间隔 ③该直线处于间隔的中间，到所有支持向量距离相等。</p>
<p>基于以下事实：</p>
<p>① 相同超平面</p>
<p>$$<br>w^Tx+b&#x3D;0 与\<br>(\alpha w^T)x+(ab)&#x3D;0是同一个超平面(\alpha \neq 0)<br>$$</p>
<p>② 点到直线&#x2F;面的距离公式</p>
<p>$$<br>d&#x3D;\frac{|w^Tx+b|}{||w||}<br>$$</p>
<p>我们要的就是最大化 margin 到 support vector 之间的距离！</p>
<p>据事实一，引出SVM最难理解的部分：用 a 去缩放 w 和 b。在 SVM 中，我们会发现我们会令支持向量到点的距离这一分式的分子是 1，为什么可以这么设呢？</p>
<p>因为对于对于一个 $$(w, b)$$，可以对齐进行任意的等比例放缩得到  $$(aw, ab)$$，二者所表示的超平面是不变的，但是会使得分子的大小变化，因此可以使得：</p>
<p>$$<br>|w^Tx_0+b|&#x3D;1, \ x_0为支持向量 \<br> |w^Tx_0+b|&gt;1, \  x_0非支持向量<br>$$</p>
<p>这样我们就大幅简化了要优化的对象。也即</p>
<p>$$<br>d&#x3D;\frac{|w^Tx+b|}{||w||} &#x3D; \frac{1}{||w||}<br>$$</p>
<p>因而问题转换为最小化 w 的模。实操中为方便求导定义作如下形式：</p>
<p>$$<br>最小化：\frac{1}{2}||w||^2 \<br>限制条件：y_i(w^TX_i+b) &gt;&#x3D; 1,(i&#x3D;1-N) \<br>||w||^2 &#x3D; \sum^{m}_{i&#x3D;1}w_i^2<br>$$</p>
<p>其中，$$y_i$$ 的作用是协调超平面的作用，同线性可分中的作用一样。上述的 1 可以改成别的整数，相当于放缩的时候采用了不同的尺度。</p>
<p>因而，SVM问题转为一个凸优化中的二次规划问题。</p>
<p>二次规划问题的定义：①目标函数(Objective Function)是二次项。②限制条件是一次项（这里的不等式就是一次项）。这样的问题要么无解，要么有唯一最小值。</p>
<p>已知凸优化问题，必有全局唯一的极值，可以用梯度下降解决。具体的解决方法，需学习《最优化》。</p>
<p>课后思考：</p>
<p>① 支持向量机的限制条件如果从大于等于1变成大于等于2，则(w, b)会变成(aw , ab) 。如果 Xi 和 w 是 M 维向量，那么 a 是多少？</p>
<p>② 证明在线性可分条件下，有且只有唯一一条直线满足 SVM 的三个条件。</p>
<h3 id="线性不可分的解法"><a href="#线性不可分的解法" class="headerlink" title="线性不可分的解法"></a>线性不可分的解法</h3><p>考虑线性不可分的情况，需要适当放松限制条件，否则以上问题无解。</p>
<p>基本思路有为为每个训练样本及其标签设置松弛变量（slack variable）δ。</p>
<p>因此，限制条件改写为：</p>
<p>$$<br>y_i(w^TX_i+b) &gt;&#x3D; 1-\delta_i,(i&#x3D;1-N)<br>$$</p>
<p>当然还要加入新的限制使得 $$\delta$$ 在一个合理范围内。最终，该问题改写为：</p>
<p>$$<br>最小化：\frac{1}{2}||w||^2 + C\sum^{N}<em>{i&#x3D;1}\delta_i\  或\ \frac{1}{2}||w||^2 + C\sum^{N}</em>{i&#x3D;1}\delta_i^2 \<br>限制条件： (1)\ \delta_i&gt;&#x3D;0,(i&#x3D;1-N)\<br>(2)\ y_i(w^TX_i+b) &gt;&#x3D; 1-\delta_i,(i&#x3D;1-N)<br>$$</p>
<p>比例因子C，起到平衡加法两侧的作用，是人为设定的超参数。实操中，要不断变化C，同时测试算法的效果，然后选个最好的。两个最小化形式都是二次型。C 设尽可能大，可以尽可能向线性的结果靠拢。</p>
<p>一个失败的情况：线性模型的表现力是不够的。</p>
<img src="https://s2.loli.net/2022/05/31/plhyxCJ6fLFswrd.png" alt="image-20220531154900234" style="zoom:50%;" />

<p>课后思考：</p>
<p>① 在这个例子中，你能否设计出一个这样的非线性变换，将这个分类问题转化为线性可分呢？</p>
<h3 id="非线性变换"><a href="#非线性变换" class="headerlink" title="非线性变换"></a>非线性变换</h3><p>针对线性模型表现力不够的情况，因而需要扩大可选函数范围。SVM中，会将特征空间把低维映射到高维，再使用线性超平面分类。</p>
<p>定理：在一个 M 维空间上随机取 N 个训练样本随机的对每个训练样本赋予标签 +1 或 -1，这些训练样本线性可分的概率为 P(M)，当 M 趋于无穷大时，P(M) &#x3D; 1。</p>
<p>构造映射 $$\varphi(x)$$ 便是关键。假设已知映射 $$\varphi(x)$$，则改为：</p>
<p>$$<br>最小化：\frac{1}{2}||w||^2 + C\sum^{N}<em>{i&#x3D;1}\delta_i\  或\ \frac{1}{2}||w||^2 + C\sum^{N}</em>{i&#x3D;1}\delta_i^2 \<br>限制条件： (1)\ \delta_i&gt;&#x3D;0,(i&#x3D;1-N)\<br>(2)\ y_i(w^T\varphi(X_i)+b) &gt;&#x3D; 1-\delta_i,(i&#x3D;1-N)<br>$$</p>
<p>此时，w 的维度和映射后的向量维度相同。解法是和低维完全类似的。</p>
<p>为研究 $$\varphi(x)$$ 的形式，引入核函数的概念。实操中我们不用知道 $$\varphi(x)$$ 的具体形式，取而代之的是核函数：</p>
<p>即对于任意两个向量，有</p>
<p>$$<br>K(X_1,X_2)&#x3D;\varphi(X_1)^T\varphi(X_2)<br>$$</p>
<p>那么仍然能通过一些技巧获得样本的类别，从而完成对样本类别的预测。具体通过为什么技巧将在之后描述。在此先举例说明核函数以及低维到高维的映射 $$\varphi(x)$$ 之间的相互关系。</p>
<p>假设 $$\varphi(x)$$ 是一个把二维向量映射为三维向量的映射：</p>
<p>$$<br>X&#x3D;[x_1,x_2]^T \<br>\phi(X)&#x3D;\phi([x_1,x_2]^T)&#x3D;[x_1^2,x_1x_2,x_2^2]<br>$$</p>
<p>假设有 X1 和 X2，那么核函数为：</p>
<p>$$<br>K(X_1,X_2)&#x3D;\phi(X_1)^T\phi(X_2) \<br>&#x3D;[x_{11}^2,x_{11}x_{12},x_{12}^2][x_{21}^2,x_{21}x_{22},x_{22}^2]^T \<br>&#x3D; x_{11}^2x_{21}^2+x_{11}x_{12}x_{21}x_{22}+x_{12}^2x_{22}^2<br>$$</p>
<p>反之，已知核函数 K 求 phi（x）。</p>
<p>$$<br>K(X_1,X_2)&#x3D;(x_{11}x_{21}+x_{12}x_{22}+1)^2 \<br>&#x3D; x_{11}^2x_{21}^2+x_{12}^2x_{22}^2+1+2x_{11}x_{21}x_{12}x_{22}+2x_{11}x_{21}+2x_{12}x_{22} \<br>&#x3D; \phi(X_1)^T\phi(X_2)<br>$$</p>
<p>根据定义和观察，</p>
<p>$$<br>\phi(X)&#x3D;\phi([x_1,x_2]^t) \<br>&#x3D; [x_1^2,x_2^2,1,\sqrt{2}x_1x_2,\sqrt{2}x_1,\sqrt{2}x_2]^T<br>$$</p>
<p>因而，核函数 K 和映射 phi 一一映射。但是 K 需要满足一定条件才可写作两个 phi 内积的形式。具体条件如下：（Mercer’s Theorem）</p>
<p>$$<br>K(X_1,X_2) 能写成 \phi(X_1)^T\phi(X_2)的充要条件：<br>$$</p>
<p>$$<br>① K(X_1,X_2)&#x3D;K(X_2,X_1)（交换性）\<br>② \forall C_i(i&#x3D; 1\sim N),\forall N有\sum^{N}<em>{i&#x3D;1}\sum^{N}</em>{j&#x3D;1}C_iC_jK(X_i,X_j) \ge0 （半正定性质）<br>$$</p>
<p>虽然无法知道 phi 的具体形式，但是可以知道 wx+b 的值，进而知道所属类别。</p>
<h3 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h3><p>具体研究已知 K 不知 phi 求 SVM 的优化问题。</p>
<p>原问题（Prime problem）</p>
<p>$$<br>最小化：f(w) \<br>限制条件：g_i(w) \le 0,i&#x3D;1\sim K \<br>h_i(w) &#x3D; 0,i&#x3D;1\sim K<br>$$</p>
<p>对偶问题（Dual problem）</p>
<p>$$<br>L(w,\alpha,\beta)&#x3D;f(w)+\sum^{K}<em>{i&#x3D;1}\alpha_ig_i(w)+\sum^{M}</em>{i&#x3D;1}\beta_ih_i(w) \<br>&#x3D;f(w)+\alpha^Tg(w)+\beta^Th(w)<br>$$</p>
<p>其中，</p>
<p>$$<br>\alpha &#x3D; [\alpha_1,\alpha_2,…,\alpha_K]^T \<br>\beta &#x3D; [\beta_1,\beta_2,…,\beta_M]^T \<br>g(w) &#x3D; [g_1(w),g_2(w),…,g_K(w)]^T \<br>h(w) &#x3D; [h_1(w),h_2(w),…,h_M(w)]^T<br>$$</p>
<p>在定义了 L 函数的基础上，定义对偶问题如下：遍历定义域里的 w，找到使得 L 最小的那个 w，同时把最小的这个函数值赋值给 theta 函数。</p>
<p>个人理解：先通过遍历 w 得到最小的 L。得到最小的 L 后就找到了对应的 w，此时 w 已知，alpha 和 beta 未知，因而得到 alpha 和 beta 的 theta 函数。之后再最大化这个函数。</p>
<img src="https://s2.loli.net/2022/05/31/OchJDWYZtAbgxas.png" alt="image-20220531162651917" style="zoom:50%;" />

<p>综合两个问题的定义，得到以下定理：</p>
<p>定理一：</p>
<img src="https://s2.loli.net/2022/06/01/VwJj5YStWBUAdru.png" alt="image-20220601212739070" style="zoom:50%;" />

<p>这个定理告诉我们原问题的解总是大于等于对偶问题的解。我们把 f(w*) - theta(alpha*, beta*) 定义为对偶差距（DUALITY GAP）。对偶差距显然大于等于0。</p>
<p>强对偶定理：</p>
<img src="https://s2.loli.net/2022/06/01/bFMSpKvQGjXTyBd.png" alt="image-20220601212922525" style="zoom:50%;" />

<p>简单点说，原问题的目标函数是凸函数，限制条件是线性函数，那么对偶差距为0。具体证明可以课后阅读。</p>
<p>根据定理一推出的不等式：</p>
<p>若 f(w*) &#x3D; theta(alpha*, beta*) （简单点说，就是原问题和对偶问题的解相等的时候），则根据定理一，显然可以推出，对于所有的 i&#x3D;1~K，要么 alpha_i &#x3D; 0，要么 g(w*) &#x3D; 0。这个条件就是 <strong>KKT 条件</strong>。</p>
<img src="https://s2.loli.net/2022/07/06/xWPny7HlMKkjC8A.webp" alt="tt" style="zoom: 80%;" />



<h3 id="最终求解"><a href="#最终求解" class="headerlink" title="最终求解"></a>最终求解</h3><p>将原问题转换为对偶问题，以完成问题的求解。</p>
<p>支持向量机的原问题满足强对偶定理。回顾 SVM 的优化问题：</p>
<img src="https://s2.loli.net/2022/05/31/oVqRixPIAESOwvZ.png" alt="image-20220531155717872" style="zoom:50%;" />

<p>结合原问题的定义，需要把前两个限制条件改成小于等于 0 的定义。限制条件取反，那么最小化中也要取反。</p>
<img src="https://s2.loli.net/2022/06/01/uI5UCYjaOpxh4qr.png" alt="image-20220601213714343" style="zoom:50%;" />

<p>两个限制条件都线性的，目标函数是凸的，满足强对偶定理。 SVM 中不存在 h(x) 的情况。因此，可以把 SVM 的对偶问题写作如下形式：</p>
<p><img src="https://s2.loli.net/2022/06/04/EQX89ehCZy6fgJM.png" alt="image-20220604100525102"></p>
<p>tips：对偶问题中的 w 指的是未知变量，此时，未知变量 w 包括 (w, sigma, beta)。求微分，得下式：</p>
<p><img src="https://s2.loli.net/2022/06/04/GvA6azXVfTZdjRn.png" alt="image-20220604101500136"></p>
<p>根据 ② 消去红框，根据 ③ 消去蓝框：</p>
<p><img src="https://s2.loli.net/2022/06/04/QoWi9dD48xhbeaK.png" alt="image-20220604101613674"></p>
<p>原式还剩三项：</p>
<p><img src="https://s2.loli.net/2022/06/04/uCDWijhQARV6azJ.png" alt="image-20220604101835441"></p>
<p><img src="https://s2.loli.net/2022/06/04/xSnw8R5I1odiZeH.png" alt="image-20220604101959039"></p>
<p>整理之后，化简为：</p>
<p><img src="https://s2.loli.net/2022/06/04/ZXldJepLO4mzkjh.png" alt="image-20220604102209717"></p>
<p>问题中，已知的是所有的 x，y 以及核函数 K。这是一个凸的问题，可以用 SMO 算法求解。</p>
<p>但化成这样后，还没完。这样求出了 alpha 还要求 omega 和 bias。</p>
<p><img src="https://s2.loli.net/2022/06/04/ImYC5iEnyph7X4R.png" alt="image-20220604102442932"></p>
<p>但是求 omega 岂不是又得知道映射函数？实则不用，因为实际上我们不需要知道 omega。考虑测试流程：</p>
<p>测试样本 x 输入，若 omega^T phi(x) + b&gt;&#x3D; 0 则 y&#x3D;+1，反之 y&#x3D;-1。</p>
<p>实际上， omega^T phi(x) &#x3D; sum_i_N alpha_i y_i K(xi, x)。又把 phi 化简掉了，只需要用核函数 K 去算就行。</p>
<p>接下来分析求 bias，先把 SVM 问题中的 KKT 条件列出：</p>
<p><img src="https://s2.loli.net/2022/06/04/en27UgKdAiz5ayw.png" alt="image-20220604103437775"></p>
<p>假定 alpha_i 都算出来了，那么一定能找出一个 alpha_i 是 0&lt;alpha_i&lt;C 的【？】。首先取一个 alpha_i 是 0&lt;alpha_i&lt;C 的，可得 beta_i &#x3D; c-alpha_i &gt; 0，可得 epsilon_i &#x3D; 0。有 alpha_i !&#x3D; 0 可得 ② 中后半式，根据该式求解 b：</p>
<p><img src="https://s2.loli.net/2022/06/04/Jr4OdHjYlGpCAiu.png" alt="image-20220604103518915"></p>
<p>在实际运算中，可以取所有满足条件 0&lt;alpha_i&lt;C 的 alpha_i，求出对应 b ，然后做平均。</p>
<p>总结如下：</p>
<img src="https://s2.loli.net/2022/06/04/8CQ5dEPj4wMyXAY.png" alt="image-20220604104117394" style="zoom:50%;" />

<p><img src="https://s2.loli.net/2022/06/04/ui7bZSk4YcTox6K.png" alt="image-20220604104219998"></p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><a class="tag" href="/categories/machine-learning/" title="machine-learning">machine-learning </a><span class="leancloud_visitors"></span><span>About 3556 words, 11 min 51 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2021/07/06/data-structure-algorithms/2021-07-06-fragmentary-knowledge/">[da] fragmentary knowledge</a></h3></div><div class="post-content"><div class="card"><p><h2 id="杂记"><a href="#杂记" class="headerlink" title="杂记"></a>杂记</h2><p>+++</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">200</span> * <span class="number">1000</span> + <span class="number">11</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> p[N];</span><br><span class="line"><span class="type">int</span> d[N];</span><br><span class="line">vector&lt;<span class="type">int</span>&gt; g[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> v, <span class="type">int</span> pr = <span class="number">-1</span>, <span class="type">int</span> dst = <span class="number">0</span>)</span> </span>&#123;</span><br><span class="line">	d[v] = dst;</span><br><span class="line">	p[v] = pr;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">auto</span> to : g[v]) &#123;</span><br><span class="line">		<span class="keyword">if</span> (to != pr) &#123;</span><br><span class="line">			<span class="built_in">dfs</span>(to, v, dst + <span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> _DEBUG</span></span><br><span class="line">	<span class="built_in">freopen</span>(<span class="string">&quot;input.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, stdin);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> n;</span><br><span class="line">	<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">		<span class="type">int</span> x, y;</span><br><span class="line">		<span class="built_in">scanf</span>(<span class="string">&quot;%d %d&quot;</span>, &amp;x, &amp;y);</span><br><span class="line">		--x, --y;</span><br><span class="line">		g[x].<span class="built_in">push_back</span>(y);</span><br><span class="line">		g[y].<span class="built_in">push_back</span>(x);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">dfs</span>(<span class="number">0</span>);</span><br><span class="line">	set&lt;pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt;&gt; st;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">		<span class="keyword">if</span> (d[i] &gt; <span class="number">2</span>) &#123;</span><br><span class="line">			st.<span class="built_in">insert</span>(<span class="built_in">make_pair</span>(-d[i], i));</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (!st.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">		<span class="type">int</span> v = st.<span class="built_in">begin</span>()-&gt;second;</span><br><span class="line">		v = p[v];</span><br><span class="line">		++ans;</span><br><span class="line">		<span class="keyword">auto</span> it = st.<span class="built_in">find</span>(<span class="built_in">make_pair</span>(-d[v], v));</span><br><span class="line">		<span class="keyword">if</span> (it != st.<span class="built_in">end</span>()) &#123;</span><br><span class="line">			st.<span class="built_in">erase</span>(it);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">auto</span> to : g[v]) &#123;</span><br><span class="line">			<span class="keyword">auto</span> it = st.<span class="built_in">find</span>(<span class="built_in">make_pair</span>(-d[to], to));</span><br><span class="line">			<span class="keyword">if</span> (it != st.<span class="built_in">end</span>()) &#123;</span><br><span class="line">				st.<span class="built_in">erase</span>(it);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, ans);</span><br><span class="line">        <span class="built_in">system</span>(<span class="string">&quot;pause&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h3 id="Memset"><a href="#Memset" class="headerlink" title="Memset"></a>Memset</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>memset 函数是内存赋值函数，用来给某一块内存空间进行赋值的。</p>
<p>原型为 ：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> *<span class="title">memset</span><span class="params">(<span class="type">void</span> *s, <span class="type">int</span> v, <span class="type">size_t</span> n)</span></span>;  </span><br></pre></td></tr></table></figure>

<p>这里s可以是数组名，也可以是指向某一内在空间的指针；v为要填充的值；n为要填充的字节数； </p>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>① 数组置0（通用）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(dp, <span class="number">0</span>, <span class="built_in">sizeof</span>(dp));</span><br></pre></td></tr></table></figure>

<p>② 无符号整数组置最值</p>
<p>即每个字节置为 0xff</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(dp, <span class="number">0xff</span>, <span class="built_in">sizeof</span>(dp));</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>③ 有符号整数置最值（memset能达到的最值）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(dp, <span class="number">0x7f</span>, <span class="built_in">sizeof</span>(dp));</span><br><span class="line"><span class="built_in">memset</span>(arr,<span class="number">0x80</span>,<span class="built_in">sizeof</span>(arr)); <span class="comment">//set int to -2139062144</span></span><br></pre></td></tr></table></figure>

<p>④ 有符号整数置-1</p>
<p>即每个字节变成 0xff（-1补码）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(dp, <span class="number">-1</span>, <span class="built_in">sizeof</span>(dp));</span><br><span class="line"><span class="built_in">memset</span>(dp, <span class="number">0xff</span>, <span class="built_in">sizeof</span>(dp));</span><br></pre></td></tr></table></figure>

<p>⑤ Double置最值</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">memset</span>(arr,<span class="number">0x7F</span>,<span class="built_in">sizeof</span>(arr)); <span class="comment">//set double to 1.38242e+306</span></span><br><span class="line"><span class="built_in">memset</span>(arr,<span class="number">0xFE</span>,<span class="built_in">sizeof</span>(arr)); <span class="comment">//set double to -5.31401e+303</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="DP"><a href="#DP" class="headerlink" title="DP"></a>DP</h3><p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/"><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/house-robber/">198. House Robber</a></a></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Input: nums = [<span class="number">2</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">3</span>,<span class="number">1</span>]</span><br><span class="line">Output: <span class="number">12</span></span><br><span class="line">Explanation: Rob house <span class="number">1</span> (money = <span class="number">2</span>), rob house <span class="number">3</span> (money = <span class="number">9</span>) <span class="keyword">and</span> rob house <span class="number">5</span> (money = <span class="number">1</span>).</span><br><span class="line">             Total amount you can rob = <span class="number">2</span> + <span class="number">9</span> + <span class="number">1</span> = <span class="number">12.</span></span><br></pre></td></tr></table></figure>

<p>动态转移方程：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dp[i] = <span class="built_in">max</span>(dp[i<span class="number">-1</span>], dp[i<span class="number">-2</span>] + nums[i]);</span><br><span class="line"><span class="comment">// 若不抢这家，那么本次最大值为上次最大值；反之为上上次最大值＋这次</span></span><br></pre></td></tr></table></figure>



<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/min-cost-climbing-stairs/">746. Min Cost Climbing Stairs</a></p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: cost = [<span class="number">1</span>, <span class="number">100</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>, <span class="number">1</span>]</span><br><span class="line">Output: <span class="number">6</span></span><br><span class="line">Explanation: Cheapest is start on cost[<span class="number">0</span>], <span class="keyword">and</span> only step on <span class="number">1</span>s, skipping cost[<span class="number">3</span>].</span><br></pre></td></tr></table></figure>

<p>动态转移方程：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dp[i] = <span class="built_in">min</span>(dp[i<span class="number">-1</span>] + cost[i<span class="number">-1</span>], dp[i<span class="number">-2</span>] + cost[i<span class="number">-2</span>]);</span><br><span class="line"><span class="comment">// 到达i点有两种方案：要么从前一次过来，要么从前前一格过来</span></span><br></pre></td></tr></table></figure>



<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/maximum-subarray/">53. Maximum Subarray</a></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input: nums = [<span class="number">-2</span>,<span class="number">1</span>,<span class="number">-3</span>,<span class="number">4</span>,<span class="number">-1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">-5</span>,<span class="number">4</span>]</span><br><span class="line">Output: <span class="number">6</span></span><br><span class="line">Explanation: [<span class="number">4</span>,<span class="number">-1</span>,<span class="number">2</span>,<span class="number">1</span>] has the largest sum = <span class="number">6.</span></span><br></pre></td></tr></table></figure>

<p>动态转移方程：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dp[i] = (dp[i<span class="number">-1</span>] &gt; <span class="number">0</span> ? dp[i<span class="number">-1</span>] + nums[i] : nums[i])</span><br><span class="line"><span class="comment">//dp[i] 代表以元素 nums[i] 为结尾的连续子数组最大和。</span></span><br></pre></td></tr></table></figure>



<p><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/is-subsequence/">392. Is Subsequence</a></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: s = <span class="string">&quot;abc&quot;</span>, t = <span class="string">&quot;ahbgdc&quot;</span></span><br><span class="line">Output: <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>动态转移方程：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dp[i] = (t[i] == s[dp[i<span class="number">-1</span>]] ? dp[i<span class="number">-1</span>]+<span class="number">1</span> : dp[i<span class="number">-1</span>]);</span><br><span class="line"><span class="comment">// dp[i] 表示t的第i位已匹配至s的dp[i]位</span></span><br></pre></td></tr></table></figure>



<h4 id="经典dp-0-1背包"><a href="#经典dp-0-1背包" class="headerlink" title="经典dp 0-1背包"></a>经典dp 0-1背包</h4><p>给你一个可装载重量为<code>W</code>的背包和<code>N</code>个物品，每个物品有重量和价值两个属性。其中第<code>i</code>个物品的重量为<code>wt[i]</code>，价值为<code>val[i]</code>，现在让你用这个背包装物品，最多能装的价值是多少？</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">3</span>, W = <span class="number">4</span></span><br><span class="line">wt = [<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">val = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<p><code>dp[i][w] </code>的定义如下：对于容量为<code>w</code>的背包，装<code>前i</code>个物品，可以装的最大价值。</p>
<p>① 若第i个物品的<code>wt[i] &gt; w</code>，那么一定不会拿取。则容量为<code>w</code>的包装<code>前i</code>个物品可得到的价值则为容量为<code>w的</code>包装<code>前i-1</code>个物品可得到的价值，即<code>dp[i][w] = dp[i-1][w]</code>。</p>
<p>② 若第i个物品的<code>wt[i] &lt;= w</code>，那么则有以下两种情况	</p>
<p>​	a.不拿。容量为<code>w</code>的包装<code>前i个</code>物品可得到的值则为容量为<code>w</code>的包装<code>前i-1</code>个物品可得到的价值，即<code>dp[i][w] = dp[i-1][w]。</code></p>
<p>​	b.拿走。容量为<code>w</code>的包装<code>前i个</code>物品可得到的值则为容量为<code>w-wt[i]</code>的包装<code>前i-1</code>个物品可得到的价值+<code>第i项物品的价值</code>，即 <code>dp[i][w] = dp[i - 1][w - wt[i-1]] + val[i-1]</code>。</p>
<p>二者取最优解即可。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">knapsack</span><span class="params">(<span class="type">int</span> W, <span class="type">int</span> N, vector&lt;<span class="type">int</span>&gt;&amp; wt, vector&lt;<span class="type">int</span>&gt;&amp; val)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// vector 全填入 0，base case 已初始化</span></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dp</span>(N + <span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(W + <span class="number">1</span>, <span class="number">0</span>));</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= N; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> w = <span class="number">1</span>; w &lt;= W; w++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (w - wt[i<span class="number">-1</span>] &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// 当前背包容量装不下，只能选择不装入背包</span></span><br><span class="line">                dp[i][w] = dp[i - <span class="number">1</span>][w];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 装入或者不装入背包，择优</span></span><br><span class="line">                dp[i][w] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][w - wt[i<span class="number">-1</span>]] + val[i<span class="number">-1</span>], </span><br><span class="line">                               dp[i - <span class="number">1</span>][w]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[N][W];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.luogu.com.cn/problem/P1048">P1048 采药</a></p>
</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2021-07-06</span><a class="tag" href="/categories/others/" title="others">others </a><span class="leancloud_visitors"></span><span>About 1100 words, 3 min 40 sec  read</span></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/page/3/">Next</a></li></ul></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>