<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Yourname"><title>Domain Adaptation · Hexo</title><meta name="description" content="27 Domain Adaptation训练资料跟测试资料的分布是不一样的，叫做 &amp;#x3D;&amp;#x3D;Domain Shift&amp;#x3D;&amp;#x3D;。
解决办法是 &amp;#x3D;&amp;#x3D;Domain Adaptation&amp;#x3D;&amp;#x3D;，它也可以看做是 &amp;#x3D;&amp;#x3D;Tra"><meta name="keywords" content="Blog,博客,Hexo"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/insight.css"><link rel="stylesheet" href="/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li> <a href="/">Home</a></li><li> <a href="/archives">Archives</a></li><li> <a href="/tags">Tags</a></li><li> <a href="/about">About</a></li><li> <a href="/links">Links</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/images/logo.webp"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/images/logo@2x.webp" style="width:220px;" alt="favicon"><h3 title=""><a href="/">Hexo</a></h3><div class="description"><p>A simple and beautiful blog</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/Lhcfl"><i class="fa fa-github"></i></a></li><li><a href="mailto:yourname@example.com"><i class="fa fa-envelope"></i></a></li><li><a target="_blank" rel="noopener" href="https://zhihu.com/people/jin-xin-4-68"><i class="fa fa-mortar-board"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> 全站CC-BY-SA-3.0 </span><i class="fa fa-star"></i><span> Yourname</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Domain Adaptation</a></h3></div><div class="post-content"><p><h1 id="27-Domain-Adaptation"><a href="#27-Domain-Adaptation" class="headerlink" title="27 Domain Adaptation"></a>27 Domain Adaptation</h1><p>训练资料跟测试资料的分布是不一样的，叫做 &#x3D;&#x3D;Domain Shift&#x3D;&#x3D;。</p>
<p>解决办法是 &#x3D;&#x3D;Domain Adaptation&#x3D;&#x3D;，它也可以看做是 &#x3D;&#x3D;Transfer Learning&#x3D;&#x3D; 的一种。</p>
<p>Transfer Learning ：在 A 任务上学到的技能可以被用在 B 任务上</p>
<p>Domain Adaptation：你的训练资料是一个 Domain，你的测试资料是另外一个 Domain，你在训练资料上面学到的资讯可以要把它用到另外一个 Domain 上。</p>
<h2 id="Domain-Shift"><a href="#Domain-Shift" class="headerlink" title="Domain Shift"></a>Domain Shift</h2><p>两者可能情况。一，输入资料即训练集和测试集的分布不同。二，输入跟输出虽然分布相同的，但它们之间的关係变了，比如训练集叫做 0 的东西在测试集里叫做 1。</p>
<p>今天只考虑前者。记测试集为 &#x3D;&#x3D;Target Domain&#x3D;&#x3D;，训练集为 &#x3D;&#x3D;Source Domain&#x3D;&#x3D;。</p>
<h2 id="Domain-Adaptation"><a href="#Domain-Adaptation" class="headerlink" title="Domain Adaptation"></a>Domain Adaptation</h2><p>分三种情况考虑：</p>
<p>其一，在 Target Domain 上有一大堆的资料且配有 Label，那就直接拿 Target Domain 的资料来训练。</p>
<p>其二，在 Target Domain 上有一点点的资料且配有 Label，那就拿他们来微调，即不要在 Target Domain 上的资料上跑太多的 Iteration。</p>
<p>其三，在 Target Domain 上有一大堆的资料但没有 Label。找个 Feature Extractor，它会把 Source 和 Target 不一样的部分拿掉，只抽取出它们共同的部分。</p>
<p>其四，在 Target Domain 上有一点点的资料且没有 Label。有一个方法叫做 &#x3D;&#x3D;Testing Time Training&#x3D;&#x3D;,它的缩写是 TTT。</p>
<img src="https://s2.loli.net/2022/07/02/YkL3rCt54DKV1hd.png" alt="image-20220702171146183" style="zoom:50%;" />



<h3 id="Domain-Adversarial-Training"><a href="#Domain-Adversarial-Training" class="headerlink" title="Domain Adversarial Training"></a>Domain Adversarial Training</h3><p>怎麼找出这样的一个 Feature Extractor 呢？那其实我们可以把一个一般的 Classifier 分成 Feature Extractor 跟 Label Predictor 。</p>
<img src="https://s2.loli.net/2022/07/02/KRqyn5MD2SxmYE3.png" alt="image-20220702172724450" style="zoom:50%;" />

<p>Domain Adaptation 的一种方法 &#x3D;&#x3D;Domain Adversarial Training&#x3D;&#x3D;</p>
<p>训练 Feature Extractor：让 Source Domain 的图片得到的 Feature，跟 Target Domain 的分不出差异。</p>
<p>训练 Domain Classifier：二元分类器，区分这个 feature 是来自於 Source Domain,还是来自於 Target Domain。</p>
<p>Domain Adversarial Training 很像是 GAN。可以把 Feature Extractor 想成是 Generator，把 Domain Classifier 想成是 Discriminator。</p>
<p>Generator 好像优势太大了，它只要都输出 0 不就无法区分了吗？不行，都输出 0 虽然 Domain Classifier 无法区分，但 Label Predictor 也无法区分！</p>
<p>接下来考虑参数优化。Label Predictor 要做的事情就是让这个 Source Domain 的 Image 分类越正确越好，即最小化 Loss（交叉熵，分类问题有交叉熵）。Domain Classifier 要做的事情就是让 Domain 的分类越正确越好，也是最小化交叉熵。</p>
<p>Feature Extractor 要做的事情是，它又要保证能让 Label Predictor 有个好结果，又要骗过 Domain Classifier，故把 loss 设为 $L-L_d$。</p>
<h4 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h4><p>刚才这整套想法有一个小小的问题</p>
<img src="https://s2.loli.net/2022/07/02/Hrnl2S15keas3fT.png" alt="image-20220702173655699" style="zoom:50%;" />

<p>直觉上讲右边更好，所以我们是不是应该要让右边的状况发生呢？怎么做呢？也许一个可能的想法：我们既然知道分界点在哪裡，那我们应该要让这些方形远离这一个分界点。</p>
<h4 id="Considering-Decision-Boundary"><a href="#Considering-Decision-Boundary" class="headerlink" title="Considering Decision Boundary"></a>Considering Decision Boundary</h4><p>什麼叫做离 Boundary 越远越好呢？如果今天输出的结果非常地集中，即 Entropy 小，叫做离 Boundary 远。反之则近。</p>
<p>到目前為止都假设说，Source Domain 跟 Target Domain，它的类别都要是一模一样。但是真的一定会这样吗？</p>
<img src="https://s2.loli.net/2022/07/02/wjvbz6ytZYGfS7H.png" alt="image-20220702174451574" style="zoom:50%;" />



<p>实线的圈圈代表，Source Domain 裡面有的东西，这个虚实线的圈圈代表 Target Domain 裡面有的东西。所以在这个前提之下，你说你要让 Source Domain 的 Data 跟 Target Domain 的 Data，它们的 Feature 完全 Match 在一起，那意味著说，你硬是要让老虎去变得跟狗像，到时候你就分不出老虎这个类别了。</p>
<h2 id="Domain-Generalization"><a href="#Domain-Generalization" class="headerlink" title="Domain Generalization"></a>Domain Generalization</h2><p>但其实还有一个更严峻的状况，如果我们对 Target Domain 一无所知的话怎麼办呢？这种情况通常就叫 &#x3D;&#x3D;Domain Generalization&#x3D;&#x3D;。</p>
<p>我们期待机器在 Testing 的时候，不管来什麼样的 Domain，它都可以处理。</p>
<p>Domain Generalization 又分成两种状况：其一，训练资料本来就包含了各式各样不同的 Domain 的数据；其二，训练资料只有一个 Domain，做 Data Augmentation。</p>
</p><div class="tip">本文采用CC-BY-SA-3.0协议，转载请注明出处<br>Author: Yourname</div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2022-07-06</span><i class="fa fa-tag"></i><a class="tag" href="/tags/machine-learning/" title="machine-learning">machine-learning </a><span class="leancloud_visitors"></span><span>About 1168 words, 3 min 53 sec  read</span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,http://example.com/2022/07/06/machine-learning/2022-07-06-review-domain-adaptation/,Hexo,Domain Adaptation,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2022/07/06/machine-learning/2022-07-06-review-pattern-recognition-courses/" title="SYSU-PR-Courses">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2022/07/06/machine-learning/2022-07-06-review-generative-adversarial-network.md/" title="Generative Adversarial Network">Next</a></li></ul></div><script src="/js/visitors.js"></script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>